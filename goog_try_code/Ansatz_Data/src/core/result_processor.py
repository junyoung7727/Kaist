#!/usr/bin/env python3
"""
ê²°ê³¼ ì²˜ë¦¬ ëª¨ë“ˆ - ì–‘ì íšŒë¡œ ì‹¤í–‰ ê²°ê³¼ ì²˜ë¦¬ ë° ë¶„ì„ ë¡œì§ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤.
"""

import sys
import os
import json
import pandas as pd
import numpy as np
from typing import Dict, List, Any, Optional, Union, Tuple
from datetime import datetime
import gc
from tqdm import tqdm

# í‘œí˜„ë ¥ ê³„ì‚° ëª¨ë“ˆ ì„í¬íŠ¸
from src.calculators.expressibility.ibm import IBMExpressibilityCalculator

# í˜„ì¬ ìŠ¤í¬ë¦½íŠ¸ì˜ ìƒìœ„ ë””ë ‰í† ë¦¬ë¥¼ ì‹œìŠ¤í…œ ê²½ë¡œì— ì¶”ê°€ (ëª¨ë“ˆ ì„í¬íŠ¸ë¥¼ ìœ„í•¨)
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))
from src.config import config # Ensure config is imported

from data_manager import save_experiment_hdf5


def make_json_serializable(obj):
    """
    ì¬ê·€ì ìœ¼ë¡œ ê°ì²´ë¥¼ JSON ì§ë ¬í™” ê°€ëŠ¥í•œ í˜•íƒœë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    QuantumCircuit ë“±ì˜ ê°ì²´ëŠ” ë¬¸ìì—´ í‘œí˜„ìœ¼ë¡œ ë³€í™˜ë©ë‹ˆë‹¤.
    """
    if hasattr(obj, '__dict__'):
        # QuantumCircuit ë“±ì˜ ë³µì¡í•œ ê°ì²´
        if hasattr(obj, 'name') and hasattr(obj, 'num_qubits'):
            return {
                "type": "QuantumCircuit",
                "name": getattr(obj, 'name', 'unnamed'),
                "num_qubits": getattr(obj, 'num_qubits', 0),
                "depth": getattr(obj, 'depth', lambda: 0)(),
                "size": getattr(obj, 'size', lambda: 0)()
            }
        else:
            # ë‹¤ë¥¸ ê°ì²´ë“¤ì€ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
            try:
                return {k: make_json_serializable(v) for k, v in obj.__dict__.items() 
                       if not k.startswith('_')}
            except:
                return str(obj)
    elif isinstance(obj, dict):
        return {k: make_json_serializable(v) for k, v in obj.items()}
    elif isinstance(obj, (list, tuple)):
        return [make_json_serializable(item) for item in obj]
    elif isinstance(obj, (int, float, str, bool)) or obj is None:
        return obj
    elif hasattr(obj, 'tolist'):  # numpy arrays
        return obj.tolist()
    else:
        # ì§ë ¬í™”í•  ìˆ˜ ì—†ëŠ” ê°ì²´ëŠ” ë¬¸ìì—´ë¡œ ë³€í™˜
        return str(obj)


def process_mega_results(analysis_results, circuit_metadata, execution_time, ibm_backend):
    """
    ë©”ê°€ ì¡(Mega job) ë¶„ì„ ê²°ê³¼ ì²˜ë¦¬ - í”¼ë¸ë¦¬í‹° ë° í‘œí˜„ë ¥ ë¶„ì„ ê²°ê³¼ë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤.
    
    Args:
        analysis_results (Dict): run_analysis_jobì—ì„œ ë°˜í™˜ëœ ë¶„ì„ ê²°ê³¼
            (íšŒë¡œë³„ í”¼ë¸ë¦¬í‹°ì™€ í‘œí˜„ë ¥ ê°’ì´ í¬í•¨ë¨)
        circuit_metadata (List[Dict]): ê° íšŒë¡œì— ëŒ€í•œ ë©”íƒ€ë°ì´í„° ëª©ë¡ì…ë‹ˆë‹¤.
        execution_time (float): ì „ì²´ ì‘ì—… ì‹¤í–‰ì— ì†Œìš”ëœ ì‹œê°„(ì´ˆ)ì…ë‹ˆë‹¤.
        ibm_backend: IBM ë°±ì—”ë“œ ê´€ë¦¬ ê°ì²´
        
    Returns:
        List[Dict]: ê° íšŒë¡œë³„ë¡œ ì²˜ë¦¬ëœ ê²°ê³¼ì˜ ëª©ë¡ì…ë‹ˆë‹¤.
    """
    from src.utils.quantum_utils import (
        calculate_error_rates_mega,
        calculate_robust_fidelity_mega,
        calculate_measurement_statistics
    )
    
    print(f"\nğŸ”¬ ë©”ê°€ ì¡ ë¶„ì„ ê²°ê³¼ ì²˜ë¦¬ ì‹œì‘ ({len(circuit_metadata)}ê°œ íšŒë¡œ)")
    
    # í”¼ë¸ë¦¬í‹° ë° í‘œí˜„ë ¥ ê³„ì‚° ê²°ê³¼ëŠ” ì´ë¯¸ analysis_resultsì— í¬í•¨ë¨
    print(f"ğŸ“Š ë¶„ì„ ê²°ê³¼ í¬ë§·íŒ… ì¤‘... ({len(analysis_results)}ê°œ íšŒë¡œ ë°ì´í„°)")
    
    all_results = []
    
    # íšŒë¡œ ì¸ë±ìŠ¤ë³„ë¡œ ê²°ê³¼ ì²˜ë¦¬
    print("ğŸ“Š íšŒë¡œë³„ ê²°ê³¼ í†µí•© ì¤‘...")
    
    # ëª¨ë“  íšŒë¡œ ë©”íƒ€ë°ì´í„°ë¥¼ ìˆœíšŒ
    for circuit_idx, metadata in enumerate(tqdm(circuit_metadata, desc="íšŒë¡œ ì²˜ë¦¬")):
        try:
            # íšŒë¡œê°€ ë¶„ì„ ê²°ê³¼ì— ì—†ìœ¼ë©´ ê±´ë„ˆëœ€
            if circuit_idx not in analysis_results:
                print(f"âš ï¸ íšŒë¡œ {circuit_idx}: ë¶„ì„ ê²°ê³¼ ì—†ìŒ")
                continue
            
            # íšŒë¡œ ë¶„ì„ ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°
            circuit_analysis = analysis_results[circuit_idx]
            
            # ë©”íƒ€ë°ì´í„° ê¸°ë³¸ ì •ë³´ ì¶”ì¶œ
            n_qubits = metadata.get('n_qubits', 0)
            depth = metadata.get('depth', 0)
            circuit_name = metadata.get('name', f"circuit_{circuit_idx}")
            gate_counts = metadata.get('gate_counts', {})
            circuit_type = metadata.get('circuit_type', 'unknown')
            
            # í”¼ë¸ë¦¬í‹° ì •ë³´ ì¶”ì¶œ
            fidelity = circuit_analysis.get('fidelity', 0.0)
            fidelity_method = circuit_analysis.get('fidelity_method', 'not_available')
            
            # í‘œí˜„ë ¥ ì •ë³´ ì¶”ì¶œ (ìˆì„ ê²½ìš°)
            expressibility = circuit_analysis.get('expressibility', 0.0)
            expressibility_method = circuit_analysis.get('expressibility_method', 'not_available')
            distance_from_haar = circuit_analysis.get('distance_from_haar', 1.0)
            
            # ì¸¡ì • í†µê³„ ë° ì˜¤ë¥˜ìœ¨ ê³„ì‚°ì— í•„ìš”í•œ ê¸°ë³¸ ê°’ë“¤
            total_counts = 0
            processed_counts = {}
            zero_state_probability = 0.0
            
            # í”¼ë¸ë¦¬í‹° ê°’ì„ í†µí•´ ëª¨ë¸ë§ëœ í”¼ë¸ë¦¬í‹° ì§€í‘œ ê³„ì‚°
            error_rates = {
                "gate_error_rate": 1.0 - fidelity if isinstance(fidelity, (int, float)) else 1.0,
                "circuit_error_probability": 1.0 - fidelity if isinstance(fidelity, (int, float)) else 1.0
            }
            
            # ê°•í™” í”¼ë¸ë¦¬í‹° - ì—…ë°ì´íŠ¸ëœ ì‹œìŠ¤í…œì—ì„œëŠ” ì§ì ‘ ì¸¡ì •ëœ ê°’ ì‚¬ìš©
            robust_fidelity = fidelity
            
            # ì¸¡ì • í†µê³„ - ë ˆê±°ì‹œ í˜¸í™˜ì„±ì„ ìœ„í•´ ì„ì˜ì˜ ê°’ ì‚¬ìš©
            measurement_statistics = {
                "entropy": 0.0,
                "unique_states": 1
            }
            
            # í‘œí˜„ë ¥ ì •ë³´ êµ¬ì„±
            circuit_expressibility = {
                "value": expressibility if isinstance(expressibility, (int, float)) else 0.0,
                "method": expressibility_method,
                "distance_from_haar": distance_from_haar
            }
            
            # í”¼ë¸ë¦¬í‹° ê³„ì‚° ë° ì¶”ê°€ ë¶„ì„
            output_result = {
                "circuit_index": circuit_idx,
                "gate_metrics": error_rates,
                "fidelity": {
                    "simple": fidelity,  # ì´ì œ ì§ì ‘ í”¼ë¸ë¦¬í‹° ê°’ ì‚¬ìš©
                    "robust": robust_fidelity,
                    "method": fidelity_method
                },
                "expressibility": circuit_expressibility,
                "measurement_statistics": measurement_statistics,
                "execution_metadata": {
                    "circuit_index": circuit_idx,
                    "execution_time": execution_time,
                    "backend_name": ibm_backend.name,
                    "timestamp": datetime.now().isoformat()
                }
            }
            
            # ë©”íƒ€ë°ì´í„°ì—ì„œ ì¶”ê°€ ì •ë³´ ì¶”ì¶œ
            if circuit_idx < len(circuit_metadata):
                circuit_meta = circuit_metadata[circuit_idx]
                output_result.update(circuit_meta)
                
                # íŠ¹ë³„íˆ ì¤‘ìš”í•œ ì •ë³´ëŠ” ë³„ë„ë¡œ ê·¸ë£¹í™”
                output_result["additional_metrics"] = {
                    "depth": depth,
                    "width": n_qubits
                }
            
            # ìµœì¢… ê²°ê³¼ì— ì¶”ê°€
            all_results.append(output_result)
            
        except Exception as e:
            print(f"âš ï¸ íšŒë¡œ {circuit_idx} ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}")
            error_result = {
                "circuit_index": circuit_idx,
                "fidelity": {
                    "simple": float('nan'),
                    "robust": float('nan'),
                    "method": "processing_error"
                },
                "expressibility": {
                    "value": float('nan'),
                    "method": "processing_error",
                    "error": str(e)
                },
                "execution_metadata": {
                    "circuit_index": circuit_idx,
                    "execution_time": execution_time,
                    "backend_name": ibm_backend.name,
                    "timestamp": datetime.now().isoformat(),
                    "processing_error": True
                }
            }
            if circuit_idx < len(circuit_metadata):
                error_result.update(circuit_metadata[circuit_idx])
            all_results.append(error_result)
    
    print(f"âœ… ë©”ê°€ ì¡ ê²°ê³¼ ì²˜ë¦¬ ì™„ë£Œ ({len(all_results)}ê°œ ê²°ê³¼)")
    return all_results


def save_mega_results(all_results, training_circuits):
    """
    ë©”ê°€ ì¡(Mega job) ê²°ê³¼ë¥¼ íŒŒì¼ì— ì €ì¥í•©ë‹ˆë‹¤.
    
    Args:
        all_results (List[Dict]): `process_mega_results` í•¨ìˆ˜ì—ì„œ ë°˜í™˜ëœ ì²˜ë¦¬ëœ ê²°ê³¼ ëª©ë¡ì…ë‹ˆë‹¤.
        training_circuits (List[Dict]): í›ˆë ¨ì— ì‚¬ìš©ëœ íšŒë¡œ ëª©ë¡ì…ë‹ˆë‹¤ (ì„ íƒ ì‚¬í•­).
        
    Returns:
        Dict: ì €ì¥ëœ íŒŒì¼ ê²½ë¡œ ë“± ê²°ê³¼ ì •ë³´ë¥¼ ë‹´ì€ ë”•ì…”ë„ˆë¦¬ì…ë‹ˆë‹¤.
    """
    print("\nğŸ’¾ ì‹¤í—˜ ê²°ê³¼ ì €ì¥ ì¤‘...")
    
    # ë¹ˆ ê²°ê³¼ ì²´í¬
    if not all_results:
        print("âš ï¸ ì €ì¥í•  ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return {"error": "No results to save"}
    
    # íŒŒì¼ëª…ì— ì‚¬ìš©ë  í˜„ì¬ ì‹œê° íƒ€ì„ìŠ¤íƒ¬í”„ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    
    # ê²°ê³¼ íŒŒì¼ì„ ì €ì¥í•  ë””ë ‰í† ë¦¬ë¥¼ í™•ì¸í•˜ê³ , ì—†ìœ¼ë©´ ìƒì„±í•©ë‹ˆë‹¤.
    results_dir = "experiments/results"
    os.makedirs(results_dir, exist_ok=True)
    
    # ê²°ê³¼ ë°ì´í„° êµ¬ì¡°ë¥¼ ì¤€ë¹„í•©ë‹ˆë‹¤.
    result_data = {
        "experiment_type": "mega_job",
        "timestamp": timestamp,
        "circuit_count": len(all_results),
        "results": all_results
    }
    
    if training_circuits:
        result_data["training_circuits"] = training_circuits
    
    # ëª¨ë“  ê²°ê³¼ ë°ì´í„°ë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.
    file_prefix = config.get('experiment_file_prefix', 'mega_job')
    json_filename = f"{results_dir}/{file_prefix}_results_{timestamp}.json"
    try:
        # JSON ì§ë ¬í™” ê°€ëŠ¥í•œ í˜•íƒœë¡œ ë³€í™˜
        serializable_data = make_json_serializable(result_data)
        with open(json_filename, 'w') as f:
            json.dump(serializable_data, f, indent=2)
        print(f"   JSON íŒŒì¼ë¡œ ì €ì¥ ì™„ë£Œ: {json_filename}")
    except Exception as e:
        print(f"âš ï¸ JSON ì €ì¥ ì‹¤íŒ¨: {str(e)}")
    
    # ì£¼ìš” ê²°ê³¼ ì§€í‘œë¥¼ ìš”ì•½í•˜ì—¬ CSV íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.
    try:
        summary_list = []
        for result in all_results:
            # ì•ˆì „í•œ ê°’ ì¶”ì¶œ í•¨ìˆ˜
            def safe_get(obj, key, default=None):
                if isinstance(obj, dict):
                    return obj.get(key, default)
                elif hasattr(obj, key):
                    return getattr(obj, key, default)
                else:
                    return default
            
            # ìƒˆë¡œìš´ ê²°ê³¼ êµ¬ì¡°ì—ì„œ ì •ë³´ ì¶”ì¶œ
            fidelity = result.get("fidelity")
            expressibility = result.get("expressibility")
            additional_metrics = result.get("additional_metrics", {})
            
            # CSVì— ì €ì¥í•  ì£¼ìš” íšŒë¡œ ì •ë³´ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
            row = {
                "circuit_index": result.get("circuit_index", -1),
                "config_group": result.get("config_group", ""),
                "n_qubits": result.get("n_qubits", 0),
                "depth": result.get("depth", 0) or safe_get(additional_metrics, "depth", 0),
                "two_qubit_ratio_target": result.get("two_qubit_ratio_target", 0),
            }
            
            # í”¼ë¸ë¦¬í‹° ê°’ ì•ˆì „í•˜ê²Œ ì¶”ì¶œ
            if isinstance(fidelity, dict):
                row["zero_state_prob"] = fidelity.get("simple", 0)
                row["robust_fidelity"] = fidelity.get("robust", 0)
                row["fidelity_method"] = fidelity.get("method", "unknown")
            elif isinstance(fidelity, (int, float)):
                row["zero_state_prob"] = fidelity
                row["robust_fidelity"] = fidelity
                row["fidelity_method"] = "simple_value"
            else:
                row["zero_state_prob"] = 0
                row["robust_fidelity"] = 0
                row["fidelity_method"] = "unknown"
            
            # í‘œí˜„ë ¥ ì§€í‘œ ì¶”ê°€
            if isinstance(expressibility, dict):
                # ê¸°ë³¸ í‘œí˜„ë ¥ ê°’
                row["expressibility_score"] = expressibility.get("value", None)
                row["expressibility_method"] = expressibility.get("method", "unknown")
                row["distance_from_haar"] = expressibility.get("distance_from_haar", 1.0)
                
                # ì¶”ê°€ì ì¸ í‘œí˜„ë ¥ ì¸¡ì • ì§€í‘œë“¤ì´ ìˆë‹¤ë©´ ì¶”ê°€
                for metric_name, value in expressibility.items():
                    if metric_name not in ["value", "method", "distance_from_haar"]:
                        if isinstance(value, (int, float, str, bool)):
                            row[f"expressibility_{metric_name}"] = value
            elif isinstance(expressibility, (int, float)):
                row["expressibility_score"] = expressibility
                row["expressibility_method"] = "simple_value"
                row["distance_from_haar"] = 1.0
            else:
                row["expressibility_score"] = None
                row["expressibility_method"] = "unknown"
                row["distance_from_haar"] = 1.0
            
            summary_list.append(row)
        
        # ì¶”ì¶œëœ ìš”ì•½ ì •ë³´ë¥¼ Pandas DataFrameìœ¼ë¡œ ë³€í™˜í•˜ì—¬ CSV íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.
        if summary_list:
            df = pd.DataFrame(summary_list)
            csv_filename = f"{results_dir}/{file_prefix}_summary_{timestamp}.csv"
            df.to_csv(csv_filename, index=False)
            print(f"   CSV ìš”ì•½ ì €ì¥ ì™„ë£Œ: {csv_filename}")
        
    except Exception as e:
        print(f"âš ï¸ CSV ìš”ì•½ ì €ì¥ ì‹¤íŒ¨: {str(e)}")
        print(f"   ì˜¤ë¥˜ ì„¸ë¶€ì‚¬í•­: {type(e).__name__}")
    
    # íŠ¸ëœìŠ¤í¬ë¨¸ ì¹œí™”ì  í˜•ì‹ìœ¼ë¡œ ì €ì¥
    try:
        transformer_data = create_transformer_friendly_format(all_results)
        transformer_filename = f"{results_dir}/{file_prefix}_transformer_{timestamp}.json"
        with open(transformer_filename, 'w') as f:
            json.dump(transformer_data, f, indent=2)
        print(f"   íŠ¸ëœìŠ¤í¬ë¨¸ í˜•ì‹ ì €ì¥ ì™„ë£Œ: {transformer_filename}")
    except Exception as e:
        print(f"âš ï¸ íŠ¸ëœìŠ¤í¬ë¨¸ í˜•ì‹ ì €ì¥ ì‹¤íŒ¨: {str(e)}")
    
    # HDF5 ì €ì¥ (ê°„ì†Œí™”ëœ ë²„ì „)
    try:
        if summary_list:  # CSV ë°ì´í„°ê°€ ì„±ê³µì ìœ¼ë¡œ ìƒì„±ëœ ê²½ìš°ë§Œ
            df = pd.DataFrame(summary_list)
            hdf5_filename = f"{results_dir}/{file_prefix}_data_{timestamp}.h5"
            df.to_hdf(hdf5_filename, key='circuit_data', mode='w')
            print(f"   HDF5 ë°ì´í„° ì €ì¥ ì™„ë£Œ: {hdf5_filename}")
    except Exception as e:
        print(f"âš ï¸ HDF5 ì €ì¥ ì‹¤íŒ¨: {str(e)}")
    
    return {
        "timestamp": timestamp,
        "json_file": json_filename,
        "csv_file": f"{results_dir}/{file_prefix}_summary_{timestamp}.csv",
        "hdf5_file": f"{results_dir}/{file_prefix}_data_{timestamp}.h5",
        "transformer_file": f"{results_dir}/{file_prefix}_transformer_{timestamp}.json"
    }


def create_transformer_friendly_format(all_results):
    """
    íŠ¸ëœìŠ¤í¬ë¨¸ ëª¨ë¸ í›ˆë ¨ì— ì í•©í•œ í˜•ì‹ìœ¼ë¡œ ë°ì´í„° ë³€í™˜
    """
    transformer_data = []
    
    for result in all_results:
        try:
            # ê¸°ë³¸ íšŒë¡œ ë©”íƒ€ë°ì´í„°
            circuit_record = {
                "circuit_id": result.get("circuit_index", -1),
                "n_qubits": result.get("n_qubits", 4),
                "depth": result.get("depth", 1),
                "two_qubit_ratio": result.get("two_qubit_ratio_target", 0.0),
            }
            
            # íšŒë¡œ í† í°í™” (ê²Œì´íŠ¸ ì‹œí€€ìŠ¤) - ìµœìƒìœ„ ë ˆë²¨ì—ì„œ ì¶”ì¶œ
            gates = result.get("gates", [])
            wires_list = result.get("wires_list", [])
            params = result.get("params", [])
            
            # ê°„ë‹¨í•œ í† í°í™”: gate_type:qubit_indices í˜•ì‹
            circuit_tokens = []
            for i, gate in enumerate(gates):
                if i < len(wires_list):
                    wires = wires_list[i]
                    if isinstance(wires, list):
                        wire_str = "_".join(map(str, wires))
                    else:
                        wire_str = str(wires)
                    token = f"{gate}:{wire_str}"
                    circuit_tokens.append(token)
            
            circuit_record["circuit_tokens"] = circuit_tokens
            circuit_record["circuit_sequence"] = " ".join(circuit_tokens)
            
            # íƒ€ê²Ÿ ë ˆì´ë¸” (íšŒê·€ ì˜ˆì¸¡ìš©)
            fidelity = result.get("fidelity")
            expressibility = result.get("expressibility")
            
            # í”¼ë¸ë¦¬í‹° ê°’ ì¶”ì¶œ
            if isinstance(fidelity, dict):
                circuit_record["target_fidelity"] = fidelity.get("simple", 0.0)
            elif isinstance(fidelity, (int, float)):
                circuit_record["target_fidelity"] = float(fidelity)
            else:
                circuit_record["target_fidelity"] = 0.0
            
            # í‘œí˜„ë ¥ ê°’ ì¶”ì¶œ
            if isinstance(expressibility, dict):
                circuit_record["target_expressibility"] = expressibility.get("value", 0.0)
            elif isinstance(expressibility, (int, float)):
                circuit_record["target_expressibility"] = float(expressibility)
            else:
                circuit_record["target_expressibility"] = 0.0
            
            # 2íë¹— ê²Œì´íŠ¸ ë¹„ìœ¨ ê³„ì‚°
            two_qubit_gates = sum(1 for gate in gates if gate.lower() in ['cx', 'cy', 'cz', 'cnot'])
            total_gates = len(gates)
            actual_two_qubit_ratio = two_qubit_gates / max(total_gates, 1)
            circuit_record["actual_two_qubit_ratio"] = actual_two_qubit_ratio
            
            transformer_data.append(circuit_record)
            
        except Exception as e:
            print(f"âš ï¸ íšŒë¡œ {result.get('circuit_index', 'unknown')} íŠ¸ëœìŠ¤í¬ë¨¸ í˜•ì‹ ë³€í™˜ ì‹¤íŒ¨: {e}")
            continue
    
    return {
        "format": "transformer_friendly",
        "description": "Circuit data formatted for transformer model training",
        "total_circuits": len(transformer_data),
        "features": [
            "circuit_id", "n_qubits", "depth", "two_qubit_ratio", 
            "circuit_tokens", "circuit_sequence"
        ],
        "targets": [
            "target_fidelity", "target_expressibility", "actual_two_qubit_ratio"
        ],
        "data": transformer_data
    }


def analyze_two_qubit_ratio_results(all_results):
    """
    2íë¹— ê²Œì´íŠ¸ ë¹„ìœ¨ì— ë”°ë¥¸ ì‹¤í—˜ ê²°ê³¼ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.
    
    Args:
        all_results (List[Dict]): `process_mega_results` í•¨ìˆ˜ì—ì„œ ë°˜í™˜ëœ ì²˜ë¦¬ëœ ê²°ê³¼ ëª©ë¡ì…ë‹ˆë‹¤.
        
    Returns:
        pd.DataFrame: ë¶„ì„ ê²°ê³¼ë¥¼ ë‹´ì€ Pandas DataFrameì…ë‹ˆë‹¤.
    """
    print("\nğŸ“Š 2íë¹— ê²Œì´íŠ¸ ë¹„ìœ¨ë³„ ê²°ê³¼ ë¶„ì„ ì¤‘...")
    
    # DataFrame ìƒì„±ì„ ìœ„í•´ ë¶„ì„ì— í•„ìš”í•œ ë°ì´í„°ë¥¼ ê²°ê³¼ ëª©ë¡ì—ì„œ ì¶”ì¶œí•©ë‹ˆë‹¤.
    analysis_data = []
    
    for result in all_results:
        try:
            # ìƒˆë¡œìš´ ê²°ê³¼ êµ¬ì¡°ì—ì„œ ì •ë³´ ì¶”ì¶œ
            fidelity = result.get("fidelity", {})
            expressibility = result.get("expressibility", {})
            additional_metrics = result.get("additional_metrics", {})
            
            # í•µì‹¬ ë©”íŠ¸ë¦­(ì§€í‘œ)ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
            row = {
                "circuit_index": result.get("circuit_index", -1),
                "config_group": result.get("config_group", ""),
                "n_qubits": result.get("n_qubits", 0),
                "depth": result.get("depth", 0) or additional_metrics.get("depth", 0),
                "two_qubit_ratio_target": result.get("two_qubit_ratio_target", 0),
                "zero_state_prob": fidelity.get("simple", 0),
                "robust_fidelity": fidelity.get("robust", 0),
                "fidelity_method": fidelity.get("method", "unknown")
            }
            
            # í‘œí˜„ë ¥ ì§€í‘œ ì¶”ê°€
            if isinstance(expressibility, dict):
                # ê¸°ë³¸ í‘œí˜„ë ¥ ê°’
                row["expressibility_score"] = expressibility.get("value", None)
                row["expressibility_method"] = expressibility.get("method", "unknown")
                row["distance_from_haar"] = expressibility.get("distance_from_haar", 1.0)
                
                # ì¶”ê°€ì ì¸ í‘œí˜„ë ¥ ì¸¡ì • ì§€í‘œë“¤ì´ ìˆë‹¤ë©´ ì¶”ê°€
                for metric_name, value in expressibility.items():
                    if metric_name not in ["value", "method", "distance_from_haar"]:
                        row[f"expressibility_{metric_name}"] = value
            
            analysis_data.append(row)
            
        except Exception as e:
            continue
    
    if not analysis_data:
        print("âš ï¸ ë¶„ì„í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return None
    
    # ì¶”ì¶œëœ ë¶„ì„ìš© ë°ì´í„°ë¡œ Pandas DataFrameì„ ìƒì„±í•©ë‹ˆë‹¤.
    df = pd.DataFrame(analysis_data)
    
    # íë¹— ìˆ˜, íšŒë¡œ ê¹Šì´, 2íë¹— ê²Œì´íŠ¸ ë¹„ìœ¨ë³„ë¡œ ê·¸ë£¹í™”í•˜ì—¬ í†µê³„ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
    print("\nğŸ“ˆ 2íë¹— ê²Œì´íŠ¸ ë¹„ìœ¨ë³„ í”¼ë¸ë¦¬í‹° ë° í‘œí˜„ë ¥ ë¶„ì„:")
    
    try:
        # ê·¸ë£¹ë³„ í†µê³„ (ì¶”ê°€ í‘œí˜„ë ¥ ë©”íŠ¸ë¦­ í¬í•¨)
        metric_columns = ['zero_state_prob', 'robust_fidelity', 'expressibility_score', 'expressibility_entropy']
        
        # DataFrameì— ë™ì ìœ¼ë¡œ ì¶”ê°€ëœ í‘œí˜„ë ¥ ë©”íŠ¸ë¦­ ì»¬ëŸ¼ë“¤ì„ ì°¾ìŠµë‹ˆë‹¤.
        distance_metrics_columns = [col for col in df.columns if col.startswith('expressibility_') 
                                   and col not in ['expressibility_score', 'expressibility_entropy']]
        if distance_metrics_columns:
            metric_columns.extend(distance_metrics_columns)
        
        # ê° ë©”íŠ¸ë¦­ë³„ë¡œ ì–´ë–¤ í†µê³„ í•¨ìˆ˜(í‰ê· , í‘œì¤€í¸ì°¨ ë“±)ë¥¼ ì ìš©í• ì§€ ì •ì˜í•©ë‹ˆë‹¤.
        agg_dict = {}
        for col in metric_columns:
            if col == 'zero_state_prob':
                agg_dict[col] = ['mean', 'std', 'count']
            else:
                agg_dict[col] = ['mean', 'std']
        
        grouped = df.groupby(['n_qubits', 'depth', 'two_qubit_ratio_target']).agg(agg_dict)
        
        # Pandas DataFrame ì¶œë ¥ í˜•ì‹ì„ ì„¤ì •í•©ë‹ˆë‹¤.
        pd.set_option('display.max_rows', None)
        pd.set_option('display.width', 120)
        pd.set_option('display.precision', 4)
        
        print("\nğŸ” ê·¸ë£¹ë³„ ì„±ëŠ¥ í†µê³„:")
        print(grouped)
        
        # ë³´ê³ ì„œ íŒŒì¼ëª…ì— ì‚¬ìš©ë  í˜„ì¬ ì‹œê° íƒ€ì„ìŠ¤íƒ¬í”„ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        
        # ë¶„ì„ ë³´ê³ ì„œë¥¼ ì €ì¥í•  ë””ë ‰í† ë¦¬ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.
        report_dir = "reports"
        os.makedirs(report_dir, exist_ok=True)
        
        # ë¶„ì„ ê²°ê³¼ë¥¼ CSV íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.
        csv_filename = f"{report_dir}/two_qubit_ratio_analysis_{timestamp}.csv"
        grouped.to_csv(csv_filename)
        print(f"\nâœ… ë¶„ì„ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {csv_filename}")
        
    except Exception as e:
        print(f"âš ï¸ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
    
    return df
