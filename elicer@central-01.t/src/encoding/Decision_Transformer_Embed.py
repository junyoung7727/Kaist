import os
import sys
import csv
import time
import math
from datetime import datetime
from typing import Dict, List, Any, Tuple, Optional

# ì¨ë“œíŒŒí‹° ë¼ì´ë¸ŒëŸ¬ë¦¬
import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
# Add quantumcommon to path
import sys
from src.models.decision_transformer import DebugMode
from pathlib import Path
sys.path.append(str(Path(__file__).parent.parent.parent.parent / "quantumcommon"))

from gates import QuantumGateRegistry

class ActionTargetBuilder:
    """ ì•¡ì…˜ íƒ€ê²Ÿ ìƒì„± ì „ìš© í´ë˜ìŠ¤ - ë‹¨ì¼ ì±…ì„ ì›ì¹™"""
    
    @staticmethod
    def build_from_grid(grid_matrix_data, batch_size: int) -> Dict[str, torch.Tensor]:
        """ê·¸ë¦¬ë“œ ë§¤íŠ¸ë¦­ìŠ¤ ë°ì´í„°ë¡œë¶€í„° ì•¡ì…˜ íƒ€ê²Ÿ ìƒì„±"""
        if 'gates' not in grid_matrix_data:
            return ActionTargetBuilder._create_empty_targets(batch_size, 0)
        
        gates = grid_matrix_data['gates']
        num_gates = len(gates)
        
        # ë²¡í„°í™”ëœ íƒ€ê²Ÿ ìƒì„± (ë‹¨ì¼ ìƒ˜í”Œìš©)
        gate_targets = torch.zeros(num_gates, dtype=torch.long)
        # ğŸ”§ NEW: 2íë¹— ê²Œì´íŠ¸ ì „ìš© í˜•íƒœë¡œ ë³€ê²½ [qubit1, qubit2]
        position_targets = torch.full((num_gates, 2), -1, dtype=torch.long)
        parameter_targets = torch.zeros(num_gates, dtype=torch.float)
        
        # ê° ê²Œì´íŠ¸ë³„ë¡œ íƒ€ê²Ÿ ìƒì„± (ë°°ì¹˜ëŠ” í˜„ì¬ 1ê°œë§Œ ì²˜ë¦¬)
        for gate_idx, gate in enumerate(gates):
            if isinstance(gate, dict):
                # ê²Œì´íŠ¸ íƒ€ì… ì„¤ì •
                if 'gate_index' in gate:
                    gate_id = gate['gate_index']
                    if 0 <= gate_id < 20:  # ìœ íš¨í•œ ê²Œì´íŠ¸ë§Œ (EOS/PAD ì œì™¸)
                        gate_targets[gate_idx] = gate_id
                
                # íë¹— ìœ„ì¹˜ ì„¤ì • - 2íë¹— í˜•íƒœ ì§€ì›
                if 'qubits' in gate and gate['qubits'] is not None:
                    qubits = gate['qubits']
                    if isinstance(qubits, list) and len(qubits) > 0:
                        # ì²« ë²ˆì§¸ íë¹— ì„¤ì •
                        if len(qubits) >= 1 and qubits[0] >= 0:
                            position_targets[gate_idx, 0] = qubits[0]
                        
                        # ë‘ ë²ˆì§¸ íë¹— ì„¤ì •
                        if len(qubits) >= 2 and qubits[1] >= 0:
                            position_targets[gate_idx, 1] = qubits[1]
                        elif len(qubits) == 1 and qubits[0] >= 0:
                            # 1íë¹— ê²Œì´íŠ¸ì˜ ê²½ìš°: ê°™ì€ íë¹—ì„ ë‘ ë²ˆ ì‚¬ìš©
                            position_targets[gate_idx, 1] = qubits[0]
                
                # íŒŒë¼ë¯¸í„° ì„¤ì • (ê·¸ë¦¬ë“œ ë°ì´í„°ì—ì„œ ì§ì ‘ ì¶”ì¶œ)
                if 'parameter_value' in gate and gate['parameter_value'] is not None:
                    param_val = gate['parameter_value']
                    if not (isinstance(param_val, float) and math.isnan(param_val)):
                        parameter_targets[gate_idx] = float(param_val)

        
        return {
            'gate_targets': gate_targets,
            'position_targets': position_targets,
            'parameter_targets': parameter_targets
        }
    
    @staticmethod
    def _create_empty_targets(batch_size: int, num_gates: int) -> Dict[str, torch.Tensor]:
        """ë¹ˆ íƒ€ê²Ÿ ìƒì„± (íŒ¨ë”©ìš©)"""
        return {
            'gate_targets': torch.zeros(num_gates, dtype=torch.long),
            'position_targets': torch.full((num_gates, 2), -1, dtype=torch.long),  # ğŸ”§ 2íë¹— í˜•íƒœë¡œ ë³€ê²½
            'parameter_targets': torch.zeros(num_gates, dtype=torch.float)
        }

class QuantumGateSequenceEmbedding(nn.Module):
    def __init__(self, d_model: int, n_gate_types: int, n_qubits: int, 
                 max_seq_len: int = 1024, grid_size: Tuple[int, int] = (8, 8)):
        super().__init__()
        self.d_model = d_model
        self.n_gate_types = n_gate_types
        self.n_qubits = n_qubits
        self.max_seq_len = max_seq_len
        self.grid_width, self.grid_height = grid_size
        
        # ì„ë² ë”© ë ˆì´ì–´ë“¤ (ì¤‘ìš”ë„ë³„ ì°¨ì› ë°°ë¶„)
        # ì¤‘ìš”ë„: gate_type > role > occupation > parameter
        gate_dim = d_model // 2      # 50% - ê°€ì¥ ì¤‘ìš” (H, X, CNOT, RZ ë“±)
        param_dim = d_model // 4      # 25% - ë‘ë²ˆì§¸ ì¤‘ìš” (íŒŒë¼ë¯¸í„°í„° êµ¬ë¶„)
        occupation_dim = d_model // 16  # 6.25% - ì„¸ë²ˆì§¸ ì¤‘ìš” (ì ìœ  ì—¬ë¶€)
        role_dim = d_model - gate_dim - param_dim - occupation_dim  # ë‚˜ë¨¸ì§€ 18.75%
        
        self.gate_type_embed = nn.Embedding(n_gate_types, gate_dim)   # ê²Œì´íŠ¸ íƒ€ì… ID (ê°€ì¥ ì¤‘ìš”)
        self.role_embed = nn.Embedding(4, role_dim)                   # ì—­í•  (control/target)
        self.occupation_embed = nn.Embedding(2, occupation_dim)       # ì ìœ  ìƒíƒœ
        self.param_embed = nn.Linear(1, param_dim)                    # ê²Œì´íŠ¸ íŒŒë¼ë¯¸í„°
        
        # ìœ„ì¹˜ ì¸ì½”ë”© (í•™ìŠµ ê°€ëŠ¥í•œ ì„ë² ë”©)
        self.positional_encoding = nn.Embedding(max_seq_len, d_model)
        
        # EOS (End-of-Sequence) íŠ¹ìˆ˜ í† í°
        self.eos_embed = nn.Parameter(torch.randn(d_model))            # íë¹— ì¸ë±ìŠ¤
        self.grid_position_embed = nn.Linear(2, d_model)              # (x, y) ì¢Œí‘œ
        
        # Decision Transformer ì»´í¬ë„ŒíŠ¸ë“¤
        self.state_embed = nn.Linear(d_model, d_model)     # ìƒíƒœ ì„ë² ë”©
        self.action_embed = nn.Linear(d_model, d_model)    # ì•¡ì…˜ ì„ë² ë”©  
        self.reward_embed = nn.Linear(1, d_model)          # ë¦¬ì›Œë“œ ì„ë² ë”©
        self.return_embed = nn.Linear(1, d_model)          # Return-to-go ì„ë² ë”©
        
        # ì‹œí€€ìŠ¤ íƒ€ì… ì„ë² ë”© (state/action/reward êµ¬ë¶„)
        self.type_embed = nn.Embedding(4, d_model)  # 0=state, 1=action, 2=reward, 3=return
        
        # ìœ„ì¹˜ ì¸ì½”ë”©
        self.register_buffer('pos_embed', self._create_positional_encoding())
        
        # ì •ê·œí™”
        self.layer_norm = nn.LayerNorm(d_model)
        self.dropout = nn.Dropout(0.1)
    
    def _create_positional_encoding(self) -> torch.Tensor:
        """ì˜¬ë°”ë¥¸ ìœ„ì¹˜ ì¸ì½”ë”© ìƒì„±"""
        pe = torch.zeros(self.max_seq_len, self.d_model)
        position = torch.arange(0, self.max_seq_len, dtype=torch.float).unsqueeze(1)
        
        div_term = torch.exp(torch.arange(0, self.d_model, 2).float() * 
                           (-math.log(10000.0) / self.d_model))
        
        pe[:, 0::2] = torch.sin(position * div_term)
        pe[:, 1::2] = torch.cos(position * div_term)
        
        return pe.unsqueeze(0)  # [1, max_seq_len, d_model]
    
    def mask(self, x: torch.Tensor) -> torch.Tensor:
        """
        ì‹œí€€ìŠ¤ì— ì–´í…ì…˜ì„ ì ìš©í•  ë•Œ, ìê¸°ë³´ë‹¤ ì´í›„ ìŠ¤í…Œì´íŠ¸ì˜ ê²Œì´íŠ¸ ë°°ì¹˜ë¥¼ ê°€ë¦¼
        
        Args:
            x: ì…ë ¥ ì‹œí€€ìŠ¤ [batch_size, seq_len, hidden_dim]
        
        Returns:
            mask: ì–´í…ì…˜ ë§ˆìŠ¤í¬ [seq_len, seq_len] (bool)
        """
        seq_len = x.size(1)
        
        # í•˜ì‚¼ê° ë§ˆìŠ¤í¬ ìƒì„± (causal mask)
        mask = torch.tril(torch.ones(seq_len, seq_len, device=x.device, dtype=torch.bool))
        
        # 0ì€ ë§ˆìŠ¤í‚¹, 1ì€ ì–´í…ì…˜ í—ˆìš©
        # Decision Transformerì—ì„œëŠ” í˜„ì¬ì™€ ì´ì „ íƒ€ì„ìŠ¤í…ë§Œ ì°¸ì¡° ê°€ëŠ¥
        return mask

    def state(self, x: torch.Tensor, gate_type_indices: torch.Tensor = None, role_indices: torch.Tensor = None) -> torch.Tensor:
        """
        ì—í”¼ì†Œë“œ ì‹œí€€ìŠ¤ì— ëŒ€í•œ ìƒíƒœ ì„ë² ë”©
        
        Args:
            x: ì—í”¼ì†Œë“œ ì‹œí€€ìŠ¤ [episode_time_len, features]
            gate_type_indices: Long íƒ€ì… ê²Œì´íŠ¸ íƒ€ì… ì¸ë±ìŠ¤ [episode_time_len]
            role_indices: Long íƒ€ì… ì—­í•  ì¸ë±ìŠ¤ [episode_time_len]
        
        Returns:
            state: ì¸ì½”ë”©ëœ ìƒíƒœ [episode_time_len, d_model]
        """
        # ğŸ” CRITICAL FIX: x ì°¨ì› ë™ì  ì²˜ë¦¬
        device = x.device
        
        # ì°¨ì›ì— ë”°ë¥¸ ë™ì  ì²˜ë¦¬
        if x.dim() == 2:
            episode_time_len, features = x.shape
        elif x.dim() == 3:
            # [batch_or_time, episode_time_len_or_qubits, features] í˜•íƒœ
            # ì‹¤ì œë¡œëŠ” [time_steps, num_qubits, features] í˜•íƒœì¼ ê°€ëŠ¥ì„±
            batch_or_time, episode_or_qubits, features = x.shape
            
            # 3D í…ì„œë¥¼ 2Dë¡œ flatten
            x = x.view(-1, features)  # [batch_or_time * episode_or_qubits, features]
            episode_time_len, features = x.shape
        else:
            raise ValueError(f"Unsupported tensor dimensions in state method: {x.shape}")
        
        # ìœ„ì¹˜ ì¸ë±ìŠ¤ ìƒì„±
        position_indices = torch.arange(episode_time_len, device=device).long()
        position_emb = self.positional_encoding(position_indices)  # [episode_time_len, d_model]
        
        # ìƒíƒœ ì¸ì½”ë”© (ê° í”¼ì²˜ë¥¼ ê°œë³„ë¡œ ì„ë² ë”©)
        if features == 4:  # [gate_type_id, role_id, occupation, parameter_value]
            # ì´ë¯¸ ì •ìˆ˜ íƒ€ì…ì¸ ê°’ë“¤ì„ embedding ì¸ë±ìŠ¤ë¡œ ì‚¬ìš©
            gate_type_ids = x[:, 0].long()      # [episode_time_len]
            role_ids = x[:, 1].long()           # [episode_time_len]
            occupation = x[:, 2].long()         # [episode_time_len]
            parameters = x[:, 3:4]              # [episode_time_len, 1]
            
            # ê°ê° ì„ë² ë”©
            gate_embedded = self.gate_type_embed(gate_type_ids)        # [episode_time_len, embed_dim]
            role_embedded = self.role_embed(role_ids)                  # [episode_time_len, embed_dim]
            occupation_embedded = self.occupation_embed(occupation)    # [episode_time_len, embed_dim]
            param_embedded = self.param_embed(parameters)              # [episode_time_len, embed_dim]
            
            # ì„ë² ë”© ê²°í•© (concatenation)
            state_encoded = torch.cat([
                gate_embedded, 
                role_embedded, 
                occupation_embedded, 
                param_embedded
            ], dim=-1)  # [episode_time_len, d_model]
        
        # ìœ„ì¹˜ ì„ë² ë”©ê³¼ ê²°í•©
        state = state_encoded + position_emb  # [episode_time_len, d_model]
        
        return state

    def action(self, episode_sequence: torch.Tensor, current_episode_time: int) -> torch.Tensor:
        """
        íŠ¹ì • ì—í”¼ì†Œë“œíƒ€ì„ì—ì„œì˜ ì•¡ì…˜ ìƒì„± (ë‹¤ìŒ ì—í”¼ì†Œë“œíƒ€ì„ì˜ ê²Œì´íŠ¸)
        ë¯¸ë˜ ì•¡ì…˜ì— ëŒ€í•œ ë§ˆìŠ¤í‚¹ í¬í•¨
        
        Args:
            episode_sequence: [episode_time_len, features] - ì „ì²´ ì—í”¼ì†Œë“œ ì‹œí€€ìŠ¤
            current_episode_time: í˜„ì¬ ì—í”¼ì†Œë“œíƒ€ì„ ì¸ë±ìŠ¤
        
        Returns:
            action: í˜„ì¬ ì—í”¼ì†Œë“œíƒ€ì„ì—ì„œì˜ ì•¡ì…˜ [d_model]
        """
        # ğŸ” CRITICAL FIX: episode_sequence ì°¨ì› ë™ì  ì²˜ë¦¬
        device = episode_sequence.device
        
        # ì°¨ì›ì— ë”°ë¥¸ ë™ì  ì²˜ë¦¬
        if episode_sequence.dim() == 2:
            episode_time_len, features = episode_sequence.shape
        elif episode_sequence.dim() == 3:
            # [batch_or_time, episode_time_len_or_qubits, features] í˜•íƒœ
            # 3D í…ì„œë¥¼ 2Dë¡œ flatten
            batch_or_time, episode_or_qubits, features = episode_sequence.shape
            episode_sequence = episode_sequence.view(-1, features)  # [batch_or_time * episode_or_qubits, features]
            episode_time_len, features = episode_sequence.shape
        else:
            raise ValueError(f"Unsupported tensor dimensions in action method: {episode_sequence.shape}")
        
        if current_episode_time < episode_time_len - 1:
            # ë‹¤ìŒ ì—í”¼ì†Œë“œíƒ€ì„ì˜ ê²Œì´íŠ¸ë¥¼ ì•¡ì…˜ìœ¼ë¡œ ì‚¬ìš© (ë§ˆìŠ¤í‚¹ ì—†ìŒ)
            next_gate = episode_sequence[current_episode_time + 1].unsqueeze(0).unsqueeze(0)  # [1, 1, features]
            action_embedded = self._embed_episode_features(next_gate)  # [1, 1, d_model]
            action = self.action_embed(action_embedded).squeeze(0).squeeze(0)  # [d_model]
        else:
            # ë§ˆì§€ë§‰ ì—í”¼ì†Œë“œíƒ€ì„: ë¹„ì–´ìˆëŠ” ì•¡ì…˜ (ë§ˆìŠ¤í‚¹)
            action = torch.zeros(self.d_model, device=device)
        
        return action
    
    def _embed_episode_features(self, episode_features: torch.Tensor) -> torch.Tensor:
        """
        ì—í”¼ì†Œë“œíƒ€ì„ ìˆœì„œì˜ í”¼ì²˜ë¥¼ ì„ë² ë”©
        
        Args:
            episode_features: [batch, episode_time_len, features]
        
        Returns:
            embedded: [batch, episode_time_len, d_model]
        """
        batch_size, episode_time_len, features = episode_features.shape
        
        if features == 4:  # [gate_type_id, role_id, occupation, parameter_value]
            # ê° í”¼ì²˜ ì¶”ì¶œ
            gate_type_ids = episode_features[:, :, 0].long()      # ê²Œì´íŠ¸ íƒ€ì… ID
            role_ids = episode_features[:, :, 1].long()           # ì—­í•  ID
            occupation = episode_features[:, :, 2].long()         # ì ìœ  ìƒíƒœ
            parameters = episode_features[:, :, 3:4]              # íŒŒë¼ë¯¸í„° ê°’
            
            # ê°ê° ì„ë² ë”© (ì°¨ì› ë¶„í• )
            gate_embedded = self.gate_type_embed(gate_type_ids)        # [batch, episode_time, gate_dim]
            role_embedded = self.role_embed(role_ids)                  # [batch, episode_time, role_dim]
            occupation_embedded = self.occupation_embed(occupation)    # [batch, episode_time, occupation_dim]
            param_embedded = self.param_embed(parameters)              # [batch, episode_time, param_dim]
            
            # ì„ë² ë”© ê²°í•© (concatenation)
            embedded = torch.cat([
                gate_embedded, 
                role_embedded, 
                occupation_embedded, 
                param_embedded
            ], dim=-1)  # [batch, episode_time, d_model]
        else:
            # ë‹¤ë¥¸ í”¼ì²˜ ì°¨ì›ì˜ ê²½ìš° ì„ í˜• ë³€í™˜
            linear_layer = nn.Linear(features, self.d_model).to(episode_features.device)
            embedded = linear_layer(episode_features)
        
        return embedded

    def reward(self, masked_state: torch.Tensor, action: torch.Tensor, current_episode_time: int, episode_time_len: int) -> torch.Tensor:
        """
        íŠ¹ì • ì—í”¼ì†Œë“œíƒ€ì„ì—ì„œì˜ ë¦¬ì›Œë“œ ìƒì„±
        ë¯¸ë˜ ë¦¬ì›Œë“œì— ëŒ€í•œ ë§ˆìŠ¤í‚¹ í¬í•¨
        
        Args:
            masked_state: í˜„ì¬ ì—í”¼ì†Œë“œíƒ€ì„ì—ì„œì˜ ë§ˆìŠ¤í‚¹ ìƒíƒœ [d_model]
            action: í˜„ì¬ ì—í”¼ì†Œë“œíƒ€ì„ì—ì„œì˜ ì•¡ì…˜ [d_model]
            current_episode_time: í˜„ì¬ ì—í”¼ì†Œë“œíƒ€ì„ ì¸ë±ìŠ¤
            episode_time_len: ì „ì²´ ì—í”¼ì†Œë“œ ì‹œê°„ ê¸¸ì´
        
        Returns:
            reward: í˜„ì¬ ì—í”¼ì†Œë“œíƒ€ì„ì—ì„œì˜ ë¦¬ì›Œë“œ [d_model]
        """
        device = masked_state.device
        
        # ë¯¸ë˜ ë¦¬ì›Œë“œ ë§ˆìŠ¤í‚¹: í˜„ì¬ ì‹œì ì—ì„œë§Œ ë¦¬ì›Œë“œ ê³„ì‚° ê°€ëŠ¥
        if current_episode_time < episode_time_len:
            # ìƒíƒœ-ì•¡ì…˜ ìŒì—ì„œ ë¦¬ì›Œë“œ ê³„ì‚°
            state_action = torch.cat([masked_state, action], dim=0)  # [2*d_model]
            
            # ë¦¬ì›Œë“œ ê³„ì‚° (ì‹¤ì œë¡œëŠ” íšŒë¡œ í’ˆì§ˆ ë©”íŠ¸ë¦­ ê¸°ë°˜)
            reward_scalar = torch.norm(state_action, dim=0, keepdim=True)  # [1]
            reward_normalized = torch.sigmoid(reward_scalar)  # [0, 1] ë²”ìœ„ë¡œ ì •ê·œí™”
            
            # ë¦¬ì›Œë“œë¥¼ d_model ì°¨ì›ìœ¼ë¡œ ì„ë² ë”©
            reward_embed_layer = nn.Linear(1, self.d_model).to(device)
            reward = reward_embed_layer(reward_normalized.unsqueeze(0)).squeeze(0)  # [d_model]
        else:
            # ë¯¸ë˜ ë¦¬ì›Œë“œ ë§ˆìŠ¤í‚¹: ë¹„ì–´ìˆëŠ” ë¦¬ì›Œë“œ
            reward = torch.zeros(self.d_model, device=device)
        
        return reward

    def create_input_sequence(self, state: torch.Tensor, action: torch.Tensor, reward: torch.Tensor) -> torch.Tensor:
        """
        state, action, rewardë¥¼ ìˆœì„œëŒ€ë¡œ êµ¬ì„±
        
        Args:
            state: ìƒíƒœ í…ì„œ [batch_size, seq_len, d_model]
            action: ì•¡ì…˜ í…ì„œ [batch_size, seq_len, d_model]
            reward: ë¦¬ì›Œë“œ í…ì„œ [batch_size, seq_len, d_model]
        
        Returns:
            sequence: ê²°í•©ëœ ì‹œí€€ìŠ¤ [batch_size, seq_len * 3, d_model]
        """
        batch_size, seq_len, d_model = state.shape
        
        # ê° íƒ€ì„ìŠ¤í…ì—ì„œ state, action, rewardë¥¼ ìˆœì„œëŒ€ë¡œ ë°°ì¹˜
        sequence_list = []
        
        for t in range(seq_len):
            # í˜„ì¬ íƒ€ì„ìŠ¤í…ì˜ state, action, reward
            curr_state = state[:, t:t+1, :]   # [batch_size, 1, d_model]
            curr_action = action[:, t:t+1, :] # [batch_size, 1, d_model]
            curr_reward = reward[:, t:t+1, :] # [batch_size, 1, d_model]
            
            # state, action, reward ìˆœì„œë¡œ ì¶”ê°€
            sequence_list.extend([curr_state, curr_action, curr_reward])
        
        # ì‹œí€€ìŠ¤ ê²°í•©
        sequence = torch.cat(sequence_list, dim=1)  # [batch_size, seq_len * 3, d_model]
        
        return sequence

    def create_input_sequence_batch(self, sequence: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:
        """
        ë°°ì¹˜ ì‹œí€€ìŠ¤ë¥¼ state, action, rewardë¡œ ë¶„ë¦¬
        
        Args:
            sequence: ê²°í•©ëœ ì‹œí€€ìŠ¤ [batch_size, seq_len * 3, d_model]
        
        Returns:
            state: ìƒíƒœ í…ì„œ [batch_size, seq_len, d_model]
            action: ì•¡ì…˜ í…ì„œ [batch_size, seq_len, d_model] 
            reward: ë¦¬ì›Œë“œ í…ì„œ [batch_size, seq_len, d_model]
        """
        batch_size, total_seq_len, d_model = sequence.shape
        seq_len = total_seq_len // 3
        
        # ì‹œí€€ìŠ¤ë¥¼ 3ê°œì”© ê·¸ë£¹ìœ¼ë¡œ ë‚˜ëˆ„ì–´ state, action, reward ì¶”ì¶œ
        sequence_reshaped = sequence.view(batch_size, seq_len, 3, d_model)
        
        # ê° íƒ€ì„ìŠ¤í…ì—ì„œ state, action, reward ì¶”ì¶œ
        state = sequence_reshaped[:, :, 0, :]   # [batch_size, seq_len, d_model]
        action = sequence_reshaped[:, :, 1, :]  # [batch_size, seq_len, d_model]
        reward = sequence_reshaped[:, :, 2, :]  # [batch_size, seq_len, d_model]
        
        return state, action, reward

    def forward(self, grid_states: torch.Tensor, 
                gate_actions: Optional[torch.Tensor] = None,
                rewards: Optional[torch.Tensor] = None) -> Dict[str, torch.Tensor]:
        """
        ë‹¨ì¼ ê·¸ë¦¬ë“œ ë§¤íŠ¸ë¦­ìŠ¤ ë‹¨ìœ„ë¡œ ìˆœì°¨ ì²˜ë¦¬ í›„ ë°°ì¹˜ í•©ì¹˜ê¸°
        
        Args:
            grid_states: ê·¸ë¦¬ë“œ ìƒíƒœ [batch_size, time_steps, num_qubits, features]
            gate_actions: ê²Œì´íŠ¸ ì•¡ì…˜ (ì„ íƒì )
            rewards: ë¦¬ì›Œë“œ (ì„ íƒì )
        
        Returns:
            Dict containing embedded sequences and components
        """
        batch_size = grid_states.shape[0]
        batch_results = []
        
        # ê° ë°°ì¹˜ ìƒ˜í”Œì„ ê°œë³„ë¡œ ì²˜ë¦¬
        for b in range(batch_size):
            single_grid = grid_states[b]  # [time_steps, num_qubits, features]
            
            # ë‹¨ì¼ ê·¸ë¦¬ë“œì— ëŒ€í•œ ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
            single_result = self._process_single_grid(single_grid)
            batch_results.append(single_result)
        
        # ë°°ì¹˜ ì°¨ì›ìœ¼ë¡œ í•©ì¹˜ê¸°
        return self._combine_batch_results(batch_results)
    
    def _process_single_grid(self, single_grid: torch.Tensor, actual_gate_count: int, grid_matrix_data: Dict[str, Any] = None, max_seq_len: int = None) -> Dict[str, torch.Tensor]:
        """
        ğŸš€ NEW: ìˆœìˆ˜ ê²Œì´íŠ¸ ìˆ˜ ê¸°ë°˜ ë‹¨ìˆœ ì²˜ë¦¬ (íŒ¨ë”© ì§€ì›)
        
        Args:
            single_grid: [time_steps, num_qubits, features] ë˜ëŠ” [total_gates, features]
            actual_gate_count: ì‹¤ì œ ê²Œì´íŠ¸ ìˆ˜ (ë©”íƒ€ë°ì´í„°ì—ì„œ ì „ë‹¬)
            grid_matrix_data: ì›ë³¸ ê·¸ë¦¬ë“œ ë§¤íŠ¸ë¦­ìŠ¤ ë°ì´í„° (íƒ€ê²Ÿ ìƒì„±ì— í•„ìš”)
            max_seq_len: ë°°ì¹˜ ë‚´ ìµœëŒ€ ì‹œí€€ìŠ¤ ê¸¸ì´ (íŒ¨ë”©ìš©)
        
        Returns:
            Dict containing single sample results (padded if max_seq_len provided)
        """
        device = single_grid.device
        
        # ì‹¤ì œ ê²Œì´íŠ¸ ìˆ˜ ê¸°ë°˜ SAR ì‹œí€€ìŠ¤ ê¸¸ì´ ê³„ì‚°
        sar_sequence_len = actual_gate_count * 3
        actual_sequence_len = sar_sequence_len + 1  # EOS í† í° í¬í•¨
        
        # íŒ¨ë”© ê¸¸ì´ ê²°ì • (ë°°ì¹˜ ë ˆë²¨ ìµœëŒ€ ê¸¸ì´ ì‚¬ìš©)
        if max_seq_len is not None:
            sequence_len = max_seq_len
        else:
            sequence_len = actual_sequence_len
        
        # ê°„ë‹¨í•œ ë”ë¯¸ ì„ë² ë”© ìƒì„± (ì‹¤ì œ ê²Œì´íŠ¸ ìˆ˜ë§Œí¼)
        state_emb = torch.zeros(actual_gate_count, self.d_model, device=device)
        action_emb = torch.zeros(actual_gate_count, self.d_model, device=device)
        reward_emb = torch.zeros(actual_gate_count, self.d_model, device=device)
        
        # SAR ì‹œí€€ìŠ¤ ìƒì„±
        sar_sequence = torch.zeros(sar_sequence_len, self.d_model, device=device)
        for i in range(actual_gate_count):
            base_idx = i * 3
            sar_sequence[base_idx] = state_emb[i]      # State
            sar_sequence[base_idx + 1] = action_emb[i]  # Action
            sar_sequence[base_idx + 2] = reward_emb[i]  # Reward
        
        # EOS í† í° ì¶”ê°€
        actual_input_sequence = torch.cat([sar_sequence, self.eos_embed.unsqueeze(0)], dim=0)
        
        # íŒ¨ë”© ì ìš© (í•„ìš”í•œ ê²½ìš°)
        if sequence_len > actual_sequence_len:
            # íŒ¨ë”© í† í°ìœ¼ë¡œ ì±„ìš°ê¸°
            padding_len = sequence_len - actual_sequence_len
            padding = torch.zeros(padding_len, self.d_model, device=device)
            input_sequence = torch.cat([actual_input_sequence, padding], dim=0)
        else:
            input_sequence = actual_input_sequence
        
        # ì–´í…ì…˜ ë§ˆìŠ¤í¬ ìƒì„± (causal mask)
        attention_mask = torch.tril(torch.ones(sequence_len, sequence_len, device=device, dtype=torch.bool))
        
        # ì•¡ì…˜ ì˜ˆì¸¡ ë§ˆìŠ¤í¬ ìƒì„± (1::3 íŒ¨í„´, ì‹¤ì œ ê¸¸ì´ë§Œ)
        action_prediction_mask = torch.zeros(sequence_len, dtype=torch.bool, device=device)
        # ì‹¤ì œ ê²Œì´íŠ¸ ìœ„ì¹˜ì—ë§Œ True ì„¤ì •
        for i in range(actual_gate_count):
            action_idx = i * 3 + 1  # 1, 4, 7, 10... ìœ„ì¹˜ (ì•¡ì…˜ ìœ„ì¹˜)
            if action_idx < sequence_len:
                action_prediction_mask[action_idx] = True
        
        # ì•¡ì…˜ íƒ€ê²Ÿ ìƒì„± (í•™ìŠµì— í•„ìš”)
        target_tensors = {}
        if grid_matrix_data is not None:
            # ActionTargetBuilderë¥¼ ì‚¬ìš©í•˜ì—¬ íƒ€ê²Ÿ í…ì„œ ìƒì„±
            action_targets = ActionTargetBuilder.build_from_grid(grid_matrix_data, batch_size=1)
            
            # íƒ€ê²Ÿ í…ì„œ ì¶”ì¶œ
            if 'gate_targets' in action_targets:
                target_tensors['target_actions'] = action_targets['gate_targets']
            if 'position_targets' in action_targets:
                target_tensors['target_qubits'] = action_targets['position_targets']
            if 'parameter_targets' in action_targets:
                target_tensors['target_params'] = action_targets['parameter_targets']
        
        # íƒ€ê²Ÿ í…ì„œê°€ ì—†ëŠ” ê²½ìš° ë”ë¯¸ ìƒì„±
        if 'target_actions' not in target_tensors:
            target_tensors['target_actions'] = torch.zeros(actual_gate_count, dtype=torch.long, device=device)
        if 'target_qubits' not in target_tensors:
            target_tensors['target_qubits'] = torch.full((actual_gate_count, 2), -1, dtype=torch.long, device=device)
        if 'target_params' not in target_tensors:
            target_tensors['target_params'] = torch.zeros(actual_gate_count, dtype=torch.float, device=device)
        
        result = {
            'input_sequence': input_sequence,           # [sequence_len, d_model]
            'attention_mask': attention_mask,           # [sequence_len, sequence_len]
            'action_prediction_mask': action_prediction_mask,  # [sequence_len]
            'state_embedded': state_emb,                # [actual_gate_count, d_model]
            'action_embedded': action_emb,              # [actual_gate_count, d_model]
            'reward_embedded': reward_emb,              # [actual_gate_count, d_model]
            'episode_time_len': torch.tensor(actual_gate_count, device=device),
            'sar_sequence_len': torch.tensor(sar_sequence_len, device=device),
            'target_actions': target_tensors['target_actions'],  # [actual_gate_count]
            'target_qubits': target_tensors['target_qubits'],    # [actual_gate_count, 2]
            'target_params': target_tensors['target_params']     # [actual_gate_count]
        }
        
        return result
    
    def _create_episode_mask(self, episode_sequence: torch.Tensor, current_episode_time: int) -> torch.Tensor:
        """
        ì—í”¼ì†Œë“œíƒ€ì„ ê¸°ì¤€ ë§ˆìŠ¤í‚¹: current_episode_timeê¹Œì§€ë§Œ ê³µê°œ
        
        Args:
            episode_sequence: [episode_time_len, features]
            current_episode_time: í˜„ì¬ ì—í”¼ì†Œë“œ ì‹œê°„
        
        Returns:
            masked_sequence: [episode_time_len, features]
        """
        masked_sequence = torch.zeros_like(episode_sequence)
        if current_episode_time > 0:
            masked_sequence[:current_episode_time] = episode_sequence[:current_episode_time]
        return masked_sequence
    
    def _combine_batch_results(self, batch_results: List[Dict[str, torch.Tensor]]) -> Dict[str, torch.Tensor]:
        """
        ê°œë³„ ì²˜ë¦¬ëœ ê²°ê³¼ë“¤ì„ ë°°ì¹˜ ì°¨ì›ìœ¼ë¡œ í•©ì¹˜ê¸°
        
        Args:
            batch_results: ê° ìƒ˜í”Œì˜ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        
        Returns:
            ë°°ì¹˜ ì°¨ì›ìœ¼ë¡œ í•©ì³ì§„ ê²°ê³¼
        """
        if not batch_results:
            return {}
        
        combined = {}
        for key in batch_results[0].keys():
            combined[key] = torch.stack([result[key] for result in batch_results], dim=0)
        
        return combined

    def convert_grid_matrix_to_tensor(self, grid_matrix_data: Dict[str, Any]) -> torch.Tensor:
        """
        grid_graph_encoder.to_grid_matrix()ì˜ ì¶œë ¥ì„ í…ì„œë¡œ ë³€í™˜ (x,y êµ¬ì¡°)
        gates ëª¨ë“ˆì˜ gate_vocabì„ ì‚¬ìš©í•˜ì—¬ ê²Œì´íŠ¸ ì¢…ë¥˜ì™€ ì—­í•  ì •ë³´ í¬í•¨
        
        Args:
            grid_matrix_data: to_grid_matrix()ì˜ ì¶œë ¥
                - grid_matrix: [num_qubits][max_parallel_order] í˜•íƒœì˜ ë§¤íŠ¸ë¦­ìŠ¤
                - grid_shape: [max_parallel_order, num_qubits]
                - node_lookup: ë…¸ë“œ ì •ë³´ ë”•ì…”ë„ˆë¦¬
        
        Returns:
            grid_tensor: [1, time_steps, num_qubits, features] í˜•íƒœì˜ í…ì„œ
            features: [gate_type_id, role_id, occupation, parameter_value]
        """
        from gates import QuantumGateRegistry
        
        grid_matrix = grid_matrix_data['grid_matrix']
        grid_shape = grid_matrix_data['grid_shape']
        node_lookup = grid_matrix_data['node_lookup']
        
        max_parallel_order, num_qubits = grid_shape[0], grid_shape[1]
        
        # gates ëª¨ë“ˆì—ì„œ gate_vocab ê°€ì ¸ì˜¤ê¸°
        gate_registry = QuantumGateRegistry()
        gate_vocab = gate_registry.get_gate_vocab()
        
        # ê·¸ë¦¬ë“œ í…ì„œ ì´ˆê¸°í™” (features: [gate_type_id, role_id, occupation, parameter_value])
        # gate_type_idì™€ role_idëŠ” embedding ì¸ë±ìŠ¤ë¡œ ì‚¬ìš©ë˜ë¯€ë¡œ Long íƒ€ì…ì´ì–´ì•¼ í•¨
        grid_tensor = torch.zeros(1, max_parallel_order, num_qubits, 4, dtype=torch.float32)
        gate_type_tensor = torch.zeros(1, max_parallel_order, num_qubits, dtype=torch.long)
        role_tensor = torch.zeros(1, max_parallel_order, num_qubits, dtype=torch.long)
        
        # ì—­í•  ë§¤í•‘ (0: empty, 1: single_qubit, 2: control, 3: target)
        role_mapping = {
            'empty': 0,
            'single': 1, 
            'control': 2,
            'target': 3
        }
        
        # grid_matrixëŠ” [qubit][time] êµ¬ì¡°ì´ë¯€ë¡œ ì´ë¥¼ tensor[batch, time, qubit, features]ë¡œ ë³€í™˜
        for qubit_idx in range(num_qubits):
            for time_idx in range(max_parallel_order):
                node_id = grid_matrix[qubit_idx][time_idx]
                
                if node_id is not None:
                    # ë…¸ë“œ ì •ë³´ ì¡°íšŒ
                    node = node_lookup.get(node_id, {})
                    gate_name = node.get('gate_name', 'unknown')
                    
                    # gate_vocabì—ì„œ ê²Œì´íŠ¸ ID ê°€ì ¸ì˜¤ê¸°
                    gate_type_id = gate_vocab.get(gate_name, gate_vocab.get('[EMPTY]', 0))
                    
                    # ë…¸ë“œ IDì—ì„œ ì—­í•  ì •ë³´ ì¶”ì¶œ
                    role_id = role_mapping['empty']  # ê¸°ë³¸ê°’
                    parameter_value = 0.0
                    
                    # ë…¸ë“œ ID íŒ¨í„´ ë¶„ì„
                    if '_target_' in node_id:
                        role_id = role_mapping['target']
                    elif '_control_' in node_id:
                        role_id = role_mapping['control']
                    elif f'{gate_name}_q' in node_id:
                        role_id = role_mapping['single']
                    
                    # íŒŒë¼ë¯¸í„° ì •ë³´ ì¶”ì¶œ (ë…¸ë“œì— ìˆëŠ” ê²½ìš°)
                    if 'parameter_value' in node:
                        parameter_value = float(node['parameter_value'])
                    elif 'parameters' in node and node['parameters']:
                        parameter_value = float(node['parameters'][0])
                    
                    # x,y êµ¬ì¡°ë¡œ ë°°ì¹˜: tensor[batch, time, qubit, features]
                    # embedding ì¸ë±ìŠ¤ë¡œ ì‚¬ìš©ë  ê°’ë“¤ì„ ì§ì ‘ Long íƒ€ì…ìœ¼ë¡œ ì €ì¥
                    gate_type_tensor[0, time_idx, qubit_idx] = gate_type_id    # ê²Œì´íŠ¸ íƒ€ì… ID (Long)
                    role_tensor[0, time_idx, qubit_idx] = role_id              # ì—­í•  ID (Long)
                    grid_tensor[0, time_idx, qubit_idx, 0] = gate_type_id      # ê²Œì´íŠ¸ íƒ€ì… ID 
                    grid_tensor[0, time_idx, qubit_idx, 1] = role_id           # ì—­í•  ID 
                    grid_tensor[0, time_idx, qubit_idx, 2] = 1.0               # ì ìœ ë¨
                    grid_tensor[0, time_idx, qubit_idx, 3] = parameter_value   # íŒŒë¼ë¯¸í„° ê°’
        
        # embedding ì¸ë±ìŠ¤ìš© Long í…ì„œë“¤ì„ grid_tensorì— ì¶”ê°€
        return {
            'grid_tensor': grid_tensor,
            'gate_type_indices': gate_type_tensor,
            'role_indices': role_tensor
        }

    def process_grid_matrix_data_simple(self, grid_matrix_data: Dict[str, Any], actual_gate_count: int, max_seq_len: int = None) -> Dict[str, torch.Tensor]:
        """
        ğŸš€ NEW: ìˆœìˆ˜ ê²Œì´íŠ¸ ìˆ˜ ê¸°ë°˜ ê°„ë‹¨í•œ Decision Transformer ì…ë ¥ ìƒì„± (íŒ¨ë”© ì§€ì›)
        
        Args:
            grid_matrix_data: to_grid_matrix()ì˜ ì¶œë ¥
            actual_gate_count: ì‹¤ì œ ê²Œì´íŠ¸ ìˆ˜
            max_seq_len: ë°°ì¹˜ ë‚´ ìµœëŒ€ ì‹œí€€ìŠ¤ ê¸¸ì´ (íŒ¨ë”©ìš©)
        
        Returns:
            Dict containing all Decision Transformer inputs (padded if max_seq_len provided)
        """
        # ğŸš€ NEW: ìˆœìˆ˜ ê²Œì´íŠ¸ ìˆ˜ ê¸°ë°˜ ê°„ë‹¨í•œ ì²˜ë¦¬
        # ê·¸ë¦¬ë“œ ë§¤íŠ¸ë¦­ìŠ¤ë¥¼ í…ì„œë¡œ ë³€í™˜ (ë”ë¯¸ ë°ì´í„°ë¡œ ëŒ€ì²´ ê°€ëŠ¥)
        tensor_data = self.convert_grid_matrix_to_tensor(grid_matrix_data)
        grid_states = tensor_data['grid_tensor']
        
        # ë‹¨ì¼ ê·¸ë¦¬ë“œì—ì„œ ì²« ë²ˆì§¸ ìƒ˜í”Œ ì¶”ì¶œ
        single_grid = grid_states[0]  # [time_steps, num_qubits, features]
        
        # ìƒˆë¡œìš´ ê°„ë‹¨í•œ ì²˜ë¦¬ í•¨ìˆ˜ í˜¸ì¶œ (íŒ¨ë”© ê¸¸ì´ ì „ë‹¬)
        # íƒ€ê²Ÿ í…ì„œ ìƒì„±ì„ ìœ„í•´ grid_matrix_data ë„˜ê¸°ê¸°
        results = self._process_single_grid(single_grid, actual_gate_count, grid_matrix_data, max_seq_len)
        
        return results
        

    def visualize_grid_tensor(self, grid_tensor: torch.Tensor) -> str:
        """
        ê·¸ë¦¬ë“œ í…ì„œë¥¼ ì‹œê°í™” (x,y êµ¬ì¡°)
        
        Args:
            grid_tensor: [1, time_steps, num_qubits, features] í˜•íƒœì˜ í…ì„œ
        
        Returns:
            ì‹œê°í™”ëœ ê·¸ë¦¬ë“œ ë¬¸ìì—´
        """
        batch_size, time_steps, num_qubits, features = grid_tensor.shape
        
        # ì²« ë²ˆì§¸ ë°°ì¹˜ë§Œ ì‹œê°í™”
        tensor_2d = grid_tensor[0, :, :, 1]  # occupation ì •ë³´ë§Œ ì‚¬ìš©
        
        visualization = "\nê·¸ë¦¬ë“œ ì‹œê°í™” (x=ì‹œê°„, y=íë¹—):\n"
        visualization += "   " + "".join([f"{t:3d}" for t in range(time_steps)]) + "\n"
        
        for qubit_idx in range(num_qubits):
            row = f"q{qubit_idx}: "
            for time_idx in range(time_steps):
                if tensor_2d[time_idx, qubit_idx] > 0:
                    gate_type = int(grid_tensor[0, time_idx, qubit_idx, 0].item())
                    row += f"{gate_type:3d}"
                else:
                    row += "  ."
            visualization += row + "\n"
        
        return visualization
