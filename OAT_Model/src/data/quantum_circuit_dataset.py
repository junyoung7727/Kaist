"""
Quantum Circuit Dataset Module
ê°„ë‹¨í•˜ê³  í™•ì¥ì„± ë†’ì€ ì–‘ìíšŒë¡œ ë°ì´í„°ì…‹ ì²˜ë¦¬
"""

import json
import torch
from torch.utils.data import Dataset, DataLoader
from typing import Dict, List, Tuple, Any, Optional
from dataclasses import dataclass
from pathlib import Path
import numpy as np
from sklearn.model_selection import train_test_split
import sys
import pathlib
import re
sys.path.append(str(pathlib.Path(__file__).parent.parent.parent.parent / "quantumcommon"))
from gates import gate_registry, GateType, GateOperation


def extract_depth_from_circuit_id(circuit_id: str) -> int:
    """
    circuit_idì—ì„œ depth ê°’ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.
    
    ì˜ˆì‹œ: "scalability_test1_16q_d1_r0.3_0" -> 1
          "circuit_8q_d10_r0.5_2" -> 10
    
    Args:
        circuit_id: íšŒë¡œ ID ë¬¸ìì—´
        
    Returns:
        depth ê°’ (ì°¾ì„ ìˆ˜ ì—†ìœ¼ë©´ 0)
    """
    # _dë’¤ì— ì˜¤ëŠ” ìˆ«ìë¥¼ ì°¾ëŠ” ì •ê·œì‹
    pattern = r'_d(\d+)_'
    match = re.search(pattern, circuit_id)
    
    if match:
        return int(match.group(1))
    else:
        # íŒ¨í„´ì„ ì°¾ì„ ìˆ˜ ì—†ìœ¼ë©´ 0 ë°˜í™˜
        print(f"Warning: Could not extract depth from circuit_id: {circuit_id}")
        return 0


@dataclass
class CircuitSpec:
    """ì–‘ì íšŒë¡œ ìŠ¤í™"""
    circuit_id: str
    num_qubits: int
    gates: List[GateOperation]
    depth: int = 0  # ê¸°ë³¸ê°’ ì¶”ê°€
    
    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> 'CircuitSpec':
        """ë”•ì…”ë„ˆë¦¬ì—ì„œ CircuitSpec ìƒì„±"""
        gates = [
            GateOperation(
                name=gate['name'],
                qubits=gate['qubits'],
                parameters=gate['parameters']
            )
            for gate in data['gates']
        ]
        
        # circuit_idì—ì„œ depth ì¶”ì¶œ
        circuit_id = data['circuit_id']
        depth = extract_depth_from_circuit_id(circuit_id)
        
        return cls(
            circuit_id=circuit_id,
            num_qubits=data['num_qubits'],
            gates=gates,
            depth=depth
        )


@dataclass
class MeasurementResult:
    """ì¸¡ì • ê²°ê³¼ ë°ì´í„° - timestamp ì œì™¸í•˜ê³  ëª¨ë“  í•„ë“œ í¬í•¨"""
    circuit_id: str
    num_qubits: int
    depth: int
    fidelity: float
    robust_fidelity: Optional[float] = None
    expressibility: Optional[Dict[str, float]] = None
    entanglement: Optional[float] = None
    
    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> 'MeasurementResult':
        """ë”•ì…”ë„ˆë¦¬ì—ì„œ MeasurementResult ìƒì„±

        ì˜ˆ:
        {
            "circuit_id": "scalability_test_15q_d1_r0.8_0",
            "num_qubits": 15,
            "depth": 16,
            "timestamp": "2025-08-13T10:14:44.745735",
            "fidelity": 0.73046875,
            "robust_fidelity": 0.962890625,
            "expressibility": {
                "kl_divergence": 8.466604598985924
            },
            "entanglement": 0.5020833333333334
        }
        """
        return cls(
            circuit_id=data['circuit_id'],
            num_qubits=data['num_qubits'],
            depth=data['depth'],
            timestamp=data['timestamp'],
            fidelity=data['fidelity'],
            robust_fidelity=data.get('robust_fidelity'),
            expressibility=data.get('expressibility'),
            entanglement=np.clip(data.get('entanglement'), 0, 1)
        )


@dataclass
class CircuitData:
    """íšŒë¡œ ìŠ¤í™ê³¼ ì¸¡ì • ê²°ê³¼ë¥¼ ê²°í•©í•œ ë°ì´í„°"""
    circuit_spec: CircuitSpec
    measurement_result: MeasurementResult
    
    @property
    def circuit_id(self) -> str:
        return self.circuit_spec.circuit_id
    
    @property
    def num_qubits(self) -> int:
        return self.circuit_spec.num_qubits
    
    @property
    def gates(self) -> List[GateOperation]:
        return self.circuit_spec.gates


class QuantumCircuitDataset(Dataset):
    """ì–‘ì íšŒë¡œ ë°ì´í„°ì…‹"""
    
    def __init__(self, circuit_data: List[CircuitData]):
        self.circuit_data = circuit_data
    
    def __len__(self) -> int:
        return len(self.circuit_data)
    
    def __getitem__(self, idx: int) -> CircuitData:
        return self.circuit_data[idx]
    
    def get_by_circuit_id(self, circuit_id: str) -> Optional[CircuitData]:
        """circuit_idë¡œ ë°ì´í„° ê²€ìƒ‰"""
        for data in self.circuit_data:
            if data.circuit_id == circuit_id:
                return data
        return None


class DatasetManager:
    """ë°ì´í„°ì…‹ ê´€ë¦¬ì - ë¡œë”©, ë¶„í• , ë³€í™˜ ë‹´ë‹¹"""
    
    def __init__(self, unified_data_path: Optional[str] = None, results_path: Optional[str] = None, circuits_path: Optional[str] = None, merged_results_path: Optional[str] = None):
        """ë°ì´í„°ì…‹ ë§¤ë‹ˆì € ì´ˆê¸°í™”
        
        Args:
            unified_data_path: í†µí•© ë°ì´í„° íŒŒì¼ ê²½ë¡œ (merged_resultsì™€ merged_circuits ëª¨ë‘ í¬í•¨)
            results_path: ì¸¡ì • ê²°ê³¼ JSON íŒŒì¼ ê²½ë¡œ (ë ˆê±°ì‹œ ì§€ì›)
            circuits_path: íšŒë¡œ ìŠ¤í™ JSON íŒŒì¼ ê²½ë¡œ (ë ˆê±°ì‹œ ì§€ì›)
            merged_results_path: ë³‘í•©ëœ ê²°ê³¼ JSON íŒŒì¼ ê²½ë¡œ (ë ˆê±°ì‹œ ì§€ì›)
        """
        self.unified_data_path = Path(unified_data_path) if unified_data_path else None
        self.results_path = Path(results_path) if results_path else None
        self.circuits_path = Path(circuits_path) if circuits_path else None
        self.merged_results_path = Path(merged_results_path) if merged_results_path else None
        
        self.raw_results_data = None
        self.raw_circuits_data = None
        self.circuit_data = None
    
    def load_results_data(self) -> Dict[str, Any]:
        """ì¸¡ì • ê²°ê³¼ JSON ë°ì´í„° ë¡œë”©"""
        if self.unified_data_path and self.unified_data_path.exists():
            # í†µí•© ë°ì´í„° íŒŒì¼ì—ì„œ ë¡œë”©
            with open(self.unified_data_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
                self.raw_results_data = data
                return data
        elif self.merged_results_path and self.merged_results_path.exists():
            # ë³‘í•©ëœ ê²°ê³¼ íŒŒì¼ì—ì„œ ë¡œë”© (ë ˆê±°ì‹œ ì§€ì›)
            with open(self.merged_results_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
                self.raw_results_data = data
                return data
        elif self.results_path and self.results_path.exists():
            # ê°œë³„ ê²°ê³¼ íŒŒì¼ì—ì„œ ë¡œë”© (ë ˆê±°ì‹œ ì§€ì›)
            with open(self.results_path, 'r', encoding='utf-8') as f:
                self.raw_results_data = json.load(f)
                return self.raw_results_data
        else:
            raise FileNotFoundError("ê²°ê³¼ ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    def load_circuits_data(self) -> Dict[str, Any]:
        """íšŒë¡œ ìŠ¤í™ JSON ë°ì´í„° ë¡œë”©"""
        if self.unified_data_path and self.unified_data_path.exists():
            # í†µí•© ë°ì´í„° íŒŒì¼ì—ì„œ ë¡œë”© (ì´ë¯¸ load_results_dataì—ì„œ ë¡œë”©ëœ ê²½ìš° ì¬ì‚¬ìš©)
            if self.raw_results_data is None:
                with open(self.unified_data_path, 'r', encoding='utf-8') as f:
                    self.raw_results_data = json.load(f)
            self.raw_circuits_data = self.raw_results_data  # ê°™ì€ íŒŒì¼ì—ì„œ circuits ì •ë³´ ì¶”ì¶œ
            return self.raw_circuits_data
        elif self.circuits_path and self.circuits_path.exists():
            # ê°œë³„ íšŒë¡œ íŒŒì¼ì—ì„œ ë¡œë”© (ë ˆê±°ì‹œ ì§€ì›)
            with open(self.circuits_path, 'r', encoding='utf-8') as f:
                self.raw_circuits_data = json.load(f)
                return self.raw_circuits_data
        else:
            raise FileNotFoundError("íšŒë¡œ ìŠ¤í™ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    def load_measurement_results(self, file_path: str) -> Dict[str, MeasurementResult]:
        """ì¸¡ì • ê²°ê³¼ íŒŒì¼ ë¡œë”© - merged_resultsì™€ IBM results í˜•ì‹ ëª¨ë‘ ì§€ì›"""
        with open(file_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        results = {}
        
        # merged_results í˜•ì‹ ì²˜ë¦¬ (ì‹œë®¬ë ˆì´í„° í˜•ì‹)
        if 'merged_results' in data:
            for result in data['merged_results']:
                # timestamp ì œê±° (ì‚¬ìš©ì ìš”ì²­)
                result_data = {k: v for k, v in result.items() if k != 'timestamp'}
                measurement_result = MeasurementResult(**result_data)
                results[measurement_result.circuit_id] = measurement_result
        
        # IBM ì‹¤í—˜ ê²°ê³¼ í˜•ì‹ ì²˜ë¦¬
        elif 'results' in data:
            for result in data['results']:
                # timestamp ì œê±° (ì‚¬ìš©ì ìš”ì²­)
                result_data = {k: v for k, v in result.items() if k != 'timestamp'}
                measurement_result = MeasurementResult(**result_data)
                results[measurement_result.circuit_id] = measurement_result
        
        # ë‹¨ì¼ ê²°ê³¼ í˜•ì‹ ì²˜ë¦¬ (ê¸°ì¡´ í˜¸í™˜ì„±)
        elif isinstance(data, list):
            for result in data:
                # timestamp ì œê±° (ì‚¬ìš©ì ìš”ì²­)
                result_data = {k: v for k, v in result.items() if k != 'timestamp'}
                measurement_result = MeasurementResult(**result_data)
                results[measurement_result.circuit_id] = measurement_result
        
        else:
            raise ValueError(f"Unsupported JSON format in {file_path}. Expected 'merged_results', 'results', or list format.")
        
        return results
    
    def parse_circuit_specs(self) -> Dict[str, CircuitSpec]:
        """íšŒë¡œ ìŠ¤í™ì„ íŒŒì‹±í•˜ì—¬ circuit_idë¥¼ í‚¤ë¡œ í•˜ëŠ” ë”•ì…”ë„ˆë¦¬ ë°˜í™˜"""
        if self.raw_circuits_data is None:
            self.load_circuits_data()
        
        specs = {}
        circuits_data = self.raw_circuits_data.get('merged_circuits', {})
        
        for circuit_id, circuit_data in circuits_data.items():
            spec = CircuitSpec.from_dict(circuit_data)
            specs[circuit_id] = spec
        
        return specs
    
    def is_valid_circuit_data(self, circuit_data: CircuitData) -> bool:
        """
        íšŒë¡œ ë°ì´í„°ì˜ ìœ íš¨ì„±ì„ ê²€ì¦
        
        Args:
            circuit_data: ê²€ì¦í•  íšŒë¡œ ë°ì´í„°
            
        Returns:
            True if valid, False if invalid
        """
        result = circuit_data.measurement_result
        # 1. ê¸°ë³¸ í•„ìˆ˜ í•„ë“œ ê²€ì¦
        if result is None or result.fidelity is None or result.entanglement is None:
            return False
        
        # 2. Expressibility ë°ì´í„° ê²€ì¦ (KL divergenceë§Œ ì‚¬ìš©)
        if result.expressibility and isinstance(result.expressibility, dict):
            expr = result.expressibility
            
            # KL divergenceê°€ 0ì¸ ê²½ìš° ë¬´íš¨í•œ ë°ì´í„°ë¡œ ì œê±°
            kl_divergence = expr.get('kl_divergence')
            if kl_divergence is None or kl_divergence == 0.0:
                return False
                
        elif result.expressibility is None:
            # expressibility ë°ì´í„°ê°€ Noneì¸ ê²½ìš° ë¬´íš¨í•œ ë°ì´í„°ë¡œ ê°„ì£¼
            return False
        else:
            # expressibilityê°€ dictê°€ ì•„ë‹Œ ê²½ìš°ë„ ë¬´íš¨í•œ ë°ì´í„°ë¡œ ê°„ì£¼
            return False
        
        # 3. í”¼ë¸ë¦¬í‹° ê°’ ê²€ì¦ (ìŒìˆ˜ë‚˜ 1ë³´ë‹¤ í° ê°’ ì œê±°)
        if result.fidelity < 0 or result.fidelity > 1:
            return False
        
        if result.robust_fidelity is not None:
            if result.robust_fidelity < 0 or result.robust_fidelity > 1:
                return False
        
        # 4. ì–½í˜ë„ ê°’ ê²€ì¦ (ìŒìˆ˜ ì œê±°)
        if result.entanglement < 0:
            return False
        
        return True
    
    def merge_data(self, enable_filtering: bool = True) -> List[CircuitData]:
        """
        íšŒë¡œ ìŠ¤í™ê³¼ ì¸¡ì • ê²°ê³¼ë¥¼ circuit_idë¡œ ë³‘í•©í•˜ê³  ë°ì´í„° í’ˆì§ˆ ê²€ì¦
        
        Args:
            enable_filtering: Trueë©´ ë¬´íš¨í•œ ë°ì´í„° í•„í„°ë§, Falseë©´ ëª¨ë“  ë°ì´í„° í¬í•¨
            
        Returns:
            ë³‘í•©ëœ íšŒë¡œ ë°ì´í„° ë¦¬ìŠ¤íŠ¸
        """
        # ì¸¡ì • ê²°ê³¼ì™€ íšŒë¡œ ìŠ¤í™ íŒŒì‹±
        # ì‚¬ìš©í•  ë°ì´í„° íŒŒì¼ ê²½ë¡œ ê²°ì •
        if self.unified_data_path:
            data_file_path = str(self.unified_data_path)
        elif self.merged_results_path:
            data_file_path = str(self.merged_results_path)
        elif self.results_path:
            data_file_path = str(self.results_path)
        else:
            raise FileNotFoundError("ë°ì´í„° íŒŒì¼ ê²½ë¡œê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            
        measurement_results = self.load_measurement_results(data_file_path)
        circuit_specs = self.parse_circuit_specs()
        
        merged_data = []
        filtered_count = 0
        
        # circuit_idë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë°ì´í„° ë³‘í•©
        for circuit_id in list(circuit_specs.keys()):

            circuit_data = CircuitData(
                circuit_spec=circuit_specs[circuit_id],
                measurement_result=measurement_results.get(circuit_id)
            )
            # ë°ì´í„° í’ˆì§ˆ ê²€ì¦
            if enable_filtering:
                merged_data.append(circuit_data)
        # ì¸¡ì • ê²°ê³¼ë§Œ ìˆê³  íšŒë¡œ ìŠ¤í™ì´ ì—†ëŠ” ê²½ìš° ê²½ê³ 
        for circuit_id in measurement_results.keys():
            if circuit_id not in list(circuit_specs.keys()):
                print(f"Warning: íšŒë¡œ ìŠ¤í™ì´ ì—†ëŠ” ì¸¡ì • ê²°ê³¼ ID: {circuit_id}")
        
        if enable_filtering and filtered_count > 0:
            print(f"âœ… ë°ì´í„° í’ˆì§ˆ í•„í„°ë§ ì™„ë£Œ: {filtered_count}ê°œ ë¬´íš¨ ë°ì´í„° ì œê±°ë¨")
            print(f"ğŸ“Š ìœ íš¨í•œ ë°ì´í„°: {len(merged_data)}ê°œ / ì „ì²´: {len(merged_data) + filtered_count}ê°œ")
        
        self.circuit_data = merged_data
        return merged_data
    
    def split_dataset(
        self,
        train_ratio: float = 0.7,
        val_ratio: float = 0.15,
        test_ratio: float = 0.15,
        random_state: int = 42
    ) -> Tuple["QuantumCircuitDataset", "QuantumCircuitDataset", "QuantumCircuitDataset"]:
        """ë°ì´í„°ì…‹ ë¶„í• """
        if self.circuit_data is None:
            self.merge_data()
        
        # ë¹„ìœ¨ ê²€ì¦
        assert abs(train_ratio + val_ratio + test_ratio - 1.0) < 1e-6, "ë¹„ìœ¨ì˜ í•©ì´ 1ì´ ë˜ì–´ì•¼ í•©ë‹ˆë‹¤"
        
        # ë°ì´í„°ì…‹ í¬ê¸° í™•ì¸
        total_samples = len(self.circuit_data)
        print(f"Total samples in dataset: {total_samples}")
        
        if total_samples <= 3:
            print("Warning: Dataset is too small for proper splitting. Using all samples for all splits.")
            # ë°ì´í„°ì…‹ì´ ë„ˆë¬´ ì‘ì€ ê²½ìš°, ëª¨ë“  ë°ì´í„°ë¥¼ ëª¨ë“  ë¶„í• ì— ì‚¬ìš©
            return (
                QuantumCircuitDataset(self.circuit_data),
                QuantumCircuitDataset(self.circuit_data),
                QuantumCircuitDataset(self.circuit_data)
            )
        
        # ì²« ë²ˆì§¸ ë¶„í• : train + val vs test
        train_val_data, test_data = train_test_split(
            self.circuit_data,
            test_size=test_ratio,
            random_state=random_state
        )
        
        # ë‘ ë²ˆì§¸ ë¶„í• : train vs val
        adjusted_val_ratio = val_ratio / (train_ratio + val_ratio)
        train_data, val_data = train_test_split(
            train_val_data,
            test_size=adjusted_val_ratio,
            random_state=random_state
        )
        
        return (
            QuantumCircuitDataset(train_data),
            QuantumCircuitDataset(val_data),
            QuantumCircuitDataset(test_data)
        )
    
    def get_dataset_stats(self) -> Dict[str, Any]:
        """ë°ì´í„°ì…‹ í†µê³„ ì •ë³´ ë°˜í™˜"""
        if self.circuit_data is None:
            self.merge_data()
        
        # ìœ íš¨í•œ measurement_resultê°€ ìˆëŠ” ë°ì´í„°ë§Œ í•„í„°ë§
        valid_data = [data for data in self.circuit_data if data.measurement_result is not None]
        
        num_circuits = len(self.circuit_data)
        num_valid_circuits = len(valid_data)
        
        # CircuitSpecì—ì„œ ê°€ì ¸ì˜¬ ìˆ˜ ìˆëŠ” ì •ë³´
        qubit_counts = [data.circuit_spec.num_qubits for data in self.circuit_data]
        gate_counts = [len(data.circuit_spec.gates) for data in self.circuit_data]
        
        stats = {
            "total_circuits": num_circuits,
            "valid_circuits": num_valid_circuits,
            "qubit_range": (min(qubit_counts), max(qubit_counts)),
            "avg_qubits": np.mean(qubit_counts),
            "gate_range": (min(gate_counts), max(gate_counts)),
            "avg_gates": np.mean(gate_counts)
        }
        
        if valid_data:
            # MeasurementResultì—ì„œ ê°€ì ¸ì˜¬ ìˆ˜ ìˆëŠ” ì •ë³´ (ìœ íš¨í•œ ë°ì´í„°ë§Œ)
            depths = [data.measurement_result.depth for data in valid_data]
            fidelities = [data.measurement_result.fidelity for data in valid_data]
            
            stats.update({
                "depth_range": (min(depths), max(depths)),
                "avg_depth": np.mean(depths),
                "fidelity_range": (min(fidelities), max(fidelities)),
                "avg_fidelity": np.mean(fidelities)
            })
            
            # ì¶”ê°€ ë©”íŠ¸ë¦­ í†µê³„ (ìˆëŠ” ê²½ìš°)
            entanglements = [data.measurement_result.entanglement for data in valid_data 
                           if data.measurement_result.entanglement is not None]
            if entanglements:
                stats["entanglement_range"] = (min(entanglements), max(entanglements))
                stats["avg_entanglement"] = np.mean(entanglements)
        
        return stats


def create_dataloaders(
    train_dataset: QuantumCircuitDataset,
    val_dataset: QuantumCircuitDataset,
    test_dataset: QuantumCircuitDataset,
    batch_size: int = 32,
    num_workers: int = 0,
    rtg_calculator = None,
    enable_rtg: bool = False
) -> Tuple[DataLoader, DataLoader, DataLoader]:
    """DataLoader ìƒì„± (RTG ì§€ì› í¬í•¨)"""
    
    # RTG í™œì„±í™” ì‹œ collate_fn ë³€ê²½
    if enable_rtg and rtg_calculator is not None:
        collate_fn = lambda batch: _rtg_collate_fn(batch, rtg_calculator)
    else:
        collate_fn = lambda x: x  # CircuitSpec ê°ì²´ë“¤ì„ ê·¸ëŒ€ë¡œ ë°˜í™˜
    
    train_loader = DataLoader(
        train_dataset,
        batch_size=batch_size,
        shuffle=True,
        num_workers=num_workers,
        collate_fn=collate_fn
    )
    
    val_loader = DataLoader(
        val_dataset,
        batch_size=batch_size,
        shuffle=False,
        num_workers=num_workers,
        collate_fn=collate_fn
    )
    
    test_loader = DataLoader(
        test_dataset,
        batch_size=batch_size,
        shuffle=False,
        num_workers=num_workers,
        collate_fn=collate_fn
    )
    
    return train_loader, val_loader, test_loader


def _rtg_collate_fn(batch, rtg_calculator):
    """RTG ê°’ì„ í¬í•¨í•œ ë°°ì¹˜ ë°ì´í„° ìƒì„±"""
    import torch
    
    batch_size = len(batch)
    
    # CircuitDataì—ì„œ í•„ìš”í•œ ì •ë³´ ì¶”ì¶œ
    circuit_specs = []
    states = []  # ìƒíƒœ ì‹œí€€ìŠ¤
    actions = []  # ì•¡ì…˜ ì‹œí€€ìŠ¤
    target_properties = {
        'entanglement': [],
        'fidelity': [],
        'expressibility': []
    }
    
    max_seq_len = 0
    
    for circuit_data in batch:
        circuit_specs.append(circuit_data)
        
        # ê²Œì´íŠ¸ ì‹œí€€ìŠ¤ë¥¼ ìƒíƒœ-ì•¡ì…˜ ìŒìœ¼ë¡œ ë³€í™˜
        gate_sequence = []
        for gate in circuit_data.gates:
            # ê²Œì´íŠ¸ ì •ë³´ë¥¼ ë²¡í„°ë¡œ ì¸ì½”ë”© (ê°„ë‹¨í™”ëœ ë²„ì „)
            gate_vector = torch.randn(256)  # d_model í¬ê¸°ë¡œ ì„ì‹œ ìƒì„±
            gate_sequence.append(gate_vector)
        
        if gate_sequence:
            states.append(torch.stack(gate_sequence))
            actions.append(torch.stack(gate_sequence))  # ì•¡ì…˜ë„ ë™ì¼í•˜ê²Œ ì„¤ì •
            max_seq_len = max(max_seq_len, len(gate_sequence))
        else:
            # ë¹ˆ ì‹œí€€ìŠ¤ ì²˜ë¦¬
            empty_seq = torch.zeros(1, 256)
            states.append(empty_seq)
            actions.append(empty_seq)
            max_seq_len = max(max_seq_len, 1)
        
        # ì •ë‹µ ì†ì„±ê°’ ì¶”ì¶œ
        if circuit_data.measurement_result:
            target_properties['entanglement'].append(
                circuit_data.measurement_result.entanglement or 0.0
            )
            target_properties['fidelity'].append(
                circuit_data.measurement_result.fidelity or 0.0
            )
            target_properties['expressibility'].append(
                getattr(circuit_data.measurement_result, 'expressibility', 0.0)
            )
        else:
            # ê¸°ë³¸ê°’ ì‚¬ìš©
            target_properties['entanglement'].append(0.0)
            target_properties['fidelity'].append(0.0)
            target_properties['expressibility'].append(0.0)
    
    # ì‹œí€€ìŠ¤ ê¸¸ì´ íŒ¨ë”©
    padded_states = []
    padded_actions = []
    attention_masks = []
    
    for i in range(batch_size):
        seq_len = states[i].shape[0]
        
        # íŒ¨ë”© ì²˜ë¦¬
        if seq_len < max_seq_len:
            pad_len = max_seq_len - seq_len
            padded_state = torch.cat([
                states[i],
                torch.zeros(pad_len, 256)
            ], dim=0)
            padded_action = torch.cat([
                actions[i],
                torch.zeros(pad_len, 256)
            ], dim=0)
            mask = torch.cat([
                torch.ones(seq_len, dtype=torch.bool),
                torch.zeros(pad_len, dtype=torch.bool)
            ])
        else:
            padded_state = states[i]
            padded_action = actions[i]
            mask = torch.ones(seq_len, dtype=torch.bool)
        
        padded_states.append(padded_state)
        padded_actions.append(padded_action)
        attention_masks.append(mask)
    
    # ë°°ì¹˜ í…ì„œë¡œ ë³€í™˜
    batch_states = torch.stack(padded_states)  # [batch_size, seq_len, d_model]
    batch_actions = torch.stack(padded_actions)  # [batch_size, seq_len, d_model]
    batch_masks = torch.stack(attention_masks)  # [batch_size, seq_len]
    
    # ëª©í‘œ ì†ì„±ê°’ì„ í…ì„œë¡œ ë³€í™˜
    target_tensors = {}
    for prop_name, prop_values in target_properties.items():
        # ê° ì‹œí€€ìŠ¤ì˜ ëª¨ë“  ìŠ¤í…ì— ëŒ€í•´ ë™ì¼í•œ ëª©í‘œê°’ ì‚¬ìš©
        prop_tensor = torch.zeros(batch_size, max_seq_len)
        for i, prop_val in enumerate(prop_values):
            prop_tensor[i, :] = prop_val
        target_tensors[prop_name] = prop_tensor
    
    # RTG ê³„ì‚° (ì‹¤ì œ RTG Calculator ì‚¬ìš©)
    if rtg_calculator is not None:
        try:
            # Property ëª¨ë¸ë¡œ ì˜ˆì¸¡
            predicted_properties = rtg_calculator.calculate_sequence_properties(
                batch_states, batch_masks
            )
            
            # í‘œì¤€ RL RTG ê³„ì‚°
            rtg_rewards = rtg_calculator.calculate_rtg_rewards(
                predicted_properties, target_tensors, batch_masks, gamma=0.99
            )
        except Exception as e:
            print(f"âš ï¸ RTG ê³„ì‚° ì˜¤ë¥˜: {e}")
            # í´ë°±: ê¸°ë³¸ê°’ ì‚¬ìš©
            rtg_rewards = torch.ones(batch_size, max_seq_len) * 0.5
    else:
        # RTG Calculatorê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’
        rtg_rewards = torch.ones(batch_size, max_seq_len) * 0.5
    
    return {
        'circuit_specs': circuit_specs,
        'states': batch_states,
        'actions': batch_actions,
        'attention_masks': batch_masks,
        'target_properties': target_tensors,
        'rtg_rewards': rtg_rewards
    }


# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    # ë°©ë²• 1: í†µí•© ë°ì´í„° íŒŒì¼ë¡œ ë¡œë”© (ê¶Œì¥)
    manager = DatasetManager(
        unified_data_path=r"C:\Users\jungh\Documents\GitHub\Kaist\OAT_Model\raw_data\merged_data.json"
    )
    
    # ë°©ë²• 2: ê°œë³„ íŒŒì¼ë¡œ ë¡œë”© (ë ˆê±°ì‹œ ì§€ì›)
    # manager = DatasetManager(
    #     results_path="path/to/results.json",
    #     circuits_path="path/to/circuits.json"
    # )
    
    # ë°©ë²• 3: ë³‘í•©ëœ ê²°ê³¼ íŒŒì¼ë¡œ ë¡œë”© (ë ˆê±°ì‹œ ì§€ì›)
    # manager = DatasetManager(
    #     merged_results_path="path/to/merged_results.json",
    #     circuits_path="path/to/circuits.json"
    # )
    
    # ë°ì´í„° ë³‘í•© (ê¸°ë³¸ì ìœ¼ë¡œ í’ˆì§ˆ í•„í„°ë§ í™œì„±í™”)
    circuit_data = manager.merge_data(enable_filtering=True)
    print(f"ì´ {len(circuit_data)}ê°œì˜ ìœ íš¨í•œ íšŒë¡œ ë°ì´í„° ë¡œë”© ì™„ë£Œ")
    print(f"í†µí•© ë°ì´í„° íŒŒì¼ ì‚¬ìš©: {manager.unified_data_path is not None}")
    
    # í†µê³„ ì •ë³´ ì¶œë ¥
    stats = manager.get_dataset_stats()
    print("\në°ì´í„°ì…‹ í†µê³„:")
    for key, value in stats.items():
        print(f"  {key}: {value}")
    
    # ë°ì´í„°ì…‹ ë¶„í• 
    train_dataset, val_dataset, test_dataset = manager.split_dataset()
    print(f"\në°ì´í„°ì…‹ ë¶„í•  ì™„ë£Œ:")
    print(f"  Train: {len(train_dataset)}")
    print(f"  Validation: {len(val_dataset)}")
    print(f"  Test: {len(test_dataset)}")
    
    # ì²« ë²ˆì§¸ ë°ì´í„° ìƒ˜í”Œ í™•ì¸
    if len(train_dataset) > 0:
        sample = train_dataset[0]
        print(f"\nì²« ë²ˆì§¸ ìƒ˜í”Œ:")
        print(f"  Circuit ID: {sample.circuit_id}")
        print(f"  Qubits: {sample.num_qubits}")
        print(f"  Gates: {len(sample.gates)}")
        print(f"  Fidelity: {sample.measurement_result.fidelity}")
        print(f"  Entanglement: {sample.measurement_result.entanglement}")

