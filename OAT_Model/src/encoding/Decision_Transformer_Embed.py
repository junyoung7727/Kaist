import os
import sys
import csv
import time
import math
from datetime import datetime
from typing import Dict, List, Any, Tuple, Optional

# ì¨ë“œíŒŒí‹° ë¼ì´ë¸ŒëŸ¬ë¦¬
import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
# Add quantumcommon to path
import sys
from pathlib import Path
sys.path.append(str(Path(__file__).parent.parent.parent.parent / "quantumcommon"))

from gates import QuantumGateRegistry

# Import unified debug utilities
import sys
from pathlib import Path
sys.path.append(str(Path(__file__).parent.parent / "utils"))
from debug_utils import dt_debug_log, dt_debug_tensor

class ActionTargetBuilder:
    """ ì•¡ì…˜ íƒ€ê²Ÿ ìƒì„± ì „ìš© í´ë˜ìŠ¤ - ë‹¨ì¼ ì±…ì„ ì›ì¹™"""
    
    @staticmethod
    def build_from_grid(grid_matrix_data, batch_size: int) -> Dict[str, torch.Tensor]:
        """ê·¸ë¦¬ë“œ ë§¤íŠ¸ë¦­ìŠ¤ ë°ì´í„°ë¡œë¶€í„° ì•¡ì…˜ íƒ€ê²Ÿ ìƒì„±"""
        if 'gates' not in grid_matrix_data:
            return ActionTargetBuilder._create_empty_targets(batch_size, 0)
        
        gates = grid_matrix_data['gates']
        num_gates = len(gates)
        
        # ë²¡í„°í™”ëœ íƒ€ê²Ÿ ìƒì„± (ë‹¨ì¼ ìƒ˜í”Œìš©)
        gate_targets = torch.zeros(num_gates, dtype=torch.long)
        # NEW: 2íë¹— ê²Œì´íŠ¸ ì „ìš© í˜•íƒœë¡œ ë³€ê²½ [qubit1, qubit2]
        position_targets = torch.full((num_gates, 2), -1, dtype=torch.long)
        parameter_targets = torch.zeros(num_gates, dtype=torch.float)
        
        # ê° ê²Œì´íŠ¸ë³„ë¡œ íƒ€ê²Ÿ ìƒì„± (ë°°ì¹˜ëŠ” í˜„ì¬ 1ê°œë§Œ ì²˜ë¦¬)
        for gate_idx, gate in enumerate(gates):
            if isinstance(gate, dict):
                # ê²Œì´íŠ¸ íƒ€ì… ì„¤ì •
                if 'gate_index' in gate:
                    gate_id = gate['gate_index']
                    if 0 <= gate_id < 20:  # ìœ íš¨í•œ ê²Œì´íŠ¸ë§Œ (EOS/PAD ì œì™¸)
                        gate_targets[gate_idx] = gate_id
                
                # íë¹— ìœ„ì¹˜ ì„¤ì • - 2íë¹— í˜•íƒœ ì§€ì›
                if 'qubits' in gate and gate['qubits'] is not None:
                    qubits = gate['qubits']
                    if isinstance(qubits, list) and len(qubits) > 0:
                        # ì²« ë²ˆì§¸ íë¹— ì„¤ì •
                        if len(qubits) >= 1 and qubits[0] >= 0:
                            position_targets[gate_idx, 0] = qubits[0]
                        
                        # ë‘ ë²ˆì§¸ íë¹— ì„¤ì •
                        if len(qubits) >= 2 and qubits[1] >= 0:
                            position_targets[gate_idx, 1] = qubits[1]
                        elif len(qubits) == 1 and qubits[0] >= 0:
                            # 1íë¹— ê²Œì´íŠ¸ì˜ ê²½ìš°: ê°™ì€ íë¹—ì„ ë‘ ë²ˆ ì‚¬ìš©
                            position_targets[gate_idx, 1] = qubits[0]
                
                # íŒŒë¼ë¯¸í„° ì„¤ì • (ê·¸ë¦¬ë“œ ë°ì´í„°ì—ì„œ ì§ì ‘ ì¶”ì¶œ)
                if 'parameter_value' in gate and gate['parameter_value'] is not None:
                    param_val = gate['parameter_value']
                    if not (isinstance(param_val, float) and math.isnan(param_val)):
                        parameter_targets[gate_idx] = float(param_val)

        
        return {
            'gate_targets': gate_targets,
            'position_targets': position_targets,
            'parameter_targets': parameter_targets
        }
    
    @staticmethod
    def _create_empty_targets(batch_size: int, num_gates: int) -> Dict[str, torch.Tensor]:
        """ë¹ˆ íƒ€ê²Ÿ ìƒì„± (íŒ¨ë”©ìš©)"""
        return {
            'gate_targets': torch.zeros(num_gates, dtype=torch.long),
            'position_targets': torch.full((num_gates, 2), -1, dtype=torch.long),  # 2íë¹— í˜•íƒœë¡œ ë³€ê²½
            'parameter_targets': torch.zeros(num_gates, dtype=torch.float)
        }

class QuantumGateSequenceEmbedding(nn.Module):
    def __init__(self, d_model: int = 512, n_gate_types: int = 20, max_pos: int = 1024, dropout: float = 0.1, device: str = 'cpu', property_prediction_model=None):
        """ì´ˆê¸°í™”
        
        Args:
            d_model: ëª¨ë¸ ì°¨ì›
            n_gate_types: ê²Œì´íŠ¸ íƒ€ì… ìˆ˜
            max_pos: ìµœëŒ€ ìœ„ì¹˜
            dropout: ë“œë¡­ì•„ì›ƒ ë¹„ìœ¨
            device: ëª¨ë¸ ë””ë°”ì´ìŠ¤
            property_prediction_model: í”„ë¡œí¼í‹° ì˜ˆì¸¡ ëª¨ë¸ (ë¦¬ì›Œë“œ ê³„ì‚°ì— ì‚¬ìš©)
        """
        super().__init__()
        
        self.d_model = d_model
        self.n_gate_types = n_gate_types
        self.max_pos = max_pos
        self.dropout = dropout
        self.property_prediction_model = property_prediction_model
        
        # ì„ë² ë”© ë ˆì´ì–´ë“¤ (ì •ë‹µë ˆì´ë¸”ê³¼ ë™ì¼í•œ í˜•íƒœ)
        # gate_type + position_vector + parameter
        gate_dim = d_model // 2      # 50% - ê²Œì´íŠ¸ íƒ€ì… (H, X, CNOT, RZ ë“±)
        position_dim = d_model // 4  # 25% - í¬ì§€ì…˜ ë²¡í„° (2íë¹— ìœ„ì¹˜)
        param_dim = d_model - gate_dim - position_dim  # ë‚˜ë¨¸ì§€ 25% - íŒŒë¼ë¯¸í„°
        
        self.gate_type_embed = nn.Embedding(n_gate_types, gate_dim)   # ê²Œì´íŠ¸ íƒ€ì… ID
        self.position_embed = nn.Linear(2, position_dim)              # í¬ì§€ì…˜ ë²¡í„° [qubit1, qubit2]
        self.param_embed = nn.Linear(1, param_dim)                    # ê²Œì´íŠ¸ íŒŒë¼ë¯¸í„°
        
        # ìœ„ì¹˜ ì¸ì½”ë”© (í•™ìŠµ ê°€ëŠ¥í•œ ì„ë² ë”©)
        self.positional_encoding = nn.Embedding(max_pos, d_model)
        
        # EOS (End-of-Sequence) íŠ¹ìˆ˜ í† í°
        self.eos_embed = nn.Parameter(torch.randn(d_model))            # íë¹— ì¸ë±ìŠ¤
        self.grid_position_embed = nn.Linear(2, d_model)              # (x, y) ì¢Œí‘œ
        
        # Decision Transformer ì»´í¬ë„ŒíŠ¸ë“¤
        self.state_embed = nn.Linear(d_model, d_model)     # ìƒíƒœ ì„ë² ë”©
        self.action_embed = nn.Linear(d_model, d_model)    # ì•¡ì…˜ ì„ë² ë”©  
        self.reward_embed = nn.Linear(1, d_model)          # ë¦¬ì›Œë“œ ì„ë² ë”©
        self.return_embed = nn.Linear(1, d_model)          # Return-to-go ì„ë² ë”©
        
        # ì‹œí€€ìŠ¤ íƒ€ì… ì„ë² ë”© (state/action/reward êµ¬ë¶„)
        self.type_embed = nn.Embedding(4, d_model)  # 0=state, 1=action, 2=reward, 3=return
        
        # ìœ„ì¹˜ ì¸ì½”ë”©
        self.register_buffer('pos_embed', self._create_positional_encoding())
        
        # ì •ê·œí™”
        self.layer_norm = nn.LayerNorm(d_model)
        self.dropout = nn.Dropout(0.1)
    
    def _create_positional_encoding(self) -> torch.Tensor:
        """ì˜¬ë°”ë¥¸ ìœ„ì¹˜ ì¸ì½”ë”© ìƒì„±"""
        pe = torch.zeros(self.max_pos, self.d_model)
        position = torch.arange(0, self.max_pos, dtype=torch.float).unsqueeze(1)
        
        div_term = torch.exp(torch.arange(0, self.d_model, 2).float() * 
                           (-math.log(10000.0) / self.d_model))
        
        pe[:, 0::2] = torch.sin(position * div_term)
        pe[:, 1::2] = torch.cos(position * div_term)
        
        return pe.unsqueeze(0)  # [1, max_pos, d_model]
    
    def mask(self, x: torch.Tensor) -> torch.Tensor:
        """
        ì‹œí€€ìŠ¤ì— ì–´í…ì…˜ì„ ì ìš©í•  ë•Œ, ìê¸°ë³´ë‹¤ ì´í›„ ìŠ¤í…Œì´íŠ¸ì˜ ê²Œì´íŠ¸ ë°°ì¹˜ë¥¼ ê°€ë¦¼
        
        Args:
            x: ì…ë ¥ ì‹œí€€ìŠ¤ [batch_size, seq_len, hidden_dim]
        
        Returns:
            mask: ì–´í…ì…˜ ë§ˆìŠ¤í¬ [seq_len, seq_len] (bool)
        """
        seq_len = x.size(1)
        
        # í•˜ì‚¼ê° ë§ˆìŠ¤í¬ ìƒì„± (causal mask)
        mask = torch.tril(torch.ones(seq_len, seq_len, device=x.device, dtype=torch.bool))
        
        # 0ì€ ë§ˆìŠ¤í‚¹, 1ì€ ì–´í…ì…˜ í—ˆìš©
        # Decision Transformerì—ì„œëŠ” í˜„ì¬ì™€ ì´ì „ íƒ€ì„ìŠ¤í…ë§Œ ì°¸ì¡° ê°€ëŠ¥
        return mask

    def state(self, x: torch.Tensor, gate_type_indices: torch.Tensor = None) -> torch.Tensor:
        """
        ì—í”¼ì†Œë“œ ì‹œí€€ìŠ¤ì— ëŒ€í•œ ìƒíƒœ ì„ë² ë”©
        
        Args:
            x: ì—í”¼ì†Œë“œ ì‹œí€€ìŠ¤ [episode_time_len, features]
            gate_type_indices: Long íƒ€ì… ê²Œì´íŠ¸ íƒ€ì… ì¸ë±ìŠ¤ [episode_time_len]
        
        Returns:
            state: ì¸ì½”ë”©ëœ ìƒíƒœ [episode_time_len, d_model]
        """
        # ğŸ” CRITICAL FIX: x ì°¨ì› ë™ì  ì²˜ë¦¬
        device = x.device
        
        dt_debug_tensor("state_input", x, detailed=True)
        
        # ì°¨ì›ì— ë”°ë¥¸ ë™ì  ì²˜ë¦¬
        if x.dim() == 2:
            episode_time_len, features = x.shape
        elif x.dim() == 3:
            # [batch_or_time, episode_time_len_or_qubits, features] í˜•íƒœ
            # ì‹¤ì œë¡œëŠ” [time_steps, num_qubits, features] í˜•íƒœì¼ ê°€ëŠ¥ì„±
            batch_or_time, episode_or_qubits, features = x.shape
            
            # 3D í…ì„œë¥¼ 2Dë¡œ flatten
            x = x.view(-1, features)  # [batch_or_time * episode_or_qubits, features]
            episode_time_len, features = x.shape
        else:
            raise ValueError(f"Unsupported tensor dimensions in state method: {x.shape}")
        
        # ìœ„ì¹˜ ì¸ë±ìŠ¤ ìƒì„± (ë””ë°”ì´ìŠ¤ ì¼ì¹˜ ë³´ì¥)
        position_indices = torch.arange(episode_time_len, device=device).long()
        # positional_encodingì´ CUDAì— ìˆëŠ”ì§€ í™•ì¸í•˜ê³  ì¸ë±ìŠ¤ë¥¼ ê°™ì€ ë””ë°”ì´ìŠ¤ë¡œ ì´ë™
        if next(self.positional_encoding.parameters()).device != device:
            position_indices = position_indices.to(next(self.positional_encoding.parameters()).device)
        position_emb = self.positional_encoding(position_indices)  # [episode_time_len, d_model]
        
        # ìƒíƒœ ì¸ì½”ë”© (ìƒˆë¡œìš´ í˜•íƒœ: [gate_type_id, qubit1, qubit2, parameter_value])
        if features >= 4:
            # í”¼ì²˜ ì¶”ì¶œ
            gate_type_ids = x[:, 0].long()      # [episode_time_len]
            positions = x[:, 1:3]               # [episode_time_len, 2] - [qubit1, qubit2]
            parameters = x[:, 3:4]              # [episode_time_len, 1]
            
            # ê°ê° ì„ë² ë”© (ë””ë°”ì´ìŠ¤ ì¼ì¹˜ ë³´ì¥)
            # embedding ë ˆì´ì–´ì˜ ë””ë°”ì´ìŠ¤ ì§ì ‘ í™•ì¸
            gate_embed_device = next(self.gate_type_embed.parameters()).device
            position_embed_device = next(self.position_embed.parameters()).device
            param_embed_device = next(self.param_embed.parameters()).device
            
            # í…ì„œë¥¼ ê° ì„ë² ë”© ë ˆì´ì–´ì˜ ë””ë°”ì´ìŠ¤ë¡œ ëª…ì‹œì  ì´ë™
            gate_type_ids = gate_type_ids.to(gate_embed_device)
            positions = positions.to(position_embed_device)
            parameters = parameters.to(param_embed_device)
            
            gate_embedded = self.gate_type_embed(gate_type_ids)    # [episode_time_len, gate_dim]
            position_embedded = self.position_embed(positions)     # [episode_time_len, position_dim]
            param_embedded = self.param_embed(parameters)          # [episode_time_len, param_dim]
            
            # ì„ë² ë”© ê²°í•© (concatenation)
            state_encoded = torch.cat([
                gate_embedded, 
                position_embedded, 
                param_embedded
            ], dim=-1)  # [episode_time_len, d_model]
        
        # ìœ„ì¹˜ ì„ë² ë”©ê³¼ ê²°í•©
        state = state_encoded + position_emb  # [episode_time_len, d_model]
        
        dt_debug_tensor("state_output", state, detailed=True)
        
        return state

    def action(self, episode_sequence: torch.Tensor, current_episode_time: int) -> torch.Tensor:
        """
        íŠ¹ì • ì—í”¼ì†Œë“œíƒ€ì„ì—ì„œì˜ ì•¡ì…˜ ìƒì„± (ë‹¤ìŒ ì—í”¼ì†Œë“œíƒ€ì„ì˜ ê²Œì´íŠ¸)
        ë¯¸ë˜ ì•¡ì…˜ì— ëŒ€í•œ ë§ˆìŠ¤í‚¹ í¬í•¨
        
        Args:
            episode_sequence: [episode_time_len, features] - ì „ì²´ ì—í”¼ì†Œë“œ ì‹œí€€ìŠ¤
            current_episode_time: í˜„ì¬ ì—í”¼ì†Œë“œíƒ€ì„ ì¸ë±ìŠ¤
        
        Returns:
            action: í˜„ì¬ ì—í”¼ì†Œë“œíƒ€ì„ì—ì„œì˜ ì•¡ì…˜ [d_model]
        """
        # ğŸ” CRITICAL FIX: episode_sequence ì°¨ì› ë™ì  ì²˜ë¦¬
        device = episode_sequence.device
        
        dt_debug_tensor("action_input", episode_sequence, detailed=True)
        
        # ì°¨ì›ì— ë”°ë¥¸ ë™ì  ì²˜ë¦¬
        if episode_sequence.dim() == 2:
            episode_time_len, features = episode_sequence.shape
        elif episode_sequence.dim() == 3:
            # [batch_or_time, episode_time_len_or_qubits, features] í˜•íƒœ
            # 3D í…ì„œë¥¼ 2Dë¡œ flatten
            batch_or_time, episode_or_qubits, features = episode_sequence.shape
            episode_sequence = episode_sequence.view(-1, features)  # [batch_or_time * episode_or_qubits, features]
            episode_time_len, features = episode_sequence.shape
        else:
            raise ValueError(f"Unsupported tensor dimensions in action method: {episode_sequence.shape}")
        
        if current_episode_time < episode_time_len - 1:
            # ë‹¤ìŒ ì—í”¼ì†Œë“œíƒ€ì„ì˜ ê²Œì´íŠ¸ë¥¼ ì•¡ì…˜ìœ¼ë¡œ ì‚¬ìš© (ë§ˆìŠ¤í‚¹ ì—†ìŒ)
            next_gate = episode_sequence[current_episode_time + 1].unsqueeze(0).unsqueeze(0)  # [1, 1, features]
            action_embedded = self._embed_episode_features(next_gate)  # [1, 1, d_model]
            action = self.action_embed(action_embedded).squeeze(0).squeeze(0)  # [d_model]
        else:
            # ë§ˆì§€ë§‰ ì—í”¼ì†Œë“œíƒ€ì„: ë¹„ì–´ìˆëŠ” ì•¡ì…˜ (ë§ˆìŠ¤í‚¹)
            # ë””ë°”ì´ìŠ¤ ì¼ê´€ì„±ì„ ìœ„í•´ ëª¨ë¸ ë””ë°”ì´ìŠ¤ í™•ì¸
            model_device = next(self.parameters()).device
            action = torch.zeros(self.d_model, device=model_device)
        
        dt_debug_tensor("action_output", action, detailed=True)
        
        return action
    
    def _embed_episode_features(self, episode_features: torch.Tensor) -> torch.Tensor:
        """
        ì—í”¼ì†Œë“œíƒ€ì„ ìˆœì„œì˜ í”¼ì²˜ë¥¼ ì„ë² ë”©
        
        Args:
            episode_features: [batch, episode_time_len, features]
        
        Returns:
            embedded: [batch, episode_time_len, d_model]
        """
        batch_size, episode_time_len, features = episode_features.shape
        
        dt_debug_tensor("embed_episode_features_input", episode_features, detailed=True)
        
        if features >= 4:  # [gate_type_id, qubit1, qubit2, parameter_value, ...]
            # ê° í”¼ì²˜ ì¶”ì¶œ (ì •ë‹µë ˆì´ë¸”ê³¼ ë™ì¼í•œ í˜•íƒœ)
            gate_type_ids = episode_features[:, :, 0].long()      # ê²Œì´íŠ¸ íƒ€ì… ID
            positions = episode_features[:, :, 1:3]               # í¬ì§€ì…˜ ë²¡í„° [qubit1, qubit2]
            parameters = episode_features[:, :, 3:4]              # íŒŒë¼ë¯¸í„° ê°’
            
            # ê°ê° ì„ë² ë”© (ë””ë°”ì´ìŠ¤ ì¼ì¹˜ ë³´ì¥)
            # embedding ë ˆì´ì–´ì˜ ë””ë°”ì´ìŠ¤ ì§ì ‘ í™•ì¸
            gate_embed_device = next(self.gate_type_embed.parameters()).device
            position_embed_device = next(self.position_embed.parameters()).device
            param_embed_device = next(self.param_embed.parameters()).device
            
            # í…ì„œë¥¼ ê° ì„ë² ë”© ë ˆì´ì–´ì˜ ë””ë°”ì´ìŠ¤ë¡œ ëª…ì‹œì  ì´ë™
            gate_type_ids = gate_type_ids.to(gate_embed_device)
            positions = positions.to(position_embed_device)
            parameters = parameters.to(param_embed_device)
            
            gate_embedded = self.gate_type_embed(gate_type_ids)   # [batch, episode_time, gate_dim]
            position_embedded = self.position_embed(positions)    # [batch, episode_time, position_dim]
            param_embedded = self.param_embed(parameters)         # [batch, episode_time, param_dim]
            
            # ì„ë² ë”© ê²°í•© (concatenation)
            embedded = torch.cat([
                gate_embedded, 
                position_embedded, 
                param_embedded
            ], dim=-1)  # [batch, episode_time, d_model]
        else:
            # ë‹¤ë¥¸ í”¼ì²˜ ì°¨ì›ì˜ ê²½ìš° ì„ í˜• ë³€í™˜
            linear_layer = nn.Linear(features, self.d_model).to(episode_features.device)
            embedded = linear_layer(episode_features)
        
        dt_debug_tensor("embed_episode_features_output", embedded, detailed=True)
        
        return embedded

    def reward(self, masked_state: torch.Tensor, action: torch.Tensor, current_episode_time: int, episode_time_len: int) -> torch.Tensor:
        """
        íŠ¹ì • ì—í”¼ì†Œë“œíƒ€ì„ì—ì„œì˜ ë¦¬ì›Œë“œ ìƒì„±
        ë¯¸ë˜ ë¦¬ì›Œë“œì— ëŒ€í•œ ë§ˆìŠ¤í‚¹ í¬í•¨
        
        Args:
            masked_state: í˜„ì¬ ì—í”¼ì†Œë“œíƒ€ì„ì—ì„œì˜ ë§ˆìŠ¤í‚¹ ìƒíƒœ [d_model]
            action: í˜„ì¬ ì—í”¼ì†Œë“œíƒ€ì„ì—ì„œì˜ ì•¡ì…˜ [d_model]
            current_episode_time: í˜„ì¬ ì—í”¼ì†Œë“œíƒ€ì„ ì¸ë±ìŠ¤
            episode_time_len: ì „ì²´ ì—í”¼ì†Œë“œ ì‹œê°„ ê¸¸ì´
        
        Returns:
            reward: í˜„ì¬ ì—í”¼ì†Œë“œíƒ€ì„ì—ì„œì˜ ë¦¬ì›Œë“œ [d_model]
        """
        device = masked_state.device
        
        dt_debug_tensor("reward_input", masked_state, detailed=True)
        dt_debug_tensor("reward_action", action, detailed=True)
        
        # ë¯¸ë˜ ë¦¬ì›Œë“œ ë§ˆìŠ¤í‚¹: í˜„ì¬ ì‹œì ì—ì„œë§Œ ë¦¬ì›Œë“œ ê³„ì‚° ê°€ëŠ¥
        if current_episode_time < episode_time_len:
            # ìƒíƒœ-ì•¡ì…˜ ìŒì—ì„œ ë¦¬ì›Œë“œ ê³„ì‚°
            state_action = torch.cat([masked_state, action], dim=0)  # [2*d_model]
            
            # í˜„ì¬ ëª¨ë¸ ë””ë°”ì´ìŠ¤ í™•ì¸
            model_device = next(self.parameters()).device
            
            # RTG Calculatorë¥¼ ì‚¬ìš©í•œ ì‹¤ì‹œê°„ ë¦¬ì›Œë“œ ê³„ì‚°
            # Property ëª¨ë¸ë¡œ í˜„ì¬ ìƒíƒœì˜ ì†ì„±ê°’ì„ ì˜ˆì¸¡í•˜ê³  ì •ë‹µê³¼ì˜ ê±°ë¦¬ë¥¼ ê¸°ë°˜ìœ¼ë¡œ RTG ê³„ì‚°
            
            if hasattr(self, 'rtg_calculator') and self.rtg_calculator is not None:
                # ìƒíƒœ-ì•¡ì…˜ì„ Property ëª¨ë¸ ì…ë ¥ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
                input_seq = state_action.unsqueeze(0).unsqueeze(0)  # [1, 1, 2*d_model]
                attn_mask = torch.ones((1, 1), dtype=torch.bool, device=model_device)
                
                # RTG Calculatorë¡œ ë¦¬ì›Œë“œ ê³„ì‚°
                rtg_value = self.rtg_calculator.calculate_single_step_rtg(
                    state_action=input_seq,
                    attention_mask=attn_mask,
                    current_step=current_episode_time,
                    total_steps=episode_time_len
                )
                
                reward_normalized = torch.tensor([rtg_value], device=model_device)
            else:
                # RTG Calculatorê°€ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ê°’
                reward_normalized = torch.tensor([0.5], device=model_device)
            
            # ë¦¬ì›Œë“œë¥¼ d_model ì°¨ì›ìœ¼ë¡œ ì„ë² ë”©
            # í˜„ì¬ ëª¨ë¸ ë””ë°”ì´ìŠ¤ì— ë§ëŠ” ë ˆì´ì–´ ìƒì„±
            reward_embed_layer = nn.Linear(1, self.d_model).to(model_device)
            reward = reward_embed_layer(reward_normalized.unsqueeze(0)).squeeze(0)  # [d_model]
        else:
            # ë¯¸ë˜ ë¦¬ì›Œë“œ ë§ˆìŠ¤í‚¹: ë¹„ì–´ìˆëŠ” ë¦¬ì›Œë“œ
            # ë””ë°”ì´ìŠ¤ ì¼ê´€ì„±ì„ ìœ„í•´ ëª¨ë¸ ë””ë°”ì´ìŠ¤ í™•ì¸
            model_device = next(self.parameters()).device
            reward = torch.zeros(self.d_model, device=model_device)
        
        dt_debug_tensor("reward_output", reward, detailed=True)
        
        return reward

    def create_input_sequence(self, state: torch.Tensor, action: torch.Tensor, reward: torch.Tensor) -> torch.Tensor:
        """
        state, action, rewardë¥¼ ìˆœì„œëŒ€ë¡œ êµ¬ì„±
        
        Args:
            state: ìƒíƒœ í…ì„œ [batch_size, seq_len, d_model]
            action: ì•¡ì…˜ í…ì„œ [batch_size, seq_len, d_model]
            reward: ë¦¬ì›Œë“œ í…ì„œ [batch_size, seq_len, d_model]
        
        Returns:
            sequence: ê²°í•©ëœ ì‹œí€€ìŠ¤ [batch_size, seq_len * 3, d_model]
        """
        batch_size, seq_len, d_model = state.shape
        
        dt_debug_tensor("create_input_sequence_state", state, detailed=True)
        dt_debug_tensor("create_input_sequence_action", action, detailed=True)
        dt_debug_tensor("create_input_sequence_reward", reward, detailed=True)
        
        # ê° íƒ€ì„ìŠ¤í…ì—ì„œ state, action, rewardë¥¼ ìˆœì„œëŒ€ë¡œ ë°°ì¹˜
        sequence_list = []
        
        for t in range(seq_len):
            # í˜„ì¬ íƒ€ì„ìŠ¤í…ì˜ state, action, reward
            curr_state = state[:, t:t+1, :]   # [batch_size, 1, d_model]
            curr_action = action[:, t:t+1, :] # [batch_size, 1, d_model]
            curr_reward = reward[:, t:t+1, :] # [batch_size, 1, d_model]
            
            # state, action, reward ìˆœì„œë¡œ ì¶”ê°€
            sequence_list.extend([curr_state, curr_action, curr_reward])
        
        # ì‹œí€€ìŠ¤ ê²°í•©
        sequence = torch.cat(sequence_list, dim=1)  # [batch_size, seq_len * 3, d_model]
        
        dt_debug_tensor("create_input_sequence_output", sequence, detailed=True)
        
        return sequence

    def create_input_sequence_batch(self, sequence: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:
        """
        ë°°ì¹˜ ì‹œí€€ìŠ¤ë¥¼ state, action, rewardë¡œ ë¶„ë¦¬
        
        Args:
            sequence: ê²°í•©ëœ ì‹œí€€ìŠ¤ [batch_size, seq_len * 3, d_model]
        
        Returns:
            state: ìƒíƒœ í…ì„œ [batch_size, seq_len, d_model]
            action: ì•¡ì…˜ í…ì„œ [batch_size, seq_len, d_model] 
            reward: ë¦¬ì›Œë“œ í…ì„œ [batch_size, seq_len, d_model]
        """
        batch_size, total_seq_len, d_model = sequence.shape
        seq_len = total_seq_len // 3
        
        dt_debug_tensor("create_input_sequence_batch_input", sequence, detailed=True)
        
        # ì‹œí€€ìŠ¤ë¥¼ 3ê°œì”© ê·¸ë£¹ìœ¼ë¡œ ë‚˜ëˆ„ì–´ state, action, reward ì¶”ì¶œ
        sequence_reshaped = sequence.view(batch_size, seq_len, 3, d_model)
        
        # ê° íƒ€ì„ìŠ¤í…ì—ì„œ state, action, reward ì¶”ì¶œ
        state = sequence_reshaped[:, :, 0, :]   # [batch_size, seq_len, d_model]
        action = sequence_reshaped[:, :, 1, :]  # [batch_size, seq_len, d_model]
        reward = sequence_reshaped[:, :, 2, :]  # [batch_size, seq_len, d_model]
        
        dt_debug_tensor("create_input_sequence_batch_state", state, detailed=True)
        dt_debug_tensor("create_input_sequence_batch_action", action, detailed=True)
        dt_debug_tensor("create_input_sequence_batch_reward", reward, detailed=True)
        
        return state, action, reward

    def forward(self, grid_states: torch.Tensor, 
                gate_actions: Optional[torch.Tensor] = None,
                rewards: Optional[torch.Tensor] = None) -> Dict[str, torch.Tensor]:
        """
        ë‹¨ì¼ ê·¸ë¦¬ë“œ ë§¤íŠ¸ë¦­ìŠ¤ ë‹¨ìœ„ë¡œ ìˆœì°¨ ì²˜ë¦¬ í›„ ë°°ì¹˜ í•©ì¹˜ê¸°
        
        Args:
            grid_states: ê·¸ë¦¬ë“œ ìƒíƒœ [batch_size, time_steps, num_qubits, features]
            gate_actions: ê²Œì´íŠ¸ ì•¡ì…˜ (ì„ íƒì )
            rewards: ë¦¬ì›Œë“œ (ì„ íƒì )
        
        Returns:
            Dict containing embedded sequences and components
        """
        batch_size = grid_states.shape[0]
        batch_results = []
        
        dt_debug_tensor("forward_grid_states", grid_states, detailed=True)
        
        # ê° ë°°ì¹˜ ìƒ˜í”Œì„ ê°œë³„ë¡œ ì²˜ë¦¬
        for b in range(batch_size):
            single_grid = grid_states[b]  # [time_steps, num_qubits, features]
            
            # ë‹¨ì¼ ê·¸ë¦¬ë“œì— ëŒ€í•œ ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
            single_result = self._process_single_grid(single_grid)
            batch_results.append(single_result)
        
        # ë°°ì¹˜ ì°¨ì›ìœ¼ë¡œ í•©ì¹˜ê¸°
        return self._combine_batch_results(batch_results)
    
    def _process_single_grid(self, single_grid: torch.Tensor, actual_gate_count: int, grid_matrix_data: Dict[str, Any] = None, max_seq_len: int = None) -> Dict[str, torch.Tensor]:
        """
        ğŸš€ NEW: ìˆœìˆ˜ ê²Œì´íŠ¸ ìˆ˜ ê¸°ë°˜ ë‹¨ìˆœ ì²˜ë¦¬ (íŒ¨ë”© ì§€ì›)
        
        Args:
            single_grid: [time_steps, num_qubits, features] ë˜ëŠ” [total_gates, features]
            actual_gate_count: ì‹¤ì œ ê²Œì´íŠ¸ ìˆ˜ (ë©”íƒ€ë°ì´í„°ì—ì„œ ì „ë‹¬)
            grid_matrix_data: ì›ë³¸ ê·¸ë¦¬ë“œ ë§¤íŠ¸ë¦­ìŠ¤ ë°ì´í„° (íƒ€ê²Ÿ ìƒì„±ì— í•„ìš”)
            max_seq_len: ë°°ì¹˜ ë‚´ ìµœëŒ€ ì‹œí€€ìŠ¤ ê¸¸ì´ (íŒ¨ë”©ìš©)
        
        Returns:
            Dict containing single sample results (padded if max_seq_len provided)
        """
        device = single_grid.device
        
        dt_debug_tensor("_process_single_grid_input", single_grid, detailed=True)
        
        # ì‹¤ì œ ê²Œì´íŠ¸ ìˆ˜ ê¸°ë°˜ SAR ì‹œí€€ìŠ¤ ê¸¸ì´ ê³„ì‚°
        sar_sequence_len = actual_gate_count * 3
        actual_sequence_len = sar_sequence_len + 1  # EOS í† í° í¬í•¨
        
        # íŒ¨ë”© ê¸¸ì´ ê²°ì • (ë°°ì¹˜ ë ˆë²¨ ìµœëŒ€ ê¸¸ì´ ì‚¬ìš©)
        if max_seq_len is not None:
            sequence_len = max_seq_len
        else:
            sequence_len = actual_sequence_len
        
        # ë””ë°”ì´ìŠ¤ ì¼ê´€ì„±ì„ ìœ„í•´ ëª¨ë¸ ë””ë°”ì´ìŠ¤ í™•ì¸
        model_device = next(self.parameters()).device
        
        # ì‹¤ì œ ê²Œì´íŠ¸ ë°ì´í„°ë¡œë¶€í„° ì„ë² ë”© ìƒì„±
        # ì…ë ¥ ë°ì´í„°ë¥¼ ì‹¤ì œ ê²Œì´íŠ¸ ì •ë³´ë¡œ ë³€í™˜
        gate_features = single_grid
        
        # ì…ë ¥ í…ì„œ í˜•íƒœ í™•ì¸ ë° ì²˜ë¦¬
        dt_debug_tensor("gate_features_shape", gate_features, detailed=True)
        
        # ê° ì—í”¼ì†Œë“œ íƒ€ì„ë³„ ëˆ„ì  ìƒíƒœ ì„ë² ë”© ìƒì„±
        state_emb = []
        
        for i in range(actual_gate_count):
            if i == 0:
                # ì²« ë²ˆì§¸ ìŠ¤í…Œì´íŠ¸ëŠ” ë¹ˆ ìƒíƒœ (ì•„ë¬´ ê²Œì´íŠ¸ë„ ì—†ìŒ)
                empty_state = torch.zeros(self.d_model, device=model_device)
                state_emb.append(empty_state)
            else:
                # ië²ˆì§¸ ìŠ¤í…Œì´íŠ¸ëŠ” 0ë¶€í„° i-1ë²ˆì§¸ ê²Œì´íŠ¸ê¹Œì§€ ì¶”ê°€ëœ íšŒë¡œ ìƒíƒœ
                if grid_matrix_data is not None:
                    # ì›ë³¸ ê·¸ë¦¬ë“œ ë°ì´í„°ì—ì„œ iê°œ ê²Œì´íŠ¸ë§Œ ì‚¬ìš©í•œ ë¶€ë¶„ íšŒë¡œ ìƒì„±
                    partial_circuit_data = self._create_partial_circuit_state(grid_matrix_data, i)
                    # ë¶€ë¶„ íšŒë¡œ ì „ì²´ë¥¼ í•˜ë‚˜ì˜ ìƒíƒœë¡œ ì„ë² ë”©
                    circuit_state_tensor = self._convert_circuit_state_to_tensor(partial_circuit_data)
                    current_state = self.state(circuit_state_tensor).squeeze(0)  # [d_model]
                else:
                    # ê·¸ë¦¬ë“œ ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ê²Œì´íŠ¸ ì‹œí€€ìŠ¤ë¥¼ íšŒë¡œ ìƒíƒœë¡œ ë³€í™˜
                    cumulative_gates = gate_features[:i]  # [i, features] - ì§€ê¸ˆê¹Œì§€ ì¶”ê°€ëœ ê²Œì´íŠ¸ë“¤
                    circuit_representation = self._build_circuit_state_from_gates(cumulative_gates)
                    current_state = self.state(circuit_representation.unsqueeze(0)).squeeze(0)  # [d_model]
                
                state_emb.append(current_state)
        
        state_emb = torch.stack(state_emb, dim=0)  # [actual_gate_count, d_model]
        
        dt_debug_tensor("state_embeddings", state_emb, detailed=True)
        
        # ì•¡ì…˜ ì„ë² ë”©: ê° ìŠ¤í…ì—ì„œ ì‹¤ì œë¡œ ì„ íƒëœ ê²Œì´íŠ¸ (ì •ë‹µ ë ˆì´ë¸”)
        action_emb = []
        for i in range(actual_gate_count):
            current_gate = gate_features[i:i+1]  # [1, features] - ië²ˆì§¸ ê²Œì´íŠ¸
            gate_embedded = self.state(current_gate)  # [1, d_model]
            action_emb.append(gate_embedded.squeeze(0))
        action_emb = torch.stack(action_emb, dim=0)  # [actual_gate_count, d_model]
        
        # ë¦¬ì›Œë“œ ì„ë² ë”©ì€ ì¼ë‹¨ ì´ˆê¸°í™” (RTG ê³„ì‚°ì—ì„œ ì±„ì›Œì§)
        reward_emb = torch.zeros(actual_gate_count, self.d_model, device=model_device)
        
        # SAR ì‹œí€€ìŠ¤ ìƒì„±
        sar_sequence = torch.zeros(sar_sequence_len, self.d_model, device=model_device)
        for i in range(actual_gate_count):
            base_idx = i * 3
            sar_sequence[base_idx] = state_emb[i]      # State
            sar_sequence[base_idx + 1] = action_emb[i]  # Action
            sar_sequence[base_idx + 2] = reward_emb[i]  # Reward
        
        # EOS í† í° ì¶”ê°€
        actual_input_sequence = torch.cat([sar_sequence, self.eos_embed.unsqueeze(0)], dim=0)
        
        # íŒ¨ë”© ì ìš© (í•„ìš”í•œ ê²½ìš°)
        if sequence_len > actual_sequence_len:
            # íŒ¨ë”© í† í°ìœ¼ë¡œ ì±„ìš°ê¸°
            padding_len = sequence_len - actual_sequence_len
            # ëª¨ë¸ ë””ë°”ì´ìŠ¤ ì‚¬ìš©
            padding = torch.zeros(padding_len, self.d_model, device=model_device)
            input_sequence = torch.cat([actual_input_sequence, padding], dim=0)
        else:
            input_sequence = actual_input_sequence
        
        dt_debug_tensor("_process_single_grid_output", input_sequence, detailed=True)
        
        # ì–´í…ì…˜ ë§ˆìŠ¤í¬ ìƒì„± (causal mask) - ëª¨ë¸ ë””ë°”ì´ìŠ¤ ì‚¬ìš©
        attention_mask = torch.tril(torch.ones(sequence_len, sequence_len, device=model_device, dtype=torch.bool))
        
        # ì•¡ì…˜ ì˜ˆì¸¡ ë§ˆìŠ¤í¬ ìƒì„± (1::3 íŒ¨í„´, ì‹¤ì œ ê¸¸ì´ë§Œ) - ëª¨ë¸ ë””ë°”ì´ìŠ¤ ì‚¬ìš©
        action_prediction_mask = torch.zeros(sequence_len, dtype=torch.bool, device=model_device)
        # ì‹¤ì œ ê²Œì´íŠ¸ ìœ„ì¹˜ì—ë§Œ True ì„¤ì •
        for i in range(actual_gate_count):
            action_idx = i * 3 + 1  # 1, 4, 7, 10... ìœ„ì¹˜ (ì•¡ì…˜ ìœ„ì¹˜)
            if action_idx < sequence_len:
                action_prediction_mask[action_idx] = True
        
        # ì•¡ì…˜ íƒ€ê²Ÿ ìƒì„± (í•™ìŠµì— í•„ìš”)
        target_tensors = {}
        if grid_matrix_data is not None:
            # ActionTargetBuilderë¥¼ ì‚¬ìš©í•˜ì—¬ íƒ€ê²Ÿ í…ì„œ ìƒì„±
            action_targets = ActionTargetBuilder.build_from_grid(grid_matrix_data, batch_size=1)
            
            # íƒ€ê²Ÿ í…ì„œ ì¶”ì¶œ
            if 'gate_targets' in action_targets:
                target_tensors['target_actions'] = action_targets['gate_targets']
            if 'position_targets' in action_targets:
                target_tensors['target_qubits'] = action_targets['position_targets']
            if 'parameter_targets' in action_targets:
                target_tensors['target_params'] = action_targets['parameter_targets']
        
        # íƒ€ê²Ÿ í…ì„œê°€ ì—†ëŠ” ê²½ìš° ë”ë¯¸ ìƒì„± - ëª¨ë¸ ë””ë°”ì´ìŠ¤ ì‚¬ìš©
        if 'target_actions' not in target_tensors:
            target_tensors['target_actions'] = torch.zeros(actual_gate_count, dtype=torch.long, device=model_device)
        if 'target_qubits' not in target_tensors:
            target_tensors['target_qubits'] = torch.full((actual_gate_count, 2), -1, dtype=torch.long, device=model_device)
        if 'target_params' not in target_tensors:
            target_tensors['target_params'] = torch.zeros(actual_gate_count, dtype=torch.float, device=model_device)
        
        result = {
            'input_sequence': input_sequence,           # [sequence_len, d_model]
            'attention_mask': attention_mask,           # [sequence_len, sequence_len]
            'action_prediction_mask': action_prediction_mask,  # [sequence_len]
            'state_embedded': state_emb,                # [actual_gate_count, d_model]
            'action_embedded': action_emb,              # [actual_gate_count, d_model]
            'reward_embedded': reward_emb,              # [actual_gate_count, d_model]
            'episode_time_len': torch.tensor(actual_gate_count, device=model_device),
            'sar_sequence_len': torch.tensor(sar_sequence_len, device=model_device),
            'target_actions': target_tensors['target_actions'],  # [actual_gate_count]
            'target_qubits': target_tensors['target_qubits'],    # [actual_gate_count, 2]
            'target_params': target_tensors['target_params']     # [actual_gate_count]
        }
        
        return result
    
    def _create_episode_mask(self, episode_sequence: torch.Tensor, current_episode_time: int) -> torch.Tensor:
        """
        ì—í”¼ì†Œë“œíƒ€ì„ ê¸°ì¤€ ë§ˆìŠ¤í‚¹: current_episode_timeê¹Œì§€ë§Œ ê³µê°œ
        
        Args:
            episode_sequence: [episode_time_len, features]
            current_episode_time: í˜„ì¬ ì—í”¼ì†Œë“œ ì‹œê°„
        
        Returns:
            masked_sequence: [episode_time_len, features]
        """
        masked_sequence = torch.zeros_like(episode_sequence)
        if current_episode_time > 0:
            masked_sequence[:current_episode_time] = episode_sequence[:current_episode_time]
        return masked_sequence
    
    def _combine_batch_results(self, batch_results: List[Dict[str, torch.Tensor]]) -> Dict[str, torch.Tensor]:
        """
        ê°œë³„ ì²˜ë¦¬ëœ ê²°ê³¼ë“¤ì„ ë°°ì¹˜ ì°¨ì›ìœ¼ë¡œ í•©ì¹˜ê¸°
        
        Args:
            batch_results: ê° ìƒ˜í”Œì˜ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        
        Returns:
            ë°°ì¹˜ ì°¨ì›ìœ¼ë¡œ í•©ì³ì§„ ê²°ê³¼
        """
        if not batch_results:
            return {}
        
        combined = {}
        for key in batch_results[0].keys():
            combined[key] = torch.stack([result[key] for result in batch_results], dim=0)
        
        return combined
    
    def _build_circuit_state_from_gates(self, gate_sequence: torch.Tensor) -> torch.Tensor:
        """ê²Œì´íŠ¸ ì‹œí€€ìŠ¤ë¡œë¶€í„° íšŒë¡œ ìƒíƒœ í‘œí˜„ ìƒì„±"""
        if len(gate_sequence) == 0:
            return torch.zeros(1, 4, device=next(self.parameters()).device)
        
        # ê²Œì´íŠ¸ ì‹œí€€ìŠ¤ë¥¼ íšŒë¡œ ìƒíƒœë¡œ ë³€í™˜ (ë‹¨ìˆœíˆ ëª¨ë“  ê²Œì´íŠ¸ì˜ ì •ë³´ë¥¼ í•©ì„±)
        # ê° ê²Œì´íŠ¸ê°€ íšŒë¡œì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ ëˆ„ì ì ìœ¼ë¡œ í‘œí˜„
        circuit_state = torch.zeros(4, device=gate_sequence.device)
        
        for gate in gate_sequence:
            # ê° ê²Œì´íŠ¸ì˜ ì •ë³´ë¥¼ íšŒë¡œ ìƒíƒœì— ëˆ„ì 
            circuit_state += gate
        
        # ì •ê·œí™”í•˜ì—¬ ì•ˆì •ì ì¸ í‘œí˜„ ìƒì„±
        circuit_state = circuit_state / len(gate_sequence)
        return circuit_state.unsqueeze(0)  # [1, 4]
    
    def _create_partial_circuit_state(self, grid_matrix_data: Dict[str, Any], num_gates: int) -> Dict[str, Any]:
        """ë¶€ë¶„ íšŒë¡œ ìƒíƒœ ìƒì„± (ì²˜ìŒ num_gatesê°œë§Œ í¬í•¨)"""
        if 'gates' not in grid_matrix_data:
            return {'gates': []}
        
        original_gates = grid_matrix_data['gates']
        partial_gates = original_gates[:num_gates]
        
        # ë¶€ë¶„ íšŒë¡œ ë°ì´í„° ìƒì„±
        partial_data = {
            'gates': partial_gates,
            'num_qubits': grid_matrix_data.get('num_qubits', 10),
            'depth': min(grid_matrix_data.get('depth', 0), num_gates)
        }
        
        return partial_data
    
    def create_incremental_state_embedding(self, current_circuit_gates: List[Dict], predicted_gate: Dict, num_qubits: int = 10) -> torch.Tensor:
        """
        ì¸í¼ëŸ°ìŠ¤ìš©: ê¸°ì¡´ íšŒë¡œì— ì˜ˆì¸¡ëœ ê²Œì´íŠ¸ë¥¼ ì¶”ê°€í•œ ìƒˆë¡œìš´ ìƒíƒœ ì„ë² ë”© ìƒì„±
        
        Args:
            current_circuit_gates: í˜„ì¬ê¹Œì§€ì˜ íšŒë¡œ ê²Œì´íŠ¸ ë¦¬ìŠ¤íŠ¸
            predicted_gate: ìƒˆë¡œ ì˜ˆì¸¡ëœ ê²Œì´íŠ¸ ì •ë³´ {'gate_name': str, 'qubits': List[int], 'parameter_value': float}
            num_qubits: íšŒë¡œì˜ íë¹— ìˆ˜
            
        Returns:
            ìƒˆë¡œìš´ ìƒíƒœ ì„ë² ë”© [d_model]
        """
        # ê¸°ì¡´ ê²Œì´íŠ¸ ë¦¬ìŠ¤íŠ¸ì— ì˜ˆì¸¡ëœ ê²Œì´íŠ¸ ì¶”ê°€
        updated_gates = current_circuit_gates.copy()
        updated_gates.append(predicted_gate)
        
        # ì—…ë°ì´íŠ¸ëœ íšŒë¡œ ë°ì´í„° ìƒì„±
        updated_circuit_data = {
            'gates': updated_gates,
            'num_qubits': num_qubits,
            'depth': len(updated_gates)
        }
        
        # ìƒˆë¡œìš´ íšŒë¡œ ìƒíƒœë¥¼ í…ì„œë¡œ ë³€í™˜
        circuit_state_tensor = self._convert_circuit_state_to_tensor(updated_circuit_data)
        
        # ìƒíƒœ ì„ë² ë”© ìƒì„±
        new_state_embedding = self.state(circuit_state_tensor).squeeze(0)  # [d_model]
        
        return new_state_embedding
    
    def update_sar_sequence_with_prediction(self, current_sar_sequence: torch.Tensor, 
                                          current_circuit_gates: List[Dict],
                                          predicted_gate: Dict,
                                          predicted_reward: float = 0.0,
                                          num_qubits: int = 10) -> torch.Tensor:
        """
        ì¸í¼ëŸ°ìŠ¤ìš©: ì˜ˆì¸¡ëœ ê²Œì´íŠ¸ë¡œ SAR ì‹œí€€ìŠ¤ ì—…ë°ì´íŠ¸
        
        Args:
            current_sar_sequence: í˜„ì¬ SAR ì‹œí€€ìŠ¤ [seq_len, d_model]
            current_circuit_gates: í˜„ì¬ê¹Œì§€ì˜ íšŒë¡œ ê²Œì´íŠ¸ ë¦¬ìŠ¤íŠ¸
            predicted_gate: ì˜ˆì¸¡ëœ ê²Œì´íŠ¸ ì •ë³´
            predicted_reward: ì˜ˆì¸¡ëœ ë¦¬ì›Œë“œ ê°’
            num_qubits: íšŒë¡œì˜ íë¹— ìˆ˜
            
        Returns:
            ì—…ë°ì´íŠ¸ëœ SAR ì‹œí€€ìŠ¤ [seq_len+3, d_model]
        """
        device = current_sar_sequence.device
        
        # 1. ìƒˆë¡œìš´ ìƒíƒœ ì„ë² ë”© ìƒì„± (ì˜ˆì¸¡ëœ ê²Œì´íŠ¸ê°€ ì¶”ê°€ëœ íšŒë¡œ ìƒíƒœ)
        new_state_emb = self.create_incremental_state_embedding(current_circuit_gates, predicted_gate, num_qubits)
        new_state_emb = new_state_emb.to(device)
        
        # 2. ì˜ˆì¸¡ëœ ì•¡ì…˜ ì„ë² ë”© ìƒì„±
        gate_registry = QuantumGateRegistry()
        gate_vocab = gate_registry.get_gate_vocab()
        gate_type_id = gate_vocab.get(predicted_gate.get('gate_name', 'unknown'), 0)
        
        qubits = predicted_gate.get('qubits', [0, 0])
        qubit1 = qubits[0] if len(qubits) > 0 else 0
        qubit2 = qubits[1] if len(qubits) > 1 else qubit1
        parameter_value = predicted_gate.get('parameter_value', 0.0)
        
        # ê²Œì´íŠ¸ ì •ë³´ë¥¼ í…ì„œë¡œ ë³€í™˜
        gate_tensor = torch.tensor([[gate_type_id, qubit1, qubit2, parameter_value]], 
                                 dtype=torch.float32, device=device)
        action_emb = self.state(gate_tensor).squeeze(0)  # [d_model]
        
        # 3. ë¦¬ì›Œë“œ ì„ë² ë”© ìƒì„±
        reward_tensor = torch.tensor([predicted_reward], device=device)
        reward_emb = self.reward_embed(reward_tensor.unsqueeze(0)).squeeze(0)  # [d_model]
        
        # 4. ìƒˆë¡œìš´ SAR íŠ¸ë¦¬í”Œë¦¿ ìƒì„±
        new_sar_triplet = torch.stack([new_state_emb, action_emb, reward_emb], dim=0)  # [3, d_model]
        
        # 5. ê¸°ì¡´ ì‹œí€€ìŠ¤ì— ì¶”ê°€
        updated_sequence = torch.cat([current_sar_sequence, new_sar_triplet], dim=0)
        
        return updated_sequence
    
    def _convert_circuit_state_to_tensor(self, circuit_data: Dict[str, Any]) -> torch.Tensor:
        """íšŒë¡œ ìƒíƒœë¥¼ í…ì„œë¡œ ë³€í™˜"""
        gates = circuit_data.get('gates', [])
        
        if not gates:
            # ë¹ˆ íšŒë¡œì¸ ê²½ìš°
            return torch.zeros(1, 4, device=next(self.parameters()).device)
        
        # íšŒë¡œ ìƒíƒœë¥¼ ê·¸ë¦¬ë“œ í˜•íƒœë¡œ í‘œí˜„
        gate_sequence = []
        for gate in gates:
            if isinstance(gate, dict):
                gate_name = gate.get('gate_name', 'unknown')
                gate_registry = QuantumGateRegistry()
                gate_vocab = gate_registry.get_gate_vocab()
                gate_type_id = gate_vocab.get(gate_name, gate_vocab.get('[EMPTY]', 0))
                
                qubits = gate.get('qubits', [])
                qubit1 = qubits[0] if len(qubits) > 0 else 0
                qubit2 = qubits[1] if len(qubits) > 1 else qubit1
                
                parameter_value = 0.0
                if 'parameter_value' in gate:
                    parameter_value = float(gate['parameter_value'])
                elif 'parameters' in gate and gate['parameters']:
                    parameter_value = float(gate['parameters'][0])
                
                gate_sequence.append([gate_type_id, qubit1, qubit2, parameter_value])
        
        if gate_sequence:
            circuit_tensor = torch.tensor(gate_sequence, dtype=torch.float32, device=next(self.parameters()).device)
            # íšŒë¡œ ì „ì²´ ìƒíƒœë¥¼ í•˜ë‚˜ì˜ ë²¡í„°ë¡œ ìš”ì•½ (í‰ê· )
            return circuit_tensor.mean(dim=0, keepdim=True)  # [1, 4]
        else:
            return torch.zeros(1, 4, device=next(self.parameters()).device)

    def convert_grid_matrix_to_tensor(self, grid_matrix_data: Dict[str, Any]) -> Dict[str, torch.Tensor]:
        """
        ê·¸ë¦¬ë“œ ë§¤íŠ¸ë¦­ìŠ¤ ë°ì´í„°ë¥¼ ìˆœìˆ˜ ê²Œì´íŠ¸ ì‹œí€€ìŠ¤ë¡œ ë³€í™˜ (ë¶„ë¦¬í•˜ì§€ ì•ŠìŒ)
        
        Args:
            grid_matrix_data: to_grid_matrix()ì˜ ì¶œë ¥
        
        Returns:
            ìˆœìˆ˜ ê²Œì´íŠ¸ ì‹œí€€ìŠ¤ í…ì„œ [gate_type_id, qubit1, qubit2, parameter_value]
        """
        from gates import QuantumGateRegistry
        
        gates = grid_matrix_data.get('gates', [])
        
        # gates ëª¨ë“ˆì—ì„œ gate_vocab ê°€ì ¸ì˜¤ê¸°
        gate_registry = QuantumGateRegistry()
        gate_vocab = gate_registry.get_gate_vocab()
        
        # ìˆœìˆ˜ ê²Œì´íŠ¸ ì‹œí€€ìŠ¤ ìƒì„± (ë¶„ë¦¬í•˜ì§€ ì•ŠìŒ)
        gate_sequence = []
        
        for gate in gates:
            if isinstance(gate, dict):
                gate_name = gate.get('gate_name', 'unknown')
                gate_type_id = gate_vocab.get(gate_name, gate_vocab.get('[EMPTY]', 0))
                
                # íë¹— ìœ„ì¹˜ ì •ë³´
                qubits = gate.get('qubits', [])
                qubit1 = qubits[0] if len(qubits) > 0 else 0
                qubit2 = qubits[1] if len(qubits) > 1 else qubit1  # 1íë¹— ê²Œì´íŠ¸ëŠ” ê°™ì€ ê°’
                
                # íŒŒë¼ë¯¸í„° ì •ë³´
                parameter_value = 0.0
                if 'parameter_value' in gate:
                    parameter_value = float(gate['parameter_value'])
                elif 'parameters' in gate and gate['parameters']:
                    parameter_value = float(gate['parameters'][0])
                
                # ê²Œì´íŠ¸ ì •ë³´ ì¶”ê°€ [gate_type_id, qubit1, qubit2, parameter_value]
                gate_sequence.append([gate_type_id, qubit1, qubit2, parameter_value])
        
        # í…ì„œë¡œ ë³€í™˜
        if gate_sequence:
            gate_tensor = torch.tensor(gate_sequence, dtype=torch.float32).unsqueeze(0)  # [1, num_gates, 4]
            gate_type_tensor = torch.tensor([seq[0] for seq in gate_sequence], dtype=torch.long).unsqueeze(0)  # [1, num_gates]
        else:
            gate_tensor = torch.zeros(1, 0, 4, dtype=torch.float32)
            gate_type_tensor = torch.zeros(1, 0, dtype=torch.long)
        
        return {
            'grid_tensor': gate_tensor,
            'gate_type_indices': gate_type_tensor
        }
        

    def visualize_grid_tensor(self, grid_tensor: torch.Tensor) -> str:
        """
        ê·¸ë¦¬ë“œ í…ì„œë¥¼ ì‹œê°í™” (x,y êµ¬ì¡°)
        
        Args:
            grid_tensor: [1, time_steps, num_qubits, features] í˜•íƒœì˜ í…ì„œ
        
        Returns:
            ì‹œê°í™”ëœ ê·¸ë¦¬ë“œ ë¬¸ìì—´
        """
        batch_size, time_steps, num_qubits, features = grid_tensor.shape
        
        # ì²« ë²ˆì§¸ ë°°ì¹˜ë§Œ ì‹œê°í™”
        tensor_2d = grid_tensor[0, :, :, 1]  # occupation ì •ë³´ë§Œ ì‚¬ìš©
        
        visualization = "\nê·¸ë¦¬ë“œ ì‹œê°í™” (x=ì‹œê°„, y=íë¹—):\n"
        visualization += "   " + "".join([f"{t:3d}" for t in range(time_steps)]) + "\n"
        
        for qubit_idx in range(num_qubits):
            row = f"q{qubit_idx}: "
            for time_idx in range(time_steps):
                if tensor_2d[time_idx, qubit_idx] > 0:
                    gate_type = int(grid_tensor[0, time_idx, qubit_idx, 0].item())
                    row += f"{gate_type:3d}"
                else:
                    row += "  ."
            visualization += row + "\n"
        
        return visualization

    def process_grid_matrix_data_simple(self, grid_matrix_data: Dict[str, Any], actual_gate_count: int, max_seq_len: int = None) -> Dict[str, torch.Tensor]:
        """
        ìˆœìˆ˜ ê²Œì´íŠ¸ ì‹œí€€ìŠ¤ ê¸°ë°˜ Decision Transformer ì…ë ¥ ìƒì„± (ë¶„ë¦¬í•˜ì§€ ì•ŠìŒ)
        
        Args:
            grid_matrix_data: to_grid_matrix()ì˜ ì¶œë ¥
            actual_gate_count: ì‹¤ì œ ê²Œì´íŠ¸ ìˆ˜
            max_seq_len: ë°°ì¹˜ ë‚´ ìµœëŒ€ ì‹œí€€ìŠ¤ ê¸¸ì´ (íŒ¨ë”©ìš©)
        
        Returns:
            Dict containing all Decision Transformer inputs (padded if max_seq_len provided)
        """
        # ìˆœìˆ˜ ê²Œì´íŠ¸ ì‹œí€€ìŠ¤ë¡œ ë³€í™˜ (ë¶„ë¦¬í•˜ì§€ ì•ŠìŒ)
        tensor_data = self.convert_grid_matrix_to_tensor(grid_matrix_data)
        gate_sequence = tensor_data['grid_tensor']  # [1, num_gates, 4]
        
        # ë‹¨ì¼ ì‹œí€€ìŠ¤ ì¶”ì¶œ
        single_sequence = gate_sequence[0]  # [num_gates, 4]
        
        # ìˆœìˆ˜ ì‹œí€€ìŠ¤ ì²˜ë¦¬ (íŒ¨ë”© ê¸¸ì´ ì „ë‹¬)
        results = self._process_single_grid(single_sequence, actual_gate_count, grid_matrix_data, max_seq_len)
        
        return results
