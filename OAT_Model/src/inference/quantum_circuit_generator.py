"""
Quantum Circuit Generator using Trained Decision Transformer

í•™ìŠµëœ Decision Transformer ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì–‘ì íšŒë¡œë¥¼ ìƒì„±í•˜ëŠ” ëª¨ë“ˆ
"""

import torch
import torch.nn.functional as F
import numpy as np
from typing import Dict, List, Optional, Tuple, Any
from pathlib import Path
import sys
import json
from dataclasses import dataclass

# í”„ë¡œì íŠ¸ ëª¨ë“ˆ ì„í¬íŠ¸
sys.path.append(str(Path(__file__).parent.parent))
from models.decision_transformer import DecisionTransformer
from data.embedding_pipeline import EmbeddingPipeline, EmbeddingConfig
from data.quantum_circuit_dataset import CircuitSpec

# quantumcommon ëª¨ë“ˆ ì„í¬íŠ¸
sys.path.append(str(Path(__file__).parent.parent.parent.parent / "quantumcommon"))
from gates import QuantumGateRegistry, GateOperation


@dataclass
class GenerationConfig:
    """íšŒë¡œ ìƒì„± ì„¤ì •"""
    max_circuit_length: int = 50
    target_num_qubits: int = 4
    temperature: float = 1.0
    top_k: int = 10
    top_p: float = 0.9
    do_sample: bool = True
    
    # ëª©í‘œ ë©”íŠ¸ë¦­ (ì„ íƒì )
    target_fidelity: Optional[float] = None
    target_entanglement: Optional[float] = None
    target_expressibility: Optional[float] = None


class QuantumCircuitGenerator:
    """í•™ìŠµëœ Decision Transformerë¥¼ ì‚¬ìš©í•œ ì–‘ì íšŒë¡œ ìƒì„±ê¸°"""
    
    def __init__(self, 
                 model_path: str,
                 config: GenerationConfig = None):
        self.config = config or GenerationConfig()
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        
        # ê²Œì´íŠ¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬ ì´ˆê¸°í™”
        self.gate_registry = QuantumGateRegistry()
        self.gate_vocab = self.gate_registry.get_gate_vocab()
        self.idx_to_gate = {idx: gate for gate, idx in self.gate_vocab.items()}
        
        # ëª¨ë¸ ë¡œë“œ
        self.model = self._load_model(model_path)
        
        # ì„ë² ë”© íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™”
        self.embedding_pipeline = self._create_embedding_pipeline()
        
        print(f"QuantumCircuitGenerator initialized on {self.device}")
        print(f"Gate vocabulary: {len(self.gate_vocab)} gates")
    
    def _load_model(self, model_path: str) -> DecisionTransformer:
        """í•™ìŠµëœ ëª¨ë¸ ë¡œë“œ"""
        checkpoint = torch.load(model_path, map_location=self.device)
        
        # ëª¨ë¸ ì„¤ì • ì¶”ì¶œ
        if 'model_config' in checkpoint:
            model_config = checkpoint['model_config']
        else:
            # ê¸°ë³¸ ì„¤ì • ì‚¬ìš©
            model_config = {
                'd_model': 512,
                'n_layers': 6,
                'n_heads': 8,
                'n_gate_types': len(self.gate_vocab),
                'dropout': 0.1
            }
        
        # ëª¨ë¸ ìƒì„± ë° ê°€ì¤‘ì¹˜ ë¡œë“œ
        model = DecisionTransformer(**model_config)
        model.load_state_dict(checkpoint['model_state_dict'])
        model.to(self.device)
        model.eval()
        
        print(f"Model loaded from {model_path}")
        return model
    
    def _create_embedding_pipeline(self) -> EmbeddingPipeline:
        """ì„ë² ë”© íŒŒì´í”„ë¼ì¸ ìƒì„±"""
        embedding_config = EmbeddingConfig(
            d_model=512,
            n_gate_types=len(self.gate_vocab),
            n_qubits=self.config.target_num_qubits,
            max_seq_len=self.config.max_circuit_length * 3  # S-A-R íŒ¨í„´
        )
        return EmbeddingPipeline(embedding_config)
    
    def generate_circuit(self, 
                        initial_state: Optional[Dict] = None,
                        target_metrics: Optional[Dict] = None) -> CircuitSpec:
        """
        ì–‘ì íšŒë¡œ ìƒì„±
        
        Args:
            initial_state: ì´ˆê¸° ìƒíƒœ (ì„ íƒì )
            target_metrics: ëª©í‘œ ë©”íŠ¸ë¦­ (fidelity, entanglement ë“±)
        
        Returns:
            ìƒì„±ëœ CircuitSpec
        """
        print(f"Generating quantum circuit...")
        print(f"Target qubits: {self.config.target_num_qubits}")
        print(f"Max length: {self.config.max_circuit_length}")
        
        # ì´ˆê¸° ìƒíƒœ ì„¤ì •
        if initial_state is None:
            initial_state = self._create_initial_state()
        
        # ìƒì„±ëœ ê²Œì´íŠ¸ë“¤
        generated_gates = []
        
        # í˜„ì¬ ìƒíƒœ (State-Action-Reward ì‹œí€€ìŠ¤)
        current_sequence = self._initialize_sequence(initial_state, target_metrics)
        
        # ìˆœì°¨ì ìœ¼ë¡œ ê²Œì´íŠ¸ ìƒì„±
        for step in range(self.config.max_circuit_length):
            # ë‹¤ìŒ ê²Œì´íŠ¸ ì˜ˆì¸¡
            next_gate = self._predict_next_gate(current_sequence, step)
            
            if next_gate is None or next_gate.name == '[EOS]':
                print(f"Circuit generation completed at step {step}")
                break
            
            # ê²Œì´íŠ¸ ì¶”ê°€
            generated_gates.append(next_gate)
            
            # ì‹œí€€ìŠ¤ ì—…ë°ì´íŠ¸
            current_sequence = self._update_sequence(current_sequence, next_gate, step)
            
            print(f"Step {step}: Generated {next_gate.name} on qubits {next_gate.qubits}")
        
        # CircuitSpec ìƒì„±
        circuit_spec = CircuitSpec(
            circuit_id=f"generated_circuit_{len(generated_gates)}_gates",
            num_qubits=self.config.target_num_qubits,
            gates=generated_gates
        )
        
        print(f"Circuit generation completed: {len(generated_gates)} gates")
        return circuit_spec
    
    def _create_initial_state(self) -> Dict:
        """ì´ˆê¸° ìƒíƒœ ìƒì„±"""
        return {
            'num_qubits': self.config.target_num_qubits,
            'circuit_depth': 0,
            'gate_count': 0
        }
    
    def _initialize_sequence(self, initial_state: Dict, target_metrics: Optional[Dict]) -> torch.Tensor:
        """ì´ˆê¸° ì‹œí€€ìŠ¤ ìƒì„± (State-Action-Reward íŒ¨í„´)"""
        # ë¹ˆ íšŒë¡œë¡œ ì‹œì‘
        empty_circuit = CircuitSpec(
            circuit_id="initial",
            num_qubits=self.config.target_num_qubits,
            gates=[]
        )
        
        # ì„ë² ë”© íŒŒì´í”„ë¼ì¸ì„ í†µí•´ ì´ˆê¸° ì‹œí€€ìŠ¤ ìƒì„±
        embedded_data = self.embedding_pipeline.process_single_circuit(empty_circuit)
        
        # ì´ˆê¸° ì‹œí€€ìŠ¤ ì¶”ì¶œ
        initial_sequence = embedded_data['input_sequence']  # [1, seq_len, d_model]
        
        return initial_sequence.to(self.device)
    
    def _predict_next_gate(self, current_sequence: torch.Tensor, step: int) -> Optional[GateOperation]:
        """ë‹¤ìŒ ê²Œì´íŠ¸ ì˜ˆì¸¡"""
        with torch.no_grad():
            # ì–´í…ì…˜ ë§ˆìŠ¤í¬ ìƒì„±
            seq_len = current_sequence.shape[1]
            attention_mask = torch.tril(torch.ones(seq_len, seq_len)).unsqueeze(0).to(self.device)
            
            # ì•¡ì…˜ ì˜ˆì¸¡ ë§ˆìŠ¤í¬ (Action ìœ„ì¹˜ì—ì„œë§Œ ì˜ˆì¸¡)
            action_mask = torch.zeros(1, seq_len, dtype=torch.bool, device=self.device)
            action_positions = list(range(1, seq_len, 3))  # 1, 4, 7, 10, ... (Action ìœ„ì¹˜)
            if action_positions:
                action_mask[0, action_positions] = True
            
            # ëª¨ë¸ ì˜ˆì¸¡
            outputs = self.model(
                input_sequence=current_sequence,
                attention_mask=attention_mask,
                action_prediction_mask=action_mask
            )
            
            # ë§ˆì§€ë§‰ Action ìœ„ì¹˜ì˜ ë¡œì§“ ì¶”ì¶œ
            action_logits = outputs['action_logits']  # [1, seq_len, n_gate_types]
            
            if action_positions:
                last_action_pos = action_positions[-1]
                if last_action_pos < seq_len:
                    logits = action_logits[0, last_action_pos, :]  # [n_gate_types]
                else:
                    # ì‹œí€€ìŠ¤ ëì— ë„ë‹¬
                    return None
            else:
                return None
            
            # ìƒ˜í”Œë§ì„ í†µí•œ ê²Œì´íŠ¸ ì„ íƒ
            gate_id = self._sample_gate_id(logits)
            
            # ê²Œì´íŠ¸ IDë¥¼ GateOperationìœ¼ë¡œ ë³€í™˜
            return self._gate_id_to_operation(gate_id)
    
    def _sample_gate_id(self, logits: torch.Tensor) -> int:
        """ë¡œì§“ì—ì„œ ê²Œì´íŠ¸ ID ìƒ˜í”Œë§"""
        if not self.config.do_sample:
            # ê·¸ë¦¬ë”” ì„ íƒ
            return torch.argmax(logits).item()
        
        # ì˜¨ë„ ì ìš©
        logits = logits / self.config.temperature
        
        # Top-k í•„í„°ë§
        if self.config.top_k > 0:
            top_k_logits, top_k_indices = torch.topk(logits, min(self.config.top_k, logits.size(-1)))
            logits = torch.full_like(logits, float('-inf'))
            logits.scatter_(-1, top_k_indices, top_k_logits)
        
        # Top-p (nucleus) í•„í„°ë§
        if self.config.top_p < 1.0:
            sorted_logits, sorted_indices = torch.sort(logits, descending=True)
            cumulative_probs = torch.cumsum(F.softmax(sorted_logits, dim=-1), dim=-1)
            
            # ëˆ„ì  í™•ë¥ ì´ top_pë¥¼ ì´ˆê³¼í•˜ëŠ” í† í°ë“¤ ì œê±°
            sorted_indices_to_remove = cumulative_probs > self.config.top_p
            sorted_indices_to_remove[1:] = sorted_indices_to_remove[:-1].clone()
            sorted_indices_to_remove[0] = 0
            
            indices_to_remove = sorted_indices[sorted_indices_to_remove]
            logits[indices_to_remove] = float('-inf')
        
        # í™•ë¥  ë¶„í¬ì—ì„œ ìƒ˜í”Œë§
        probs = F.softmax(logits, dim=-1)
        gate_id = torch.multinomial(probs, 1).item()
        
        return gate_id
    
    def _gate_id_to_operation(self, gate_id: int) -> Optional[GateOperation]:
        """ê²Œì´íŠ¸ IDë¥¼ GateOperationìœ¼ë¡œ ë³€í™˜"""
        if gate_id not in self.idx_to_gate:
            return None
        
        gate_name = self.idx_to_gate[gate_id]
        
        # íŠ¹ìˆ˜ í† í° ì²˜ë¦¬
        if gate_name in ['[EOS]', '[PAD]', '[EMPTY]']:
            return GateOperation(name=gate_name, qubits=[], parameters=[])
        
        # ğŸš¨ CRITICAL FIX: gate_registry.get_gate_info() ë©”ì„œë“œê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŒ!
        # ì˜¬ë°”ë¥¸ ë©”ì„œë“œ ì‚¬ìš©
        try:
            gate_def = self.gate_registry.get_gate(gate_name)
            if gate_def is None:
                return None
            
            # íë¹— ì„ íƒ
            required_qubits = gate_def.num_qubits
            qubits = self._select_qubits(required_qubits)
            
            # íŒŒë¼ë¯¸í„° ìƒì„±
            required_params = gate_def.num_parameters
            parameters = self._generate_parameters(required_params)
            
        except Exception as e:
            print(f"Warning: Failed to get gate info for {gate_name}: {e}")
            return None
        
        return GateOperation(
            name=gate_name,
            qubits=qubits,
            parameters=parameters
        )
    
    def _select_qubits(self, num_qubits: int) -> List[int]:
        """ê²Œì´íŠ¸ì— í•„ìš”í•œ íë¹— ì„ íƒ"""
        available_qubits = list(range(self.config.target_num_qubits))
        
        if num_qubits == 1:
            # ë‹¨ì¼ íë¹— ê²Œì´íŠ¸
            return [np.random.choice(available_qubits)]
        elif num_qubits == 2:
            # 2íë¹— ê²Œì´íŠ¸
            selected = np.random.choice(available_qubits, size=2, replace=False)
            return selected.tolist()
        else:
            # ë‹¤ì¤‘ íë¹— ê²Œì´íŠ¸
            selected = np.random.choice(available_qubits, size=min(num_qubits, len(available_qubits)), replace=False)
            return selected.tolist()
    
    def _generate_parameters(self, num_params: int) -> List[float]:
        """ê²Œì´íŠ¸ íŒŒë¼ë¯¸í„° ìƒì„±"""
        if num_params == 0:
            return []
        
        # 0 ~ 2Ï€ ë²”ìœ„ì˜ ëœë¤ íŒŒë¼ë¯¸í„°
        parameters = []
        for _ in range(num_params):
            param = np.random.uniform(0, 2 * np.pi)
            parameters.append(param)
        
        return parameters
    
    def _update_sequence(self, current_sequence: torch.Tensor, new_gate: GateOperation, step: int) -> torch.Tensor:
        """ì‹œí€€ìŠ¤ì— ìƒˆ ê²Œì´íŠ¸ ì¶”ê°€ - CRITICAL FIX"""
        # ğŸš¨ CRITICAL: ì´ì „ êµ¬í˜„ì€ ì™„ì „íˆ ì˜ëª»ë¨!
        # State-Action-Reward íŒ¨í„´ìœ¼ë¡œ ì‹œí€€ìŠ¤ë¥¼ ì‹¤ì œë¡œ ì—…ë°ì´íŠ¸í•´ì•¼ í•¨
        
        try:
            # í˜„ì¬ ì‹œí€€ìŠ¤ì—ì„œ íšŒë¡œ ìƒíƒœ ì¶”ì¶œ
            batch_size, seq_len, d_model = current_sequence.shape
            
            # ìƒˆ ê²Œì´íŠ¸ë¥¼ í¬í•¨í•œ ì„ì‹œ íšŒë¡œ ìƒì„±
            temp_circuit = CircuitSpec(
                circuit_id=f"temp_step_{step}",
                num_qubits=self.config.target_num_qubits,
                gates=[new_gate]  # ìƒˆ ê²Œì´íŠ¸ë§Œ í¬í•¨
            )
            
            # ì„ë² ë”© íŒŒì´í”„ë¼ì¸ì„ í†µí•´ ìƒˆ ì‹œí€€ìŠ¤ ìƒì„±
            embedded_data = self.embedding_pipeline.process_single_circuit(temp_circuit)
            new_sequence = embedded_data['input_sequence'].to(self.device)
            
            # ê¸°ì¡´ ì‹œí€€ìŠ¤ì™€ ìƒˆ ì‹œí€€ìŠ¤ ì—°ê²°
            # State-Action-Reward íŒ¨í„´ ìœ ì§€
            if seq_len + new_sequence.shape[1] <= self.config.max_circuit_length * 3:
                updated_sequence = torch.cat([current_sequence, new_sequence], dim=1)
            else:
                # ìµœëŒ€ ê¸¸ì´ ì´ˆê³¼ì‹œ ê¸°ì¡´ ì‹œí€€ìŠ¤ ìœ ì§€
                updated_sequence = current_sequence
            
            return updated_sequence
            
        except Exception as e:
            print(f"Warning: Failed to update sequence: {e}")
            # ì‹¤íŒ¨ì‹œ ê¸°ì¡´ ì‹œí€€ìŠ¤ ë°˜í™˜
            return current_sequence
    
    def generate_multiple_circuits(self, 
                                 num_circuits: int = 5,
                                 target_metrics: Optional[Dict] = None) -> List[CircuitSpec]:
        """ì—¬ëŸ¬ íšŒë¡œ ìƒì„±"""
        circuits = []
        
        for i in range(num_circuits):
            print(f"\nGenerating circuit {i+1}/{num_circuits}")
            circuit = self.generate_circuit(target_metrics=target_metrics)
            circuits.append(circuit)
        
        return circuits
    
    def save_circuits(self, circuits: List[CircuitSpec], output_path: str):
        """ìƒì„±ëœ íšŒë¡œë“¤ì„ JSON íŒŒì¼ë¡œ ì €ì¥"""
        circuits_data = []
        
        for circuit in circuits:
            circuit_data = {
                'circuit_id': circuit.circuit_id,
                'num_qubits': circuit.num_qubits,
                'gates': [
                    {
                        'name': gate.name,
                        'qubits': gate.qubits,
                        'parameters': gate.parameters
                    }
                    for gate in circuit.gates
                ]
            }
            circuits_data.append(circuit_data)
        
        with open(output_path, 'w') as f:
            json.dump(circuits_data, f, indent=2)
        
        print(f"Saved {len(circuits)} circuits to {output_path}")


def main():
    """ì‚¬ìš© ì˜ˆì‹œ"""
    # ì„¤ì •
    config = GenerationConfig(
        max_circuit_length=20,
        target_num_qubits=4,
        temperature=0.8,
        top_k=10,
        do_sample=True
    )
    
    # ëª¨ë¸ ê²½ë¡œ (í•™ìŠµëœ ì²´í¬í¬ì¸íŠ¸)
    model_path = "checkpoints/best_model.pt"
    
    # ìƒì„±ê¸° ì´ˆê¸°í™”
    generator = QuantumCircuitGenerator(model_path, config)
    
    # ëª©í‘œ ë©”íŠ¸ë¦­ ì„¤ì • (ì„ íƒì )
    target_metrics = {
        'target_fidelity': 0.8,
        'target_entanglement': 0.6
    }
    
    # íšŒë¡œ ìƒì„±
    circuits = generator.generate_multiple_circuits(
        num_circuits=5,
        target_metrics=target_metrics
    )
    
    # ê²°ê³¼ ì €ì¥
    generator.save_circuits(circuits, "generated_circuits.json")
    
    # ìƒì„±ëœ íšŒë¡œ ì •ë³´ ì¶œë ¥
    for i, circuit in enumerate(circuits):
        print(f"\nCircuit {i+1}:")
        print(f"  Qubits: {circuit.num_qubits}")
        print(f"  Gates: {len(circuit.gates)}")
        for j, gate in enumerate(circuit.gates[:5]):  # ì²˜ìŒ 5ê°œ ê²Œì´íŠ¸ë§Œ ì¶œë ¥
            print(f"    {j+1}. {gate.name} on qubits {gate.qubits}")
        if len(circuit.gates) > 5:
            print(f"    ... and {len(circuit.gates) - 5} more gates")


if __name__ == "__main__":
    main()
