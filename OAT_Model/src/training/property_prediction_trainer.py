"""
Property Prediction Transformer Training Pipeline

CircuitSpecìœ¼ë¡œë¶€í„° ì–½í˜ë„, fidelity, robust fidelityë¥¼ ì˜ˆì¸¡í•˜ëŠ” 
íŠ¸ëœìŠ¤í¬ë¨¸ ëª¨ë¸ì˜ í•™ìŠµ íŒŒì´í”„ë¼ì¸
"""

import torch
import torch.nn as nn
from torch.utils.data import DataLoader
from torch.optim import AdamW
from torch.optim.lr_scheduler import CosineAnnealingLR, OneCycleLR
from pathlib import Path
from tqdm import tqdm
from typing import Dict, List, Any, Optional, Tuple
import wandb
import json
import numpy as np
import math
from dataclasses import asdict
import time
import os

# Import model components
from models.property_prediction_transformer import (
    PropertyPredictionTransformer,
    PropertyPredictionConfig,
    PropertyPredictionLoss,
    create_property_prediction_model
)

# Import quantum dataset
from data.quantum_circuit_dataset import (
    DatasetManager,
    QuantumCircuitDataset,
    CircuitData,
    create_dataloaders
)

# Import circuit interface
import sys
sys.path.append(str(Path(__file__).parent.parent.parent/ "quantumcommon"))
from circuit_interface import CircuitSpec
from gates import GateOperation


class PropertyPredictionDataset:
    """ì–‘ì íšŒë¡œ íŠ¹ì„± ì˜ˆì¸¡ì„ ìœ„í•œ ë°ì´í„°ì…‹ ë˜í¼"""
    
    def __init__(self, quantum_dataset: QuantumCircuitDataset):
        """
        Args:
            quantum_dataset: QuantumCircuitDataset ì¸ìŠ¤í„´ìŠ¤
        """
        self.quantum_dataset = quantum_dataset
        
        print(f"[INIT] Property Prediction ë°ì´í„°ì…‹ ì´ˆê¸°í™”: {len(self.quantum_dataset)} ìƒ˜í”Œ")
    
    def __len__(self) -> int:
        return len(self.quantum_dataset)
    
    def __getitem__(self, idx: int) -> Dict:
        """CircuitDataë¥¼ Property Prediction í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
        circuit_data: CircuitData = self.quantum_dataset[idx]
        
        # Check if measurement result exists
        if circuit_data.measurement_result is None:
            raise ValueError(f"No measurement result for circuit {circuit_data.circuit_id}")
            
        measurement = circuit_data.measurement_result
        
        # Validate required fields
        if measurement.fidelity is None:
            raise ValueError(f"Missing fidelity for circuit {circuit_data.circuit_id}")
        
        # Extract expressibility (KL divergence only)
        expressibility_value = 0.0
        if measurement.expressibility and isinstance(measurement.expressibility, dict):
            kl_div = measurement.expressibility.get('kl_divergence', 0.0)
            # Use KL divergence directly as expressibility
            expressibility_value = float(kl_div)
        
        # Extract robust fidelity (ë””ë²„ê·¸ ì¶”ê°€)
        robust_fidelity_value = 0.0
        if hasattr(measurement, 'robust_fidelity') and measurement.robust_fidelity is not None:
            robust_fidelity_value = float(measurement.robust_fidelity)
        else:
            raise ValueError(f"Missing robust_fidelity for circuit {circuit_data.circuit_id}")
        
        targets = {
            'entanglement': float(measurement.entanglement) if measurement.entanglement is not None else 0.0,
            'fidelity': float(measurement.fidelity),
            'expressibility': float(expressibility_value),
            'robust_fidelity': robust_fidelity_value
        }
        
        # Combined target vector
        targets['combined'] = torch.tensor([
            targets['entanglement'],
            targets['fidelity'], 
            targets['expressibility'],
            targets['robust_fidelity']
        ], dtype=torch.float32)
        
        return {
            'circuit_spec': circuit_data.circuit_spec,
            'targets': targets,
            'metadata': {
                'num_qubits': circuit_data.num_qubits,
                'num_gates': len(circuit_data.gates),
                'circuit_id': circuit_data.circuit_id,
                'depth': measurement.depth
            }
        }


def collate_fn(batch: List[Dict]) -> Dict:
    """ë°°ì¹˜ ë°ì´í„° collation"""
    # Filter out None items from batch
    valid_batch = [item for item in batch if item is not None]
    
    if not valid_batch:
        raise ValueError("[EMPTY] - No valid items in batch")
    
    circuit_specs = [item['circuit_spec'] for item in valid_batch]
    
    # íƒ€ê²Ÿ ê°’ë“¤ì„ í…ì„œë¡œ ë³€í™˜
    targets = {}
    for key in ['entanglement', 'fidelity', 'expressibility', 'robust_fidelity']:
        targets[key] = torch.tensor([item['targets'][key] for item in valid_batch], dtype=torch.float32)
    
    targets['combined'] = torch.stack([item['targets']['combined'] for item in valid_batch])
    
    # ë©”íƒ€ë°ì´í„°
    metadata = [item['metadata'] for item in valid_batch]
    
    return {
        'circuit_specs': circuit_specs,
        'targets': targets,
        'metadata': metadata
    }


class PropertyPredictionTrainer:
    """Property Prediction Transformer í•™ìŠµê¸°"""
    
    def __init__(
        self,
        config: PropertyPredictionConfig,
        model: nn.Module,
        train_dataset: PropertyPredictionDataset,
        val_dataset: PropertyPredictionDataset,
        save_dir: str = './OAT_Model/checkpoints'
    ):
        self.config = config
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.model = model.to(self.device)
        self.train_dataset = train_dataset
        self.val_dataset = val_dataset
        self.save_dir = Path(save_dir)
        self.save_dir.mkdir(parents=True, exist_ok=True)
        
        # í•™ìŠµ íŒŒë¼ë¯¸í„° ì„¤ì •
        self.train_loader = DataLoader(
            self.train_dataset, 
            batch_size=self.config.train_batch_size,
            shuffle=True, 
            collate_fn=collate_fn,
            num_workers=0,  # ë©€í‹°í”„ë¡œì„¸ì‹± ë¹„í™œì„±í™” (ì•ˆì •ì„±)
            pin_memory=True if self.device.type == 'cuda' else False  # GPU ë©”ëª¨ë¦¬ ìµœì í™”
        )
        
        self.val_loader = DataLoader(
            val_dataset,
            batch_size=config.val_batch_size,
            shuffle=False,
            collate_fn=collate_fn,
            num_workers=0,
            pin_memory=True if self.device.type == 'cuda' else False
        )
        
        # Create optimizer
        self.optimizer = AdamW(
            self.model.parameters(),
            lr=config.learning_rate,
            weight_decay=config.weight_decay if hasattr(config, 'weight_decay') else 0.01,
            betas=(0.9, 0.999),
            eps=1e-8
        )
        
        # Create loss criterion
        self.criterion = PropertyPredictionLoss(
            entanglement_weight=getattr(config, 'weight_entanglement', 1.0),
            fidelity_weight=getattr(config, 'weight_fidelity', 1.0),
            expressibility_weight=getattr(config, 'weight_expressibility', 1.0),
            combined_weight=getattr(config, 'weight_combined', 1.0)
        )
        
        # Learning rate scheduler - ë” ì•ˆì •ì ì¸ ìŠ¤ì¼€ì¤„ëŸ¬ ì‚¬ìš©
        self.scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(
            self.optimizer,
            mode='min',
            factor=0.5,
            patience=5,
            min_lr=1e-6
        )
        
        # GPU ë©”ëª¨ë¦¬ ìµœì í™” ì„¤ì •
        if self.device.type == 'cuda':
            torch.cuda.empty_cache()  # ì´ˆê¸° ë©”ëª¨ë¦¬ ì •ë¦¬
            torch.backends.cudnn.benchmark = True  # cuDNN ìµœì í™”
            torch.backends.cudnn.deterministic = False  # ì„±ëŠ¥ ìš°ì„ 
            print(f"[GPU] ë©”ëª¨ë¦¬ ìµœì í™” í™œì„±í™” - ì‚¬ìš© ê°€ëŠ¥: {torch.cuda.get_device_properties(0).total_memory / (1024**3):.1f}GB")
        
        # Training state
        self.current_epoch = 0
        self.best_val_loss = float('inf')
        self.training_history = []
        
        # ë””ë²„ê¹…ì„ ìœ„í•œ ì˜ˆì¸¡/ì •ë‹µ ì¶”ì 
        self.debug_predictions = []
        
        # Early stopping ì„¤ì •
        self.patience = getattr(config, 'early_stopping_patience', 15)  # ê¸°ë³¸ê°’ 15 ì—í­
        self.early_stopping_counter = 0
        self.min_delta = getattr(config, 'early_stopping_delta', 0.001)  # ìµœì†Œ ê°œì„  í•„ìš”ì¹˜
        self.early_stopped = False
        
        # í•™ìŠµë¥  ìµœì†Œê°’ ì„¤ì • (ë„ˆë¬´ ì‘ì•„ì§€ë©´ í•™ìŠµì´ ì§„í–‰ë˜ì§€ ì•ŠìŒ)
        self.min_lr = getattr(config, 'min_learning_rate', 1e-7)
        
        # ë©”ëª¨ë¦¬ ê´€ë¦¬ ì„¤ì •
        self.memory_cleanup_frequency = getattr(config, 'memory_cleanup_frequency', 10)
        self.debug_targets = []
    
    def train_epoch(self) -> Dict[str, float]:
        """í•œ ì—í­ í•™ìŠµ"""
        self.model.train()
        
        total_losses = {
            'total': 0.0,
            'entanglement': 0.0,
            'fidelity': 0.0,
            'expressibility': 0.0,
            'robust_fidelity': 0.0,
            'combined': 0.0
        }
        
        num_batches = 0
        
        progress_bar = tqdm(self.train_loader, desc=f"Epoch {self.current_epoch}")
        
        for batch_idx, batch in enumerate(progress_bar):
            try:
                # GPU ë©”ëª¨ë¦¬ ìµœì í™”
                if self.device.type == 'cuda' and batch_idx % 10 == 0:
                    torch.cuda.empty_cache()  # ì£¼ê¸°ì  ë©”ëª¨ë¦¬ ì •ë¦¬
                
                # Forward pass
                circuit_specs = batch['circuit_specs']
                targets = {k: v.to(self.device, non_blocking=True).float() for k, v in batch['targets'].items()}
                
                # Model prediction - AMP ì œê±°, ëª¨ë“  í…ì„œë¥¼ floatìœ¼ë¡œ í†µì¼
                predictions = self.model(circuit_specs)
                
                # Move predictions to device and ensure float type
                for key in predictions:
                    predictions[key] = predictions[key].to(self.device, non_blocking=True).float()
                
                # ë””ë²„ê¹…: ì²« ë²ˆì§¸ ë°°ì¹˜ì˜ ì˜ˆì¸¡ê³¼ ì •ë‹µ ë¹„êµ
                if batch_idx == 0:
                    self._debug_predictions_vs_targets(predictions, targets, batch_idx)
                
                # Calculate loss with NaN check
                losses = self.criterion(predictions, targets)
                
                # NaN loss ì²´í¬ ë° ìŠ¤í‚µ
                if torch.isnan(losses['total']) or torch.isinf(losses['total']):
                    print(f"[WARNING] ë°°ì¹˜ {batch_idx}: NaN/Inf loss ê°ì§€, ìŠ¤í‚µ")
                    continue
                
                # Backward pass - float íƒ€ì… ë³´ì¥
                self.optimizer.zero_grad()
                total_loss = losses['total'].float()  # ëª…ì‹œì ìœ¼ë¡œ floatìœ¼ë¡œ ë³€í™˜
                total_loss.backward()
                
                # ê·¸ë˜ë””ì–¸íŠ¸ NaN ì²´í¬
                has_nan_grad = False
                for name, param in self.model.named_parameters():
                    if param.grad is not None and (torch.isnan(param.grad).any() or torch.isinf(param.grad).any()):
                        print(f"[WARNING] ë°°ì¹˜ {batch_idx}: {name}ì—ì„œ NaN ê·¸ë˜ë””ì–¸íŠ¸ ê°ì§€")
                        has_nan_grad = True
                        break
                
                if has_nan_grad:
                    self.optimizer.zero_grad()
                    continue
                
                # Gradient clipping (ë” ê°•í•œ í´ë¦¬í•‘)
                torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=0.5)
                
                self.optimizer.step()
                # ReduceLROnPlateauëŠ” validation lossë¡œ step
                
                # Accumulate losses
                for key, loss in losses.items():
                    total_losses[key] += loss.item()
                
                num_batches += 1
                
                # Update progress bar with GPU ë©”ëª¨ë¦¬ ì •ë³´
                current_lr = self.optimizer.param_groups[0]['lr']
                postfix = {
                    'loss': f"{losses['total'].item():.4f}",
                    'lr': f"{current_lr:.2e}"
                }
                
                if self.device.type == 'cuda':
                    gpu_memory = torch.cuda.memory_allocated() / (1024**3)
                    postfix['GPU'] = f"{gpu_memory:.1f}GB"
                
                progress_bar.set_postfix(postfix)
                
            except Exception as e:
                print(f"[ERROR] ë°°ì¹˜ {batch_idx} í•™ìŠµ ì˜¤ë¥˜: {e}")
                import traceback
                traceback.print_exc()
                
                # GPU ë©”ëª¨ë¦¬ ì •ë¦¬
                if self.device.type == 'cuda':
                    torch.cuda.empty_cache()
                continue
        
        # Average losses
        avg_losses = {key: total_loss / max(num_batches, 1) for key, total_loss in total_losses.items()}
        
        return avg_losses
    
    def _debug_predictions_vs_targets(self, predictions: Dict[str, torch.Tensor], 
                                    targets: Dict[str, torch.Tensor], batch_idx: int):
        """ì˜ˆì¸¡ê°’ê³¼ ì •ë‹µ ë ˆì´ë¸” ë¹„êµ ë””ë²„ê¹…"""
        print(f"\n[DEBUG] [ë°°ì¹˜ {batch_idx}] ì˜ˆì¸¡ vs ì •ë‹µ ë””ë²„ê¹…:")
        
        # ì²« ë²ˆì§¸ ìƒ˜í”Œë§Œ ë¶„ì„
        sample_idx = 0
        
        for property_name in ['entanglement', 'fidelity', 'expressibility', 'robust_fidelity']:
            if property_name in predictions and property_name in targets:
                pred_val = predictions[property_name][sample_idx].item()
                target_val = targets[property_name][sample_idx].item()
                diff = abs(pred_val - target_val)
                
                print(f"  [DATA] {property_name:15s}: ì˜ˆì¸¡={pred_val:7.4f}, ì •ë‹µ={target_val:7.4f}, ì°¨ì´={diff:7.4f}")
        
        # Combined ì˜ˆì¸¡ (4ì°¨ì› ë²¡í„°)
        if 'combined' in predictions and 'combined' in targets:
            pred_combined = predictions['combined'][sample_idx]
            target_combined = targets['combined'][sample_idx]
            
            print(f"  [DATA] {'combined':15s}:")
            property_names = ['entanglement', 'fidelity', 'expressibility', 'robust_fidelity']
            for i, prop_name in enumerate(property_names):
                if i < len(pred_combined) and i < len(target_combined):
                    pred_val = pred_combined[i].item()
                    target_val = target_combined[i].item()
                    diff = abs(pred_val - target_val)
                    print(f"    - {prop_name:13s}: ì˜ˆì¸¡={pred_val:7.4f}, ì •ë‹µ={target_val:7.4f}, ì°¨ì´={diff:7.4f}")
        
        # ì˜ˆì¸¡ê°’ ë²”ìœ„ ì²´í¬
        print(f"  [RANGE] ì˜ˆì¸¡ê°’ ë²”ìœ„ ì²´í¬:")
        for property_name, pred_tensor in predictions.items():
            if torch.is_tensor(pred_tensor):
                min_val = pred_tensor.min().item()
                max_val = pred_tensor.max().item()
                mean_val = pred_tensor.mean().item()
                print(f"    - {property_name:13s}: min={min_val:7.4f}, max={max_val:7.4f}, mean={mean_val:7.4f}")
        
        # NaN/Inf ì²´í¬
        nan_found = False
        for property_name, pred_tensor in predictions.items():
            if torch.is_tensor(pred_tensor):
                if torch.isnan(pred_tensor).any() or torch.isinf(pred_tensor).any():
                    print(f"  [WARNING] {property_name}ì—ì„œ NaN/Inf ê°ì§€!")
                    nan_found = True
        
        if not nan_found:
            print(f"  [OK] ëª¨ë“  ì˜ˆì¸¡ê°’ì´ ì •ìƒ ë²”ìœ„ ë‚´ì— ìˆìŠµë‹ˆë‹¤.")
        
        print()  # ë¹ˆ ì¤„ ì¶”ê°€
    
    def validate(self) -> Dict[str, float]:
        """ê²€ì¦"""
        self.model.eval()
        
        total_losses = {
            'total': 0.0,
            'entanglement': 0.0,
            'fidelity': 0.0,
            'expressibility': 0.0,
            'robust_fidelity': 0.0,
            'combined': 0.0
        }
        
        num_batches = 0
        all_predictions = []
        all_targets = []
        
        with torch.no_grad():
            progress_bar = tqdm(self.val_loader, desc="Validation")
            for batch_idx, batch in enumerate(progress_bar):
                try:
                    # GPU ë©”ëª¨ë¦¬ ìµœì í™” - ê²€ì¦ì—ë„ ì ìš©
                    if self.device.type == 'cuda' and batch_idx % 10 == 0:
                        torch.cuda.empty_cache()  # ì£¼ê¸°ì  ë©”ëª¨ë¦¬ ì •ë¦¬
                    
                    circuit_specs = batch['circuit_specs']
                    targets = {k: v.to(self.device, non_blocking=True).float() for k, v in batch['targets'].items()}
                    
                    # Model prediction with float consistency
                    predictions = self.model(circuit_specs)
                    
                    # Move predictions to device and ensure float type
                    for key in predictions:
                        predictions[key] = predictions[key].to(self.device, non_blocking=True).float()
                    
                    # NaN ì²´í¬ (ê²€ì¦ ê³¼ì •ì—ì„œë„ í•„ìš”)
                    has_nan = False
                    for key, pred in predictions.items():
                        if torch.isnan(pred).any() or torch.isinf(pred).any():
                            has_nan = True
                            print(f"[WARNING] ê²€ì¦ ë°°ì¹˜ {batch_idx}: {key}ì—ì„œ NaN/Inf ì˜ˆì¸¡ê°’ ê°ì§€")
                            break
                    
                    if has_nan:
                        continue
                    
                    # Calculate loss
                    losses = self.criterion(predictions, targets)
                    
                    # NaN loss ì²´í¬
                    if torch.isnan(losses['total']) or torch.isinf(losses['total']):
                        print(f"[WARNING] ê²€ì¦ ë°°ì¹˜ {batch_idx}: NaN/Inf loss ê°ì§€, ìŠ¤í‚µ")
                        continue
                    
                    # Accumulate losses
                    for key, loss in losses.items():
                        total_losses[key] += loss.item()
                    
                    # ë””ë²„ê¹…ìš© ì˜ˆì¸¡/ì •ë‹µ ì €ì¥ (ì¼ë¶€ë§Œ)
                    if len(all_predictions) < 100:  # ìµœëŒ€ 100ê°œ ìƒ˜í”Œë§Œ ì €ì¥
                        all_predictions.append({k: v.detach().cpu() for k, v in predictions.items()})
                        all_targets.append({k: v.detach().cpu() for k, v in targets.items()})
                    
                    num_batches += 1
                    
                    # Update progress bar with GPU info
                    postfix = {'loss': f"{losses['total'].item():.4f}"}
                    if self.device.type == 'cuda':
                        gpu_memory = torch.cuda.memory_allocated() / (1024**3)
                        postfix['GPU'] = f"{gpu_memory:.1f}GB"
                    
                    progress_bar.set_postfix(postfix)
                
                except Exception as e:
                    print(f"[ERROR] ê²€ì¦ ë°°ì¹˜ {batch_idx} ì˜¤ë¥˜: {e}")
                    if self.device.type == 'cuda':
                        torch.cuda.empty_cache()
                        
                    import traceback
                    traceback.print_exc()
                    continue
        
        # Average losses
        avg_losses = {key: total_loss / max(num_batches, 1) for key, total_loss in total_losses.items()}
        
        # Calculate additional metrics
        metrics = self._calculate_metrics(all_predictions, all_targets)
        avg_losses.update(metrics)
        
        return avg_losses
    
    def _calculate_metrics(self, predictions: List[Dict], targets: List[Dict]) -> Dict[str, float]:
        """ì¶”ê°€ ë©”íŠ¸ë¦­ ê³„ì‚° - ê°œì„ ëœ ì—ëŸ¬ ì²˜ë¦¬ì™€ í†µê³„"""
        if not predictions or not targets:
            print("\n[WARNING] ë©”íŠ¸ë¦­ ê³„ì‚°ì„ ìœ„í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return {}
            
        try:
            metrics = {}
            
            # ë¶„ì„í•  í”„ë¡œí¼í‹° ì§€ì •
            properties = ['entanglement', 'fidelity', 'expressibility']
            available_props = [p for p in properties if all(p in pred and p in target for pred, target in zip(predictions, targets))]
            
            if not available_props:
                print("\n[WARNING] ë©”íŠ¸ë¦­ ê³„ì‚°ì„ ìœ„í•œ í”„ë¡œí¼í‹°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return {}
                
            print(f"\n[INFO] ë¶„ì„í•  í”„ë¡œí¼í‹°: {available_props}")
            
            # í”„ë¡œí¼í‹°ë³„ ë©”íŠ¸ë¦­ ê³„ì‚°
            for prop in available_props:
                try:
                    # ì˜ˆì¸¡/íƒ€ê²Ÿê°’ ëª¨ìœ¼ê¸° (ìœ íš¨í•œ ê°’ë§Œ)
                    pred_values = []
                    target_values = []
                    
                    for pred, target in zip(predictions, targets):
                        if prop in pred and prop in target:
                            # NaN/Inf ì²´í¬
                            p_vals = pred[prop]
                            t_vals = target[prop]
                            
                            valid_indices = ~(torch.isnan(p_vals) | torch.isinf(p_vals) | torch.isnan(t_vals) | torch.isinf(t_vals))
                            if valid_indices.any():
                                pred_values.append(p_vals[valid_indices])
                                target_values.append(t_vals[valid_indices])
                    
                    if not pred_values:
                        print(f"  - {prop}: ìœ íš¨í•œ ê°’ì´ ì—†ìŠµë‹ˆë‹¤")
                        continue
                    
                    # ìœ íš¨í•œ ê°’ë§Œ ëª¨ì•„ì„œ í…ì„œë¡œ ë³€í™˜
                    pred_tensor = torch.cat(pred_values)
                    target_tensor = torch.cat(target_values)
                    
                    # ê°’ ë²”ìœ„ í™•ì¸
                    pred_min, pred_max = pred_tensor.min().item(), pred_tensor.max().item()
                    target_min, target_max = target_tensor.min().item(), target_tensor.max().item()
                    
                    # MAE (Mean Absolute Error)
                    mae = torch.mean(torch.abs(target_tensor - pred_tensor)).item()
                    metrics[f'{prop}_mae'] = mae
                    
                    # MSE (Mean Squared Error)
                    mse = torch.mean((target_tensor - pred_tensor) ** 2).item()
                    metrics[f'{prop}_mse'] = mse
                    
                    # RMSE (Root Mean Squared Error)
                    rmse = math.sqrt(mse)
                    metrics[f'{prop}_rmse'] = rmse
                    
                    # RÂ² score ê³„ì‚°
                    ss_res = torch.sum((target_tensor - pred_tensor) ** 2)
                    ss_tot = torch.sum((target_tensor - torch.mean(target_tensor)) ** 2)
                    r2 = 1 - (ss_res / (ss_tot + 1e-8))
                    r2 = max(min(r2.item(), 1.0), -1.0)  # R2ëŠ” -âˆ ~ 1 ë²”ìœ„ì§€ë§Œ, í‘œì‹œë¥¼ ìœ„í•´ ì œí•œ
                    metrics[f'{prop}_r2'] = r2
                    
                    # í‰ê·  í¸í–¥ (Mean Bias)
                    mean_bias = torch.mean(pred_tensor - target_tensor).item()
                    metrics[f'{prop}_bias'] = mean_bias
                    
                    # ìƒê´€ê³„ìˆ˜ (Pearson correlation)
                    if len(pred_tensor) > 1:  # ìƒê´€ê³„ìˆ˜ëŠ” 2ê°œ ì´ìƒì˜ ìƒ˜í”Œ í•„ìš”
                        pred_std = torch.std(pred_tensor)
                        target_std = torch.std(target_tensor)
                        if pred_std > 0 and target_std > 0:  # 0ìœ¼ë¡œ ë‚˜ëˆ„ëŠ” ê²ƒ ë°©ì§€
                            cov = torch.mean((pred_tensor - torch.mean(pred_tensor)) * (target_tensor - torch.mean(target_tensor)))
                            corr = cov / (pred_std * target_std)
                            metrics[f'{prop}_corr'] = corr.item()
                    
                    print(f"  - {prop}: MAE={mae:.4f}, RMSE={rmse:.4f}, RÂ²={r2:.4f}, "
                          f"bias={mean_bias:.4f}, range=({pred_min:.2f}-{pred_max:.2f})")
                    
                except Exception as e:
                    print(f"  - {prop} ë©”íŠ¸ë¦­ ê³„ì‚° ì¤‘ ì˜¤ë¥˜: {e}")
            
            return metrics
            
        except Exception as e:
            print(f"\n[ERROR] ë©”íŠ¸ë¦­ ê³„ì‚° ì˜¤ë¥˜: {e}")
            import traceback
            traceback.print_exc()
            return {}
    
    def train(self, num_epochs: int = 100, resume_checkpoint: str = None) -> Dict[str, Any]:
        """
        ì „ì²´ í•™ìŠµ í”„ë¡œì„¸ìŠ¤ - Early stopping ë° í•™ìŠµ ì¬ê°œ ê¸°ëŠ¥ ì¶”ê°€
        
        Args:
            num_epochs: ìµœëŒ€ ì—í­ ìˆ˜
            resume_checkpoint: ì¬ê°œí•  ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œ, Noneì´ë©´ ì²˜ìŒë¶€í„° í•™ìŠµ
            
        Returns:
            Dict[str, Any]: í•™ìŠµ ê¸°ë¡ ë° ìƒíƒœ ì •ë³´ í¬í•¨
        """
        # í•™ìŠµ ì¬ê°œ ì²˜ë¦¬
        start_epoch = 0
        if resume_checkpoint:
            if self.load_checkpoint(resume_checkpoint):
                start_epoch = self.current_epoch + 1  # ë‹¤ìŒ ì—í­ë¶€í„° ì‹œì‘
                print(f"\n[RESUME] í•™ìŠµ ì¬ê°œ ì¤€ë¹„ ì™„ë£Œ: ì—í­ {start_epoch}ë¶€í„° {num_epochs}ê¹Œì§€ í•™ìŠµ ì§„í–‰")
            else:
                print(f"\n[WARNING] ì²´í¬í¬ì¸íŠ¸ ë¡œë”© ì‹¤íŒ¨, ì²˜ìŒë¶€í„° í•™ìŠµ ì§„í–‰")
        
        print(f"\n[START] Property Prediction Transformer í•™ìŠµ ì‹œì‘")
        print(f"   - ì—í­ ìˆ˜: {start_epoch} ì‹œì‘, {num_epochs} ê¹Œì§€ (ìµœëŒ€ {num_epochs - start_epoch} ì—í­)")
        print(f"   - í•™ìŠµ ìƒ˜í”Œ: {len(self.train_dataset)}")
        print(f"   - ê²€ì¦ ìƒ˜í”Œ: {len(self.val_dataset)}")
        print(f"   - ë°°ì¹˜ í¬ê¸°: {self.train_loader.batch_size}")
        print(f"   - Early stopping ì¸ë‚´: {self.patience} ì—í­ (ìµœì†Œ ê°œì„ ì¹˜: {self.min_delta:.6f})")
        print(f"   - í˜„ì¬ ìµœì  ê²€ì¦ ì†ì‹¤: {self.best_val_loss:.6f}")
        print(f"   - Early stopping ì¹´ìš´í„°: {self.early_stopping_counter}/{self.patience}")
        
        # ì´ë¯¸ Early stopping ì¡°ê±´ì— ë„ë‹¬í•œ ê²½ìš°
        if self.early_stopping_counter >= self.patience:
            print(f"\n[WARNING] Early stopping ì„ê³„ì¹˜({self.patience})ì— ì´ë¯¸ ë„ë‹¬í–ˆìŠµë‹ˆë‹¤. í•™ìŠµì„ ì§„í–‰í•˜ë ¤ë©´ early_stopping_counterë¥¼ ìˆ˜ë™ìœ¼ë¡œ ë¦¬ì…‹í•´ì•¼ í•©ë‹ˆë‹¤.")
            return False
        
        start_time = time.time()
        
        for epoch in range(start_epoch, num_epochs):
            epoch_start_time = time.time()
            self.current_epoch = epoch
            
            # ë©”ëª¨ë¦¬ ì •ë¦¬ (ì£¼ê¸°ì )
            if self.device.type == 'cuda' and epoch % 3 == 0:
                torch.cuda.empty_cache()
            
            # Training
            train_losses = self.train_epoch()
            
            # Validation
            val_losses = self.validate()
            
            epoch_duration = time.time() - epoch_start_time
            
            # Early stopping ì²˜ë¦¬
            improved = False
            
            # ìŠ¤ì¼€ì¤„ëŸ¬ ì—…ë°ì´íŠ¸ (validation loss ê¸°ë°˜)
            self.scheduler.step(val_losses['total'])
            
            # ìµœì  ëª¨ë¸ ì €ì¥
            if val_losses['total'] < self.best_val_loss - self.min_delta:
                improved = True
                self.early_stopping_counter = 0  # ê°œì„ ë˜ì—ˆìœ¼ë‹ˆ ì¹´ìš´í„° ë¦¬ì…‹
                self.best_val_loss = val_losses['total']
                self.save_checkpoint('best_model.pt')
                print(f"[SAVE] ìµœê³  ëª¨ë¸ ì €ì¥ (val_loss: {self.best_val_loss:.4f})")
            else:
                self.early_stopping_counter += 1
                print(f"   [WAIT] ê°œì„ ë˜ì§€ ì•ŠìŒ: {self.early_stopping_counter}/{self.patience} (ìµœê³ : {self.best_val_loss:.4f})")
            
            # í•™ìŠµë¥  ê°ì†Œ ì²´í¬
            current_lr = self.optimizer.param_groups[0]['lr']
            if current_lr <= self.min_lr:
                print(f"[WARNING] í•™ìŠµë¥ ì´ ìµœì†Œê°’({self.min_lr:.8f})ì— ë„ë‹¬í–ˆìŠµë‹ˆë‹¤. í•™ìŠµ ì¤‘ì§€.")
                break
            
            # Log results
            epoch_results = {
                'epoch': epoch,
                'train_loss': train_losses['total'],
                'val_loss': val_losses['total'],
                'train_entanglement': train_losses['entanglement'],
                'val_entanglement': val_losses['entanglement'],
                'train_fidelity': train_losses['fidelity'],
                'val_fidelity': val_losses['fidelity'],
                'train_expressibility': train_losses['expressibility'],
                'val_expressibility': val_losses['expressibility'],
                'learning_rate': current_lr,
                'duration_sec': epoch_duration,
                'improved': improved
            }
            
            # ì¶”ê°€ ê²€ì¦ ë©”íŠ¸ë¦­ë“¤ ê¸°ë¡
            for key, value in val_losses.items():
                if key.endswith('_mae') or key.endswith('_r2') or key.endswith('_corr') or key.endswith('_rmse'):
                    epoch_results[f'val_{key}'] = value
            
            self.training_history.append(epoch_results)
            
            # ìƒì„¸ ì§„í–‰ë¥  ì¶œë ¥ (4ê°€ì§€ ì •í™•ë„ ë©”íŠ¸ë¦­ í¬í•¨)
            metrics_str = ""
            for prop in ['entanglement', 'fidelity', 'expressibility']:
                mae_key = f'val_{prop}_mae'
                r2_key = f'val_{prop}_r2'
                if mae_key in val_losses and r2_key in val_losses:
                    metrics_str += f" | {prop[:3].upper()}: MAE={val_losses[mae_key]:.3f}, RÂ²={val_losses[r2_key]:.3f}"
            
            print(f"Epoch {epoch:3d}/{num_epochs-1} | "
                  f"Train: {train_losses['total']:.4f} | "
                  f"Val: {val_losses['total']:.4f} | "
                  f"LR: {current_lr:.2e} | "
                  f"Time: {epoch_duration:.1f}s{metrics_str}")
            
            # ì£¼ê¸°ì  ì²´í¬í¬ì¸íŠ¸ ì €ì¥
            if (epoch + 1) % 10 == 0:
                self.save_checkpoint(f'checkpoint_epoch_{epoch+1}.pt')
                
            # Early stopping íš¨ê³¼
            if self.early_stopping_counter >= self.patience:
                print(f"[WARNING] Early stopping í™œì„±í™”: {self.patience} ì—í­ ë™ì•ˆ ê°œì„  ì—†ìŒ")
                self.early_stopped = True
                break
        
        # í•™ìŠµ ì™„ë£Œ ë©”ì‹œì§€
        total_time = time.time() - start_time
        hours, remainder = divmod(total_time, 3600)
        minutes, seconds = divmod(remainder, 60)
        
        if self.early_stopped:
            print(f"[DONE] Early stoppingìœ¼ë¡œ í•™ìŠµ ì¡°ê¸° ì¢…ë£Œ! (ì´ {self.current_epoch+1} ì—í­, {int(hours)}h {int(minutes)}m {int(seconds)}s)")
        else:
            print(f"[DONE] ê³„íšëœ í•™ìŠµ ì™„ë£Œ! (ì´ {self.current_epoch+1} ì—í­, {int(hours)}h {int(minutes)}m {int(seconds)}s)")
        
        # ìµœì¢… ê²°ê³¼ ì €ì¥ ë° ì‹œê°í™”ìš© ë°ì´í„° ìƒì„±
        self.save_training_history()
        self.save_metrics_for_visualization()
        
        # í•™ìŠµ í†µê³„ ê³„ì‚°
        total_duration = total_time  # ì´ë¯¸ ê³„ì‚°ëœ total_time ì‚¬ìš©
        epoch_count = self.current_epoch - start_epoch + 1
        epoch_mean_time = total_duration / max(1, epoch_count)
        best_epoch = 0
        best_val_loss = float('inf')
        
        # ìµœì  ì—í­ ì°¾ê¸°
        for i, epoch_data in enumerate(self.training_history):
            if epoch_data.get('val_total', float('inf')) < best_val_loss:
                best_val_loss = epoch_data.get('val_total', float('inf'))
                best_epoch = i
        
        # ìµœì¢… í•™ìŠµë¥  í™•ì¸
        current_lr = self.optimizer.param_groups[0]['lr']
        
        # ê²°ê³¼ ë°˜í™˜
        return {
            'training_history': self.training_history,
            'best_val_loss': self.best_val_loss,
            'best_epoch': best_epoch,
            'early_stopped': self.early_stopped,
            'early_stopping_counter': self.early_stopping_counter,
            'last_epoch': self.current_epoch,
            'total_epochs': epoch_count,
            'total_duration': total_duration,
            'epoch_mean_time': epoch_mean_time,
            'final_lr': current_lr,
            'best_model_path': str(self.save_dir / 'best_model.pt'),
            'device': str(self.device),
            'metrics_file': str(self.save_dir / 'training_metrics.json'),
            'visualization_data': str(self.save_dir / 'visualization_data.json')
        }
    
    def save_checkpoint(self, filename: str):
        """ì²´í¬í¬ì¸íŠ¸ ì €ì¥ - ë©”íƒ€ë°ì´í„° ì¶”ê°€ ë° ë³´ì•ˆ ê°œì„ """
        try:
            # í˜„ì¬ GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í™•ì¸
            gpu_memory_info = None
            if self.device.type == 'cuda':
                gpu_memory_info = {
                    'allocated': torch.cuda.memory_allocated() / (1024**3),
                    'reserved': torch.cuda.memory_reserved() / (1024**3),
                    'max_allocated': torch.cuda.max_memory_allocated() / (1024**3)
                }
            
            # ì²´í¬í¬ì¸íŠ¸ ë°ì´í„° êµ¬ì„±
            checkpoint = {
                # í•™ìŠµ ìƒíƒœ
                'epoch': self.current_epoch,
                'model_state_dict': self.model.state_dict(),
                'optimizer_state_dict': self.optimizer.state_dict(),
                'scheduler_state_dict': self.scheduler.state_dict(),
                'best_val_loss': self.best_val_loss,
                
                # êµ¬ì„± ë° ê¸°ë¡
                'config': asdict(self.config),
                'training_history': self.training_history,
                
                # ì¶”ê°€ ë©”íƒ€ë°ì´í„°
                'early_stopping': {
                    'counter': self.early_stopping_counter,
                    'patience': self.patience,
                    'min_delta': self.min_delta,
                    'stopped_early': self.early_stopped
                },
                
                # ì‹œìŠ¤í…œ ì •ë³´
                'timestamp': time.time(),
                'save_date': time.strftime('%Y-%m-%d %H:%M:%S'),
                'device': str(self.device),
                'gpu_memory': gpu_memory_info
            }
            
            # ì²´í¬í¬ì¸íŠ¸ ì €ì¥ ê²½ë¡œ êµ¬ì„±
            checkpoint_path = self.save_dir / filename
            
            # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥ í›„ ì´ë™ (íŒŒì¼ ì†ìƒ ë°©ì§€)
            temp_path = self.save_dir / f"temp_{filename}"
            torch.save(checkpoint, temp_path)
            
            # ì´ë¯¸ íŒŒì¼ì´ ìˆëŠ” ê²½ìš° ë°±ì—…
            if checkpoint_path.exists():
                backup_path = self.save_dir / f"backup_{filename}"
                if backup_path.exists():
                    backup_path.unlink()  # ê¸°ì¡´ ë°±ì—… ì‚­ì œ
                checkpoint_path.rename(backup_path)  # ê¸°ì¡´ íŒŒì¼ì„ ë°±ì—…ìœ¼ë¡œ ì´ë™
            
            # ì„ì‹œ íŒŒì¼ì„ ìµœì¢… íŒŒì¼ë¡œ ì´ë¦„ ë³€ê²½
            temp_path.rename(checkpoint_path)
            
            # ì„±ê³µ ë©”ì‹œì§€ (ìƒì„¸ ì¶œë ¥ ì˜µì…˜
            if 'best_model' in filename:
                print(f"[DONE] ì²´í¬í¬ì¸íŠ¸ ì €ì¥ ì™„ë£Œ: {checkpoint_path.name} ")
            
            return True
            
        except Exception as e:
            print(f"\n[ERROR] ì²´í¬í¬ì¸íŠ¸ ì €ì¥ ì˜¤ë¥˜: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    def save_training_history(self):
        """í•™ìŠµ ê¸°ë¡ ì €ì¥"""
        history_path = self.save_dir / 'training_history.json'
        with open(history_path, 'w') as f:
            json.dump(self.training_history, f, indent=2)
        
        print(f"[SAVE] í•™ìŠµ ê¸°ë¡ ì €ì¥: {history_path}")
    
    def load_checkpoint(self, checkpoint_path: str):
        """
        ì²´í¬í¬ì¸íŠ¸ë¥¼ ë¶ˆëŸ¬ì™€ ëª¨ë¸ê³¼ í•™ìŠµ ìƒíƒœë¥¼ ë³µì›
        
        Args:
            checkpoint_path: ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ ê²½ë¡œ
            
        Returns:
            bool: ë¡œë”© ì„±ê³µ ì—¬ë¶€
            
        """
        try:
            # Path ê°ì²´ë¡œ ë³€í™˜
            checkpoint_path = Path(checkpoint_path)
            if not checkpoint_path.exists():
                print(f"\n[ERROR] ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {checkpoint_path}")
                return False
                
            # CPUì—ì„œ ë¡œë”© (ì•ˆì •ì„±ì„ ìœ„í•´)
            print(f"\n[LOAD] ì²´í¬í¬ì¸íŠ¸ ë¡œë”© ì¤‘: {checkpoint_path.name}")
            checkpoint = torch.load(checkpoint_path, map_location='cpu')
            
            # ê¸°ë³¸ í•„ìˆ˜ í•„ë“œ ê²€ìƒ‰
            required_fields = ['model_state_dict', 'optimizer_state_dict', 'epoch']
            for field in required_fields:
                if field not in checkpoint:
                    print(f"\n[ERROR] ì²´í¬í¬ì¸íŠ¸ì— í•„ìˆ˜ í•„ë“œ '{field}'ê°€ ì—†ìŠµë‹ˆë‹¤.")
                    return False
            
            # ìƒì„¸ ì •ë³´ ì¶œë ¥ (ë©”íƒ€ë°ì´í„°)
            if 'save_date' in checkpoint:
                print(f"  - ì €ì¥ ì‹œì : {checkpoint['save_date']}")
            print(f"  - ì—í­: {checkpoint['epoch']}")
            if 'best_val_loss' in checkpoint:
                print(f"  - ìµœì  ê²€ì¦ ì†ì‹¤: {checkpoint['best_val_loss']:.6f}")
            
            # GPU ë©”ëª¨ë¦¬ ì •ë¦¬
            if self.device.type == 'cuda':
                torch.cuda.empty_cache()
            
            # ëª¨ë¸ ê°€ì¤‘ì¹˜ ë¡œë”©
            self.model.load_state_dict(checkpoint['model_state_dict'])
            
            # ì¶”ê°€ ìƒíƒœ ë³µì›
            self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
            
            # ìŠ¤ì¼€ì¤„ëŸ¬ ë³µì›
            if 'scheduler_state_dict' in checkpoint:
                try:
                    self.scheduler.load_state_dict(checkpoint['scheduler_state_dict'])
                except Exception as e:
                    print(f"  âš ï¸ ìŠ¤ì¼€ì¤„ëŸ¬ ë³µì› ì˜¤ë¥˜ (skip): {e}")
            
            # í•™ìŠµ ê¸°ë¡ ë³µì›
            if 'training_history' in checkpoint:
                self.training_history = checkpoint['training_history']
            
            # ê¸°íƒ€ í•„ë“œ ë³µì›
            self.current_epoch = checkpoint['epoch']
            if 'best_val_loss' in checkpoint:
                self.best_val_loss = checkpoint['best_val_loss']
            
            # Early stopping ê´€ë ¨ í•„ë“œ ë³µì›
            if 'early_stopping' in checkpoint:
                es_info = checkpoint['early_stopping']
                if 'counter' in es_info:
                    self.early_stopping_counter = es_info['counter']
                if 'patience' in es_info:
                    self.patience = es_info['patience']
                if 'min_delta' in es_info:
                    self.min_delta = es_info['min_delta']
                if 'stopped_early' in es_info:
                    self.early_stopped = es_info['stopped_early']
            
            # ëª¨ë¸ì„ ì ì ˆí•œ ê¸°ê¸°ë¡œ ì´ë™
            self.model = self.model.to(self.device)
            
            print(f"\nâœ… ì²´í¬í¬ì¸íŠ¸ ë¡œë”© ì„±ê³µ! í•™ìŠµì„ ì—í­ {self.current_epoch+1}ë¶€í„° ê³„ì†í•©ë‹ˆë‹¤.")
            return True
            
        except Exception as e:
            print(f"\nâš ï¸ ì²´í¬í¬ì¸íŠ¸ ë¡œë”© ì˜¤ë¥˜: {e}")
            import traceback
            traceback.print_exc()
            return False

    def save_metrics_for_visualization(self):
        """ì‹œê°í™”ë¥¼ ìœ„í•œ ë©”íŠ¸ë¦­ ë°ì´í„° ì €ì¥"""
        try:
            import json
            from datetime import datetime
            
            # ì‹œê°í™”ìš© ë°ì´í„° êµ¬ì¡° ìƒì„±
            visualization_data = {
                'metadata': {
                    'experiment_name': 'property_prediction_training',
                    'timestamp': datetime.now().isoformat(),
                    'total_epochs': len(self.training_history),
                    'device': str(self.device),
                    'model_config': {
                        'd_model': getattr(self.config, 'd_model', 512),
                        'n_heads': getattr(self.config, 'n_heads', 8),
                        'n_layers': getattr(self.config, 'n_layers', 6),
                        'attention_mode': getattr(self.config, 'attention_mode', 'advanced')
                    }
                },
                'metrics': {
                    'epochs': [],
                    'train_loss': [],
                    'val_loss': [],
                    'learning_rate': [],
                    'duration_sec': [],
                    'properties': {
                        'entanglement': {
                            'train_loss': [], 'val_loss': [],
                            'val_mae': [], 'val_rmse': [], 'val_r2': [], 'val_corr': []
                        },
                        'fidelity': {
                            'train_loss': [], 'val_loss': [],
                            'val_mae': [], 'val_rmse': [], 'val_r2': [], 'val_corr': []
                        },
                        'expressibility': {
                            'train_loss': [], 'val_loss': [],
                            'val_mae': [], 'val_rmse': [], 'val_r2': [], 'val_corr': []
                        }
                    }
                }
            }
            
            # ì—í¬í¬ë³„ ë°ì´í„° ì¶”ì¶œ
            for epoch_data in self.training_history:
                visualization_data['metrics']['epochs'].append(epoch_data.get('epoch', 0))
                visualization_data['metrics']['train_loss'].append(epoch_data.get('train_loss', 0.0))
                visualization_data['metrics']['val_loss'].append(epoch_data.get('val_loss', 0.0))
                visualization_data['metrics']['learning_rate'].append(epoch_data.get('learning_rate', 0.0))
                visualization_data['metrics']['duration_sec'].append(epoch_data.get('duration_sec', 0.0))
                
                # í”„ë¡œí¼í‹°ë³„ ë©”íŠ¸ë¦­ ì¶”ì¶œ
                for prop in ['entanglement', 'fidelity', 'expressibility']:
                    prop_data = visualization_data['metrics']['properties'][prop]
                    prop_data['train_loss'].append(epoch_data.get(f'train_{prop}', 0.0))
                    prop_data['val_loss'].append(epoch_data.get(f'val_{prop}', 0.0))
                    
                    # ì •í™•ë„ ë©”íŠ¸ë¦­ë“¤
                    for metric in ['mae', 'rmse', 'r2', 'corr']:
                        key = f'val_{prop}_{metric}'
                        prop_data[f'val_{metric}'].append(epoch_data.get(key, 0.0))
            
            # ì‹œê°í™” ë°ì´í„° ì €ì¥
            viz_file = self.save_dir / 'visualization_data.json'
            with open(viz_file, 'w', encoding='utf-8') as f:
                json.dump(visualization_data, f, indent=2, ensure_ascii=False)
            
            # ìš”ì•½ í†µê³„ ê³„ì‚° ë° ì €ì¥
            summary_stats = self._calculate_training_summary()
            summary_file = self.save_dir / 'training_summary.json'
            with open(summary_file, 'w', encoding='utf-8') as f:
                json.dump(summary_stats, f, indent=2, ensure_ascii=False)
            
            print(f"ğŸ“Š ì‹œê°í™” ë°ì´í„° ì €ì¥ ì™„ë£Œ:")
            print(f"  - ë©”íŠ¸ë¦­ ë°ì´í„°: {viz_file}")
            print(f"  - í•™ìŠµ ìš”ì•½: {summary_file}")
            
        except Exception as e:
            print(f"[ERROR] ì‹œê°í™” ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
    
    def _calculate_training_summary(self) -> dict:
        """í•™ìŠµ ìš”ì•½ í†µê³„ ê³„ì‚°"""
        if not self.training_history:
            return {}
        
        summary = {
            'training_overview': {
                'total_epochs': len(self.training_history),
                'best_epoch': 0,
                'best_val_loss': self.best_val_loss,
                'early_stopped': getattr(self, 'early_stopped', False),
                'final_learning_rate': self.training_history[-1].get('learning_rate', 0.0)
            },
            'loss_progression': {
                'initial_train_loss': self.training_history[0].get('train_loss', 0.0),
                'final_train_loss': self.training_history[-1].get('train_loss', 0.0),
                'initial_val_loss': self.training_history[0].get('val_loss', 0.0),
                'final_val_loss': self.training_history[-1].get('val_loss', 0.0)
            },
            'property_performance': {}
        }
        
        # ìµœì  ì—í¬í¬ ì°¾ê¸°
        best_val_loss = float('inf')
        for i, epoch_data in enumerate(self.training_history):
            if epoch_data.get('val_loss', float('inf')) < best_val_loss:
                best_val_loss = epoch_data.get('val_loss', float('inf'))
                summary['training_overview']['best_epoch'] = i
        
        # í”„ë¡œí¼í‹°ë³„ ìµœì¢… ì„±ëŠ¥
        final_epoch = self.training_history[-1]
        for prop in ['entanglement', 'fidelity', 'expressibility']:
            prop_summary = {}
            for metric in ['mae', 'rmse', 'r2', 'corr']:
                key = f'val_{prop}_{metric}'
                if key in final_epoch:
                    prop_summary[f'final_{metric}'] = final_epoch[key]
            
            if prop_summary:
                summary['property_performance'][prop] = prop_summary
        
        return summary


def create_datasets(data_path: str, train_ratio: float = 0.7, val_ratio: float = 0.15, 
                   enable_augmentation: bool = True) -> Tuple[PropertyPredictionDataset, PropertyPredictionDataset, PropertyPredictionDataset]:
    """merged_data.jsonì„ ì‚¬ìš©í•œ ë°ì´í„°ì…‹ ë¶„í•  ìƒì„± (ì¦ê°• ì§€ì›)"""
    # Create dataset manager
    manager = DatasetManager(unified_data_path=data_path)
    
    # Split quantum datasets
    train_quantum, val_quantum, test_quantum = manager.split_dataset(
        train_ratio=train_ratio,
        val_ratio=val_ratio,
        test_ratio=1.0 - train_ratio - val_ratio
    )
    
    # Apply augmentation to training set if enabled
    if enable_augmentation:
        from data.augmented_dataset import create_augmented_datasets
        train_quantum, val_quantum, test_quantum = create_augmented_datasets(
            train_quantum, val_quantum, test_quantum,
            mixup_samples=500,
            noise_samples=500,
            param_random_samples=1000
        )
    
    # Wrap with PropertyPredictionDataset
    train_dataset = PropertyPredictionDataset(train_quantum)
    val_dataset = PropertyPredictionDataset(val_quantum)
    test_dataset = PropertyPredictionDataset(test_quantum)
    
    print(f"ğŸ“Š ë°ì´í„°ì…‹ ë¶„í•  ì™„ë£Œ:")
    print(f"  - Train: {len(train_dataset)} ìƒ˜í”Œ")
    print(f"  - Validation: {len(val_dataset)} ìƒ˜í”Œ")
    print(f"  - Test: {len(test_dataset)} ìƒ˜í”Œ")
    
    return train_dataset, val_dataset, test_dataset


if __name__ == "__main__":
    # Configuration
    config = PropertyPredictionConfig(
        d_model=512,
        n_heads=8,
        n_layers=6,
        attention_mode="advanced",
        dropout=0.1,
        learning_rate=1e-4,
        property_dim=3  # entanglement, fidelity, expressibility
    )
    
    # Create model
    from models.property_prediction_transformer import create_property_prediction_model
    model = create_property_prediction_model(config)
    
    # Load datasets using merged_data.json
    data_path = r"C:\Users\jungh\Documents\GitHub\Kaist\OAT_Model\raw_data\merged_data.json"
    
    try:
        train_dataset, val_dataset, test_dataset = create_datasets(data_path)
        
        # Create trainer
        trainer = PropertyPredictionTrainer(
            model=model,
            config=config,
            train_dataset=train_dataset,
            val_dataset=val_dataset,
            save_dir="property_prediction_checkpoints"
        )
        
        # Start training
        print("ğŸš€ Starting Property Prediction Training...")
        results = trainer.train(num_epochs=100)
        
        print(f"âœ… Training completed!")
        print(f"ğŸ“Š Best validation loss: {results['best_val_loss']:.4f}")
        print(f"ğŸ“ Best model saved at: {results['best_model_path']}")
        
    except Exception as e:
        print(f"âŒ Training failed: {e}")
        import traceback
        traceback.print_exc()
