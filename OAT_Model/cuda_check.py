#!/usr/bin/env python3
"""
CUDA ë° GPU ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ ì§„ë‹¨ ìŠ¤í¬ë¦½íŠ¸
"""

import torch
import sys
import subprocess
import os

def check_cuda_availability():
    """CUDA ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ ì²´í¬"""
    print("=" * 60)
    print("ğŸ” CUDA ë° GPU ì§„ë‹¨ ì‹œì‘")
    print("=" * 60)
    
    # 1. PyTorch ë²„ì „ í™•ì¸
    print(f"ğŸ“¦ PyTorch ë²„ì „: {torch.__version__}")
    
    # 2. CUDA ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€
    cuda_available = torch.cuda.is_available()
    print(f"ğŸ¯ CUDA ì‚¬ìš© ê°€ëŠ¥: {cuda_available}")
    
    if not cuda_available:
        print("âŒ CUDAë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤!")
        print("\nê°€ëŠ¥í•œ ì›ì¸ë“¤:")
        print("1. CUDAê°€ ì„¤ì¹˜ë˜ì§€ ì•ŠìŒ")
        print("2. PyTorchê°€ CPU ë²„ì „ìœ¼ë¡œ ì„¤ì¹˜ë¨")
        print("3. NVIDIA ë“œë¼ì´ë²„ ë¬¸ì œ")
        print("4. í™˜ê²½ ë³€ìˆ˜ ì„¤ì • ë¬¸ì œ")
        return False
    
    # 3. CUDA ë²„ì „ ì •ë³´
    print(f"ğŸ”§ CUDA ë²„ì „: {torch.version.cuda}")
    print(f"ğŸ”§ cuDNN ë²„ì „: {torch.backends.cudnn.version()}")
    
    # 4. GPU ê°œìˆ˜ ë° ì •ë³´
    gpu_count = torch.cuda.device_count()
    print(f"ğŸ® ì‚¬ìš© ê°€ëŠ¥í•œ GPU ê°œìˆ˜: {gpu_count}")
    
    for i in range(gpu_count):
        gpu_name = torch.cuda.get_device_name(i)
        gpu_memory = torch.cuda.get_device_properties(i).total_memory / 1024**3
        print(f"  GPU {i}: {gpu_name} ({gpu_memory:.1f} GB)")
    
    # 5. í˜„ì¬ GPU ì„¤ì •
    if gpu_count > 0:
        current_device = torch.cuda.current_device()
        print(f"ğŸ¯ í˜„ì¬ ì‚¬ìš© ì¤‘ì¸ GPU: {current_device}")
    
    return True

def test_gpu_operations():
    """GPU ì—°ì‚° í…ŒìŠ¤íŠ¸"""
    print("\n" + "=" * 60)
    print("ğŸ§ª GPU ì—°ì‚° í…ŒìŠ¤íŠ¸")
    print("=" * 60)
    
    if not torch.cuda.is_available():
        print("âŒ CUDAë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ì–´ í…ŒìŠ¤íŠ¸ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
        return False
    
    try:
        # ê°„ë‹¨í•œ í…ì„œ ì—°ì‚° í…ŒìŠ¤íŠ¸
        print("ğŸ”„ GPU ë©”ëª¨ë¦¬ í• ë‹¹ í…ŒìŠ¤íŠ¸...")
        device = torch.device('cuda')
        
        # ì‘ì€ í…ì„œë¡œ ì‹œì‘
        x = torch.randn(100, 100, device=device)
        y = torch.randn(100, 100, device=device)
        
        print("âœ… í…ì„œ ìƒì„± ì„±ê³µ")
        
        # í–‰ë ¬ ê³±ì…ˆ í…ŒìŠ¤íŠ¸
        print("ğŸ”„ í–‰ë ¬ ê³±ì…ˆ í…ŒìŠ¤íŠ¸...")
        z = torch.matmul(x, y)
        print("âœ… í–‰ë ¬ ê³±ì…ˆ ì„±ê³µ")
        
        # GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í™•ì¸
        allocated = torch.cuda.memory_allocated() / 1024**2
        cached = torch.cuda.memory_reserved() / 1024**2
        print(f"ğŸ“Š GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {allocated:.1f} MB (í• ë‹¹) / {cached:.1f} MB (ìºì‹œ)")
        
        # ë©”ëª¨ë¦¬ ì •ë¦¬
        del x, y, z
        torch.cuda.empty_cache()
        print("ğŸ§¹ GPU ë©”ëª¨ë¦¬ ì •ë¦¬ ì™„ë£Œ")
        
        return True
        
    except Exception as e:
        print(f"âŒ GPU ì—°ì‚° í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        return False

def check_nvidia_driver():
    """NVIDIA ë“œë¼ì´ë²„ í™•ì¸"""
    print("\n" + "=" * 60)
    print("ğŸš— NVIDIA ë“œë¼ì´ë²„ í™•ì¸")
    print("=" * 60)
    
    try:
        result = subprocess.run(['nvidia-smi'], capture_output=True, text=True, timeout=10)
        if result.returncode == 0:
            print("âœ… nvidia-smi ì‹¤í–‰ ì„±ê³µ")
            print("\nGPU ì •ë³´:")
            print(result.stdout)
            return True
        else:
            print("âŒ nvidia-smi ì‹¤í–‰ ì‹¤íŒ¨")
            print(f"ì—ëŸ¬: {result.stderr}")
            return False
    except FileNotFoundError:
        print("âŒ nvidia-smië¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. NVIDIA ë“œë¼ì´ë²„ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        return False
    except subprocess.TimeoutExpired:
        print("âŒ nvidia-smi ì‹¤í–‰ ì‹œê°„ ì´ˆê³¼")
        return False
    except Exception as e:
        print(f"âŒ nvidia-smi ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
        return False

def check_environment():
    """í™˜ê²½ ë³€ìˆ˜ í™•ì¸"""
    print("\n" + "=" * 60)
    print("ğŸŒ í™˜ê²½ ë³€ìˆ˜ í™•ì¸")
    print("=" * 60)
    
    cuda_vars = ['CUDA_PATH', 'CUDA_HOME', 'CUDA_ROOT']
    for var in cuda_vars:
        value = os.environ.get(var)
        if value:
            print(f"âœ… {var}: {value}")
        else:
            print(f"âŒ {var}: ì„¤ì •ë˜ì§€ ì•ŠìŒ")
    
    # PATHì—ì„œ CUDA í™•ì¸
    path = os.environ.get('PATH', '')
    cuda_in_path = any('cuda' in p.lower() for p in path.split(os.pathsep))
    print(f"ğŸ›¤ï¸  PATHì— CUDA í¬í•¨: {cuda_in_path}")

def provide_solutions():
    """í•´ê²° ë°©ë²• ì œì‹œ"""
    print("\n" + "=" * 60)
    print("ğŸ’¡ ë¬¸ì œ í•´ê²° ë°©ë²•")
    print("=" * 60)
    
    if not torch.cuda.is_available():
        print("CUDAë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ëŠ” ê²½ìš° í•´ê²° ë°©ë²•:")
        print("\n1. PyTorch ì¬ì„¤ì¹˜ (CUDA ë²„ì „):")
        print("   pip uninstall torch torchvision torchaudio")
        print("   pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118")
        
        print("\n2. NVIDIA ë“œë¼ì´ë²„ ì„¤ì¹˜/ì—…ë°ì´íŠ¸:")
        print("   https://www.nvidia.com/drivers ì—ì„œ ìµœì‹  ë“œë¼ì´ë²„ ë‹¤ìš´ë¡œë“œ")
        
        print("\n3. CUDA Toolkit ì„¤ì¹˜:")
        print("   https://developer.nvidia.com/cuda-downloads")
        
        print("\n4. í™˜ê²½ ë³€ìˆ˜ ì„¤ì •:")
        print("   CUDA_PATH=C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v11.8")
        print("   PATHì— %CUDA_PATH%\\bin ì¶”ê°€")

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("ğŸš€ CUDA ì§„ë‹¨ ìŠ¤í¬ë¦½íŠ¸ ì‹œì‘\n")
    
    # 1. CUDA ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
    cuda_ok = check_cuda_availability()
    
    # 2. NVIDIA ë“œë¼ì´ë²„ í™•ì¸
    driver_ok = check_nvidia_driver()
    
    # 3. í™˜ê²½ ë³€ìˆ˜ í™•ì¸
    check_environment()
    
    # 4. GPU ì—°ì‚° í…ŒìŠ¤íŠ¸ (CUDA ì‚¬ìš© ê°€ëŠ¥í•œ ê²½ìš°)
    if cuda_ok:
        test_ok = test_gpu_operations()
    else:
        test_ok = False
    
    # 5. ê²°ê³¼ ìš”ì•½
    print("\n" + "=" * 60)
    print("ğŸ“‹ ì§„ë‹¨ ê²°ê³¼ ìš”ì•½")
    print("=" * 60)
    print(f"CUDA ì‚¬ìš© ê°€ëŠ¥: {'âœ…' if cuda_ok else 'âŒ'}")
    print(f"NVIDIA ë“œë¼ì´ë²„: {'âœ…' if driver_ok else 'âŒ'}")
    print(f"GPU ì—°ì‚° í…ŒìŠ¤íŠ¸: {'âœ…' if test_ok else 'âŒ'}")
    
    if not (cuda_ok and driver_ok and test_ok):
        print("\nâŒ ë¬¸ì œê°€ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤.")
        provide_solutions()
    else:
        print("\nâœ… ëª¨ë“  í…ŒìŠ¤íŠ¸ í†µê³¼! GPUë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    
    print("\n" + "=" * 60)

if __name__ == "__main__":
    main()
