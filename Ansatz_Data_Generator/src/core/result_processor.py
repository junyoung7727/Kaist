#!/usr/bin/env python3
"""
ê²°ê³¼ ì²˜ë¦¬ ëª¨ë“ˆ - ì–‘ì íšŒë¡œ ì‹¤í–‰ ê²°ê³¼ ì²˜ë¦¬ ë° ë¶„ì„ ë¡œì§ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤.
"""

import sys
import os
import json
import pandas as pd
import numpy as np
from typing import Dict, List, Any, Optional, Union, Tuple
from datetime import datetime
import gc
from tqdm import tqdm

# í‘œí˜„ë ¥ ê³„ì‚° ëª¨ë“ˆ ì„í¬íŠ¸
from src.calculators.expressibility.ibm import IBMExpressibilityCalculator

# í˜„ì¬ ìŠ¤í¬ë¦½íŠ¸ì˜ ìƒìœ„ ë””ë ‰í† ë¦¬ë¥¼ ì‹œìŠ¤í…œ ê²½ë¡œì— ì¶”ê°€ (ëª¨ë“ˆ ì„í¬íŠ¸ë¥¼ ìœ„í•¨)
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))
from src.config import config # Ensure config is imported

from data_manager import save_experiment_hdf5


def make_json_serializable(obj):
    """
    ì¬ê·€ì ìœ¼ë¡œ ê°ì²´ë¥¼ JSON ì§ë ¬í™” ê°€ëŠ¥í•œ í˜•íƒœë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    QuantumCircuit ë“±ì˜ ê°ì²´ëŠ” ë¬¸ìì—´ í‘œí˜„ìœ¼ë¡œ ë³€í™˜ë©ë‹ˆë‹¤.
    """
    if hasattr(obj, '__dict__'):
        # QuantumCircuit ë“±ì˜ ë³µì¡í•œ ê°ì²´
        if hasattr(obj, 'name') and hasattr(obj, 'num_qubits'):
            return {
                "type": "QuantumCircuit",
                "name": getattr(obj, 'name', 'unnamed'),
                "num_qubits": getattr(obj, 'num_qubits', 0),
                "depth": getattr(obj, 'depth', lambda: 0)(),
                "size": getattr(obj, 'size', lambda: 0)()
            }
        else:
            # ë‹¤ë¥¸ ê°ì²´ë“¤ì€ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
            try:
                return {k: make_json_serializable(v) for k, v in obj.__dict__.items() 
                       if not k.startswith('_')}
            except:
                return str(obj)
    elif isinstance(obj, dict):
        return {k: make_json_serializable(v) for k, v in obj.items()}
    elif isinstance(obj, (list, tuple)):
        return [make_json_serializable(item) for item in obj]
    elif isinstance(obj, (int, float, str, bool)) or obj is None:
        return obj
    elif hasattr(obj, 'tolist'):  # numpy arrays
        return obj.tolist()
    else:
        # ì§ë ¬í™”í•  ìˆ˜ ì—†ëŠ” ê°ì²´ëŠ” ë¬¸ìì—´ë¡œ ë³€í™˜
        return str(obj)


def process_mega_results(analysis_results, circuit_metadata, execution_time, ibm_backend):
    """
    ë©”ê°€ ì¡(Mega job) ë¶„ì„ ê²°ê³¼ ì²˜ë¦¬ - í”¼ë¸ë¦¬í‹° ë° í‘œí˜„ë ¥ ë¶„ì„ ê²°ê³¼ë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤.
    
    Args:
        analysis_results (Dict): run_analysis_jobì—ì„œ ë°˜í™˜ëœ ë¶„ì„ ê²°ê³¼
            (íšŒë¡œë³„ í”¼ë¸ë¦¬í‹°ì™€ í‘œí˜„ë ¥ ê°’ì´ í¬í•¨ë¨)
        circuit_metadata (List[Dict]): ê° íšŒë¡œì— ëŒ€í•œ ë©”íƒ€ë°ì´í„° ëª©ë¡ì…ë‹ˆë‹¤.
        execution_time (float): ì „ì²´ ì‘ì—… ì‹¤í–‰ì— ì†Œìš”ëœ ì‹œê°„(ì´ˆ)ì…ë‹ˆë‹¤.
        ibm_backend: IBM ë°±ì—”ë“œ ê´€ë¦¬ ê°ì²´
        
    Returns:
        List[Dict]: ê° íšŒë¡œë³„ë¡œ ì²˜ë¦¬ëœ ê²°ê³¼ì˜ ëª©ë¡ì…ë‹ˆë‹¤.
    """
    from src.utils.quantum_utils import (
        calculate_error_rates_mega,
        calculate_robust_fidelity_mega,
        calculate_measurement_statistics
    )
    
    print(f"\nğŸ”¬ ë©”ê°€ ì¡ ë¶„ì„ ê²°ê³¼ ì²˜ë¦¬ ì‹œì‘ ({len(circuit_metadata)}ê°œ íšŒë¡œ)")
    
    # í”¼ë¸ë¦¬í‹° ë° í‘œí˜„ë ¥ ê³„ì‚° ê²°ê³¼ëŠ” ì´ë¯¸ analysis_resultsì— í¬í•¨ë¨
    print(f"ğŸ“Š ë¶„ì„ ê²°ê³¼ í¬ë§·íŒ… ì¤‘... ({len(analysis_results)}ê°œ íšŒë¡œ ë°ì´í„°)")
    
    all_results = []
    
    # íšŒë¡œ ì¸ë±ìŠ¤ë³„ë¡œ ê²°ê³¼ ì²˜ë¦¬
    print("ğŸ“Š íšŒë¡œë³„ ê²°ê³¼ í†µí•© ì¤‘...")
    
    # ëª¨ë“  íšŒë¡œ ë©”íƒ€ë°ì´í„°ë¥¼ ìˆœíšŒ
    for circuit_idx, metadata in enumerate(tqdm(circuit_metadata, desc="íšŒë¡œ ì²˜ë¦¬")):
        try:
            # íšŒë¡œê°€ ë¶„ì„ ê²°ê³¼ì— ì—†ìœ¼ë©´ ê±´ë„ˆëœ€
            if circuit_idx not in analysis_results:
                print(f"âš ï¸ íšŒë¡œ {circuit_idx}: ë¶„ì„ ê²°ê³¼ ì—†ìŒ")
                continue
            
            # íšŒë¡œ ë¶„ì„ ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°
            circuit_analysis = analysis_results[circuit_idx]
            
            # ë©”íƒ€ë°ì´í„° ê¸°ë³¸ ì •ë³´ ì¶”ì¶œ
            n_qubits = metadata.get('n_qubits', 0)
            depth = metadata.get('depth', 0)
            circuit_name = metadata.get('name', f"circuit_{circuit_idx}")
            gate_counts = metadata.get('gate_counts', {})
            circuit_type = metadata.get('circuit_type', 'unknown')
            
            # í”¼ë¸ë¦¬í‹° ì •ë³´ ì¶”ì¶œ
            fidelity = circuit_analysis.get('fidelity', 0.0)
            fidelity_method = circuit_analysis.get('fidelity_method', 'not_available')
            
            # í‘œí˜„ë ¥ ì •ë³´ ì¶”ì¶œ (ìˆì„ ê²½ìš°)
            expressibility = circuit_analysis.get('expressibility', 0.0)
            expressibility_method = circuit_analysis.get('expressibility_method', 'not_available')
            distance_from_haar = circuit_analysis.get('distance_from_haar', 1.0)
            
            # ì¸¡ì • í†µê³„ ë° ì˜¤ë¥˜ìœ¨ ê³„ì‚°ì— í•„ìš”í•œ ê¸°ë³¸ ê°’ë“¤
            total_counts = 0
            processed_counts = {}
            zero_state_probability = 0.0
            
            # í”¼ë¸ë¦¬í‹° ê°’ì„ í†µí•´ ëª¨ë¸ë§ëœ í”¼ë¸ë¦¬í‹° ì§€í‘œ ê³„ì‚°
            error_rates = {
                "gate_error_rate": 1.0 - fidelity if isinstance(fidelity, (int, float)) else 1.0,
                "circuit_error_probability": 1.0 - fidelity if isinstance(fidelity, (int, float)) else 1.0
            }
            
            # ê°•í™” í”¼ë¸ë¦¬í‹° - ì—…ë°ì´íŠ¸ëœ ì‹œìŠ¤í…œì—ì„œëŠ” ì§ì ‘ ì¸¡ì •ëœ ê°’ ì‚¬ìš©
            robust_fidelity = fidelity
            
            # ì¸¡ì • í†µê³„ - ë ˆê±°ì‹œ í˜¸í™˜ì„±ì„ ìœ„í•´ ì„ì˜ì˜ ê°’ ì‚¬ìš©
            measurement_statistics = {
                "entropy": 0.0,
                "unique_states": 1
            }
            
            # í‘œí˜„ë ¥ ì •ë³´ êµ¬ì„±
            circuit_expressibility = {
                "value": expressibility if isinstance(expressibility, (int, float)) else 0.0,
                "method": expressibility_method,
                "distance_from_haar": distance_from_haar
            }
            
            # í”¼ë¸ë¦¬í‹° ê³„ì‚° ë° ì¶”ê°€ ë¶„ì„
            output_result = {
                "circuit_index": circuit_idx,
                "gate_metrics": error_rates,
                "fidelity": {
                    "simple": fidelity,  # ì´ì œ ì§ì ‘ í”¼ë¸ë¦¬í‹° ê°’ ì‚¬ìš©
                    "robust": robust_fidelity,
                    "method": fidelity_method
                },
                "expressibility": circuit_expressibility,
                "measurement_statistics": measurement_statistics,
                "execution_metadata": {
                    "circuit_index": circuit_idx,
                    "execution_time": execution_time,
                    "backend_name": ibm_backend.name,
                    "timestamp": datetime.now().isoformat()
                }
            }
            
            # ë©”íƒ€ë°ì´í„°ì—ì„œ ì¶”ê°€ ì •ë³´ ì¶”ì¶œ
            if circuit_idx < len(circuit_metadata):
                circuit_meta = circuit_metadata[circuit_idx]
                output_result.update(circuit_meta)
                
                # íŠ¹ë³„íˆ ì¤‘ìš”í•œ ì •ë³´ëŠ” ë³„ë„ë¡œ ê·¸ë£¹í™”
                output_result["additional_metrics"] = {
                    "depth": depth,
                    "width": n_qubits
                }
            
            # ìµœì¢… ê²°ê³¼ì— ì¶”ê°€
            all_results.append(output_result)
            
        except Exception as e:
            print(f"âš ï¸ íšŒë¡œ {circuit_idx} ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}")
            error_result = {
                "circuit_index": circuit_idx,
                "fidelity": {
                    "simple": float('nan'),
                    "robust": float('nan'),
                    "method": "processing_error"
                },
                "expressibility": {
                    "value": float('nan'),
                    "method": "processing_error",
                    "error": str(e)
                },
                "execution_metadata": {
                    "circuit_index": circuit_idx,
                    "execution_time": execution_time,
                    "backend_name": ibm_backend.name,
                    "timestamp": datetime.now().isoformat(),
                    "processing_error": True
                }
            }
            if circuit_idx < len(circuit_metadata):
                error_result.update(circuit_metadata[circuit_idx])
            all_results.append(error_result)
    
    print(f"âœ… ë©”ê°€ ì¡ ê²°ê³¼ ì²˜ë¦¬ ì™„ë£Œ ({len(all_results)}ê°œ ê²°ê³¼)")
    return all_results


def save_mega_results(all_results, training_circuits):
    """
    ë©”ê°€ ì¡(Mega job) ê²°ê³¼ë¥¼ íŒŒì¼ì— ì €ì¥í•©ë‹ˆë‹¤.
    
    Args:
        all_results (List[Dict]): `process_mega_results` í•¨ìˆ˜ì—ì„œ ë°˜í™˜ëœ ì²˜ë¦¬ëœ ê²°ê³¼ ëª©ë¡ì…ë‹ˆë‹¤.
        training_circuits (List[Dict]): í›ˆë ¨ì— ì‚¬ìš©ëœ íšŒë¡œ ëª©ë¡ì…ë‹ˆë‹¤ (ì„ íƒ ì‚¬í•­).
        
    Returns:
        Dict: ì €ì¥ëœ íŒŒì¼ ê²½ë¡œ ë“± ê²°ê³¼ ì •ë³´ë¥¼ ë‹´ì€ ë”•ì…”ë„ˆë¦¬ì…ë‹ˆë‹¤.
    """
    print("\nğŸ’¾ ì‹¤í—˜ ê²°ê³¼ ì €ì¥ ì¤‘...")
    
    # íŒŒì¼ëª…ì— ì‚¬ìš©ë  í˜„ì¬ ì‹œê° íƒ€ì„ìŠ¤íƒ¬í”„ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    
    # ê²°ê³¼ íŒŒì¼ì„ ì €ì¥í•  ë””ë ‰í† ë¦¬ë¥¼ í™•ì¸í•˜ê³ , ì—†ìœ¼ë©´ ìƒì„±í•©ë‹ˆë‹¤.
    results_dir = "experiments/results"
    os.makedirs(results_dir, exist_ok=True)
    
    # ê²°ê³¼ ë°ì´í„° êµ¬ì¡°ë¥¼ ì¤€ë¹„í•©ë‹ˆë‹¤.
    result_data = {
        "experiment_type": "mega_job",
        "timestamp": timestamp,
        "circuit_count": len(all_results),
        "results": all_results
    }
    
    if training_circuits:
        result_data["training_circuits"] = training_circuits
    
    # ëª¨ë“  ê²°ê³¼ ë°ì´í„°ë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.
    file_prefix = config.get('experiment_file_prefix', 'mega_job')
    json_filename = f"{results_dir}/{file_prefix}_results_{timestamp}.json"
    try:
        # JSON ì§ë ¬í™” ê°€ëŠ¥í•œ í˜•íƒœë¡œ ë³€í™˜
        serializable_data = make_json_serializable(result_data)
        with open(json_filename, 'w') as f:
            json.dump(serializable_data, f, indent=2)
        print(f"   JSON íŒŒì¼ë¡œ ì €ì¥ ì™„ë£Œ: {json_filename}")
    except Exception as e:
        print(f"âš ï¸ JSON ì €ì¥ ì‹¤íŒ¨: {str(e)}")
    
    # ì£¼ìš” ê²°ê³¼ ì§€í‘œë¥¼ ìš”ì•½í•˜ì—¬ CSV íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.
    try:
        summary_list = []
        for result in all_results:
            # ìƒˆë¡œìš´ ê²°ê³¼ êµ¬ì¡°ì—ì„œ ì •ë³´ ì¶”ì¶œ
            fidelity = result.get("fidelity", {})
            expressibility = result.get("expressibility", {})
            additional_metrics = result.get("additional_metrics", {})
            
            # CSVì— ì €ì¥í•  ì£¼ìš” íšŒë¡œ ì •ë³´ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
            row = {
                "circuit_index": result.get("circuit_index", -1),
                "config_group": result.get("config_group", ""),
                "n_qubits": result.get("n_qubits", 0),
                "depth": result.get("depth", 0) or additional_metrics.get("depth", 0),
                "two_qubit_ratio_target": result.get("two_qubit_ratio_target", 0),
                "zero_state_prob": fidelity.get("simple", 0),
                "robust_fidelity": fidelity.get("robust", 0),
                "fidelity_method": fidelity.get("method", "unknown")
            }
            
            # í‘œí˜„ë ¥ ì§€í‘œ ì¶”ê°€
            if isinstance(expressibility, dict):
                # ê¸°ë³¸ í‘œí˜„ë ¥ ê°’
                row["expressibility_score"] = expressibility.get("value", None)
                row["expressibility_method"] = expressibility.get("method", "unknown")
                row["distance_from_haar"] = expressibility.get("distance_from_haar", 1.0)
                
                # ì¶”ê°€ì ì¸ í‘œí˜„ë ¥ ì¸¡ì • ì§€í‘œë“¤ì´ ìˆë‹¤ë©´ ì¶”ê°€
                for metric_name, value in expressibility.items():
                    if metric_name not in ["value", "method", "distance_from_haar"]:
                        row[f"expressibility_{metric_name}"] = value
            
            summary_list.append(row)
        
        # ì¶”ì¶œëœ ìš”ì•½ ì •ë³´ë¥¼ Pandas DataFrameìœ¼ë¡œ ë³€í™˜í•˜ì—¬ CSV íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.
        if summary_list:
            df = pd.DataFrame(summary_list)
            # file_prefix is defined above for the json filename
            csv_filename = f"{results_dir}/{file_prefix}_summary_{timestamp}.csv"
            df.to_csv(csv_filename, index=False)
            print(f"   CSV ìš”ì•½ ì €ì¥ ì™„ë£Œ: {csv_filename}")
        
    except Exception as e:
        print(f"âš ï¸ CSV ìš”ì•½ ì €ì¥ ì‹¤íŒ¨: {str(e)}")
    
    # ëª¨ë“  ê²°ê³¼ ë°ì´í„°ë¥¼ HDF5 í˜•ì‹ìœ¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤ (ëŒ€ìš©ëŸ‰ ë°ì´í„°ì— ì í•©).
    try:
        # file_prefix is defined above for the json filename
        hdf5_filename = f"{results_dir}/{file_prefix}_data_{timestamp}.h5"
        save_experiment_hdf5(all_results, hdf5_filename)
        print(f"   HDF5 ë°ì´í„° ì €ì¥ ì™„ë£Œ: {hdf5_filename}")
    except Exception as e:
        print(f"âš ï¸ HDF5 ì €ì¥ ì‹¤íŒ¨: {str(e)}")
    
    return {
        "timestamp": timestamp,
        "json_file": json_filename,
        "csv_file": f"{results_dir}/mega_job_summary_{timestamp}.csv",
        "hdf5_file": f"{results_dir}/mega_job_data_{timestamp}.h5"
    }


def analyze_two_qubit_ratio_results(all_results):
    """
    2íë¹— ê²Œì´íŠ¸ ë¹„ìœ¨ì— ë”°ë¥¸ ì‹¤í—˜ ê²°ê³¼ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.
    
    Args:
        all_results (List[Dict]): `process_mega_results` í•¨ìˆ˜ì—ì„œ ë°˜í™˜ëœ ì²˜ë¦¬ëœ ê²°ê³¼ ëª©ë¡ì…ë‹ˆë‹¤.
        
    Returns:
        pd.DataFrame: ë¶„ì„ ê²°ê³¼ë¥¼ ë‹´ì€ Pandas DataFrameì…ë‹ˆë‹¤.
    """
    print("\nğŸ“Š 2íë¹— ê²Œì´íŠ¸ ë¹„ìœ¨ë³„ ê²°ê³¼ ë¶„ì„ ì¤‘...")
    
    # DataFrame ìƒì„±ì„ ìœ„í•´ ë¶„ì„ì— í•„ìš”í•œ ë°ì´í„°ë¥¼ ê²°ê³¼ ëª©ë¡ì—ì„œ ì¶”ì¶œí•©ë‹ˆë‹¤.
    analysis_data = []
    
    for result in all_results:
        try:
            # ìƒˆë¡œìš´ ê²°ê³¼ êµ¬ì¡°ì—ì„œ ì •ë³´ ì¶”ì¶œ
            fidelity = result.get("fidelity", {})
            expressibility = result.get("expressibility", {})
            additional_metrics = result.get("additional_metrics", {})
            
            # í•µì‹¬ ë©”íŠ¸ë¦­(ì§€í‘œ)ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
            row = {
                "circuit_index": result.get("circuit_index", -1),
                "config_group": result.get("config_group", ""),
                "n_qubits": result.get("n_qubits", 0),
                "depth": result.get("depth", 0) or additional_metrics.get("depth", 0),
                "two_qubit_ratio_target": result.get("two_qubit_ratio_target", 0),
                "zero_state_prob": fidelity.get("simple", 0),
                "robust_fidelity": fidelity.get("robust", 0),
                "fidelity_method": fidelity.get("method", "unknown")
            }
            
            # í‘œí˜„ë ¥ ì§€í‘œ ì¶”ê°€
            if isinstance(expressibility, dict):
                # ê¸°ë³¸ í‘œí˜„ë ¥ ê°’
                row["expressibility_score"] = expressibility.get("value", None)
                row["expressibility_method"] = expressibility.get("method", "unknown")
                row["distance_from_haar"] = expressibility.get("distance_from_haar", 1.0)
                
                # ì¶”ê°€ì ì¸ í‘œí˜„ë ¥ ì¸¡ì • ì§€í‘œë“¤ì´ ìˆë‹¤ë©´ ì¶”ê°€
                for metric_name, value in expressibility.items():
                    if metric_name not in ["value", "method", "distance_from_haar", "error"]:
                        row[f"expressibility_{metric_name}"] = value
            
            analysis_data.append(row)
            
        except Exception as e:
            continue
    
    if not analysis_data:
        print("âš ï¸ ë¶„ì„í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return None
    
    # ì¶”ì¶œëœ ë¶„ì„ìš© ë°ì´í„°ë¡œ Pandas DataFrameì„ ìƒì„±í•©ë‹ˆë‹¤.
    df = pd.DataFrame(analysis_data)
    
    # íë¹— ìˆ˜, íšŒë¡œ ê¹Šì´, 2íë¹— ê²Œì´íŠ¸ ë¹„ìœ¨ë³„ë¡œ ê·¸ë£¹í™”í•˜ì—¬ í†µê³„ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
    print("\nğŸ“ˆ 2íë¹— ê²Œì´íŠ¸ ë¹„ìœ¨ë³„ í”¼ë¸ë¦¬í‹° ë° í‘œí˜„ë ¥ ë¶„ì„:")
    
    try:
        # ê·¸ë£¹ë³„ í†µê³„ (ì¶”ê°€ í‘œí˜„ë ¥ ë©”íŠ¸ë¦­ í¬í•¨)
        metric_columns = ['zero_state_prob', 'robust_fidelity', 'expressibility_score', 'expressibility_entropy']
        
        # DataFrameì— ë™ì ìœ¼ë¡œ ì¶”ê°€ëœ í‘œí˜„ë ¥ ë©”íŠ¸ë¦­ ì»¬ëŸ¼ë“¤ì„ ì°¾ìŠµë‹ˆë‹¤.
        distance_metrics_columns = [col for col in df.columns if col.startswith('expressibility_') 
                                   and col not in ['expressibility_score', 'expressibility_entropy']]
        if distance_metrics_columns:
            metric_columns.extend(distance_metrics_columns)
        
        # ê° ë©”íŠ¸ë¦­ë³„ë¡œ ì–´ë–¤ í†µê³„ í•¨ìˆ˜(í‰ê· , í‘œì¤€í¸ì°¨ ë“±)ë¥¼ ì ìš©í• ì§€ ì •ì˜í•©ë‹ˆë‹¤.
        agg_dict = {}
        for col in metric_columns:
            if col == 'zero_state_prob':
                agg_dict[col] = ['mean', 'std', 'count']
            else:
                agg_dict[col] = ['mean', 'std']
        
        grouped = df.groupby(['n_qubits', 'depth', 'two_qubit_ratio_target']).agg(agg_dict)
        
        # Pandas DataFrame ì¶œë ¥ í˜•ì‹ì„ ì„¤ì •í•©ë‹ˆë‹¤.
        pd.set_option('display.max_rows', None)
        pd.set_option('display.width', 120)
        pd.set_option('display.precision', 4)
        
        print("\nğŸ” ê·¸ë£¹ë³„ ì„±ëŠ¥ í†µê³„:")
        print(grouped)
        
        # ë³´ê³ ì„œ íŒŒì¼ëª…ì— ì‚¬ìš©ë  í˜„ì¬ ì‹œê° íƒ€ì„ìŠ¤íƒ¬í”„ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        
        # ë¶„ì„ ë³´ê³ ì„œë¥¼ ì €ì¥í•  ë””ë ‰í† ë¦¬ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.
        report_dir = "reports"
        os.makedirs(report_dir, exist_ok=True)
        
        # ë¶„ì„ ê²°ê³¼ë¥¼ CSV íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.
        csv_filename = f"{report_dir}/two_qubit_ratio_analysis_{timestamp}.csv"
        grouped.to_csv(csv_filename)
        print(f"\nâœ… ë¶„ì„ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {csv_filename}")
        
    except Exception as e:
        print(f"âš ï¸ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
    
    return df
