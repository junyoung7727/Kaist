#!/usr/bin/env python3
"""
ê²°ê³¼ ì²˜ë¦¬ ëª¨ë“ˆ - ì–‘ì íšŒë¡œ ì‹¤í–‰ ê²°ê³¼ ì²˜ë¦¬ ë° ë¶„ì„ ë¡œì§ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤.
"""

import sys
import os
import json
import pandas as pd
import numpy as np
from typing import Dict, List, Any, Optional, Union, Tuple
from datetime import datetime
import gc
from tqdm import tqdm

# í‘œí˜„ë ¥ ê³„ì‚° ëª¨ë“ˆ ì„í¬íŠ¸
from src.calculators.expressibility.ibm import IBMExpressibilityCalculator

# í˜„ì¬ ìŠ¤í¬ë¦½íŠ¸ì˜ ìƒìœ„ ë””ë ‰í† ë¦¬ë¥¼ ì‹œìŠ¤í…œ ê²½ë¡œì— ì¶”ê°€ (ëª¨ë“ˆ ì„í¬íŠ¸ë¥¼ ìœ„í•¨)
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))
from src.config import config # Ensure config is imported

from data_manager import save_experiment_hdf5


def process_mega_results(result, circuit_metadata, execution_time, ibm_backend):
    """
    ë©”ê°€ ì¡(Mega job) ê²°ê³¼ ì²˜ë¦¬ - ì‹¤ì œ ì¸¡ì • ë°ì´í„°ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.
    
    Args:
        result: IBM ë°±ì—”ë“œì—ì„œ ì‹¤í–‰ëœ ê²°ê³¼ ê°ì²´ì…ë‹ˆë‹¤.
        circuit_metadata (List[Dict]): ê° íšŒë¡œì— ëŒ€í•œ ë©”íƒ€ë°ì´í„° ëª©ë¡ì…ë‹ˆë‹¤.
        execution_time (float): ì „ì²´ ì¡ ì‹¤í–‰ì— ì†Œìš”ëœ ì‹œê°„(ì´ˆ)ì…ë‹ˆë‹¤.
        
    Returns:
        List[Dict]: ê° íšŒë¡œë³„ë¡œ ì²˜ë¦¬ëœ ê²°ê³¼ì˜ ëª©ë¡ì…ë‹ˆë‹¤.
    """
    from src.utils.quantum_utils import (
        calculate_error_rates_mega,
        calculate_robust_fidelity_mega,
        calculate_measurement_statistics
    )
    from src.core.job_runner import run_mega_expressibility_batch
    
    print(f"\nğŸ”¬ ë©”ê°€ ì¡ ê²°ê³¼ ì²˜ë¦¬ ì‹œì‘ ({len(circuit_metadata)}ê°œ íšŒë¡œ)")
    
    # ë©”ê°€ ë°°ì¹˜ í‘œí˜„ë ¥ ê³„ì‚° - ëª¨ë“  íšŒë¡œì— ëŒ€í•´ í•œ ë²ˆì— ì‹¤í–‰
    print("ğŸš€ ë©”ê°€ ë°°ì¹˜ í‘œí˜„ë ¥ ê³„ì‚° ì‹¤í–‰ ì¤‘...")
    mega_expressibility_results = run_mega_expressibility_batch(circuit_metadata, ibm_backend)
    print(f"âœ… ë©”ê°€ ë°°ì¹˜ í‘œí˜„ë ¥ ê³„ì‚° ì™„ë£Œ ({len(mega_expressibility_results)}ê°œ ê²°ê³¼)")
    
    all_results = []
    
    # ê° íšŒë¡œë³„ë¡œ ê²°ê³¼ ì²˜ë¦¬
    print("ğŸ“Š íšŒë¡œë³„ ê²°ê³¼ ë¶„ì„ ì¤‘...")
    
    for circuit_idx, circuit_result in enumerate(tqdm(result, desc="íšŒë¡œ ì²˜ë¦¬")):
        try:
            # ë©”íƒ€ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
            metadata = circuit_metadata[circuit_idx] if circuit_idx < len(circuit_metadata) else {}
            n_qubits = metadata.get('n_qubits', 0)
            
            # ì¸¡ì • ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°
            if hasattr(circuit_result, 'data'):
                if hasattr(circuit_result.data(), '__iter__'):
                    counts = circuit_result.data()[0].get("meas", {})
                else:
                    counts = circuit_result.data().get("meas", {})
            elif hasattr(circuit_result, 'get_counts'):
                counts = circuit_result.get_counts()
            else:
                counts = getattr(circuit_result, 'counts', {})
            
            if not counts:
                print(f"âš ï¸ íšŒë¡œ {circuit_idx}: ì¸¡ì • ê²°ê³¼ ì—†ìŒ")
                continue
            
            # ë¹„íŠ¸ ë¬¸ìì—´ ê¸¸ì´ ì •ê·œí™”
            total_counts = sum(counts.values())
            processed_counts = {}
            
            for bit_str, count in counts.items():
                if len(bit_str) > n_qubits:
                    bit_str = bit_str[:n_qubits]
                elif len(bit_str) < n_qubits:
                    bit_str = bit_str.zfill(n_qubits)
                
                if bit_str in processed_counts:
                    processed_counts[bit_str] += count
                else:
                    processed_counts[bit_str] = count
            
            # 0 ìƒíƒœ(zero state) í™•ë¥ ì„ ê¸°ë°˜ìœ¼ë¡œ ë‹¨ìˆœ í”¼ë¸ë¦¬í‹°ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
            zero_state = '0' * n_qubits
            zero_count = processed_counts.get(zero_state, 0)
            zero_state_probability = zero_count / total_counts if total_counts > 0 else 0
            
            # ë‹¤ì–‘í•œ ì˜¤ë¥˜ìœ¨ ì§€í‘œë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
            error_rates = calculate_error_rates_mega(
                processed_counts,
                n_qubits,
                total_counts
            )
            
            # Robust í”¼ë¸ë¦¬í‹°ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
            robust_fidelity = calculate_robust_fidelity_mega(
                processed_counts,
                n_qubits,
                total_counts
            )
            
            # ì¸¡ì • ê²°ê³¼ì— ëŒ€í•œ ì¶”ê°€ í†µê³„ì¹˜ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
            measurement_stats = calculate_measurement_statistics(
                processed_counts,
                n_qubits
            )
            
            # ë©”ê°€ ë°°ì¹˜ì—ì„œ ë¯¸ë¦¬ ê³„ì‚°ëœ í‘œí˜„ë ¥ ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°
            expressibility_result = mega_expressibility_results.get(circuit_idx, {
                "expressibility_value": float('nan'),
                "method": "not_calculated",
                "error": "Not found in mega batch results"
            })
                
            # ê³„ì‚°ëœ ëª¨ë“  ì§€í‘œë¥¼ í¬í•¨í•˜ëŠ” ì‹¤í–‰ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬ë¥¼ êµ¬ì„±í•©ë‹ˆë‹¤.
            execution_result = {
                "zero_state_probability": zero_state_probability,
                "measurement_counts": processed_counts,
                "measured_states": total_counts,
                "error_rates": error_rates,
                "robust_fidelity": robust_fidelity,
                "measurement_statistics": measurement_stats,
                "expressibility": expressibility_result,  # ë©”ê°€ ë°°ì¹˜ ê²°ê³¼ ì‚¬ìš©
                "execution_metadata": {
                    "circuit_index": circuit_idx,
                    "execution_time": execution_time,
                    "backend_name": ibm_backend.name,
                    "timestamp": datetime.now().isoformat()
                }
            }
            
            # ë©”íƒ€ë°ì´í„°ì™€ ì‹¤í–‰ ê²°ê³¼ë¥¼ ê²°í•©
            complete_result = {**metadata, **execution_result}
            all_results.append(complete_result)
            
        except Exception as e:
            print(f"âš ï¸ íšŒë¡œ {circuit_idx} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            # ì˜¤ë¥˜ ë°œìƒ ì‹œì—ë„ ê¸°ë³¸ ê²°ê³¼ êµ¬ì¡° ìœ ì§€
            error_result = {
                "circuit_index": circuit_idx,
                "error": str(e),
                "zero_state_probability": float('nan'),
                "measurement_counts": {},
                "measured_states": 0,
                "error_rates": {},
                "robust_fidelity": float('nan'),
                "measurement_statistics": {},
                "expressibility": {
                    "expressibility_value": float('nan'),
                    "method": "processing_error",
                    "error": str(e)
                },
                "execution_metadata": {
                    "circuit_index": circuit_idx,
                    "execution_time": execution_time,
                    "backend_name": ibm_backend.name,
                    "timestamp": datetime.now().isoformat(),
                    "processing_error": True
                }
            }
            if circuit_idx < len(circuit_metadata):
                error_result.update(circuit_metadata[circuit_idx])
            all_results.append(error_result)
    
    print(f"âœ… ë©”ê°€ ì¡ ê²°ê³¼ ì²˜ë¦¬ ì™„ë£Œ ({len(all_results)}ê°œ ê²°ê³¼)")
    return all_results


def save_mega_results(all_results, training_circuits):
    """
    ë©”ê°€ ì¡(Mega job) ê²°ê³¼ë¥¼ íŒŒì¼ì— ì €ì¥í•©ë‹ˆë‹¤.
    
    Args:
        all_results (List[Dict]): `process_mega_results` í•¨ìˆ˜ì—ì„œ ë°˜í™˜ëœ ì²˜ë¦¬ëœ ê²°ê³¼ ëª©ë¡ì…ë‹ˆë‹¤.
        training_circuits (List[Dict]): í›ˆë ¨ì— ì‚¬ìš©ëœ íšŒë¡œ ëª©ë¡ì…ë‹ˆë‹¤ (ì„ íƒ ì‚¬í•­).
        
    Returns:
        Dict: ì €ì¥ëœ íŒŒì¼ ê²½ë¡œ ë“± ê²°ê³¼ ì •ë³´ë¥¼ ë‹´ì€ ë”•ì…”ë„ˆë¦¬ì…ë‹ˆë‹¤.
    """
    print("\nğŸ’¾ ì‹¤í—˜ ê²°ê³¼ ì €ì¥ ì¤‘...")
    
    # íŒŒì¼ëª…ì— ì‚¬ìš©ë  í˜„ì¬ ì‹œê° íƒ€ì„ìŠ¤íƒ¬í”„ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    
    # ê²°ê³¼ íŒŒì¼ì„ ì €ì¥í•  ë””ë ‰í† ë¦¬ë¥¼ í™•ì¸í•˜ê³ , ì—†ìœ¼ë©´ ìƒì„±í•©ë‹ˆë‹¤.
    results_dir = "experiments/results"
    os.makedirs(results_dir, exist_ok=True)
    
    # JSON íŒŒì¼ì— ì €ì¥í•  ì „ì²´ ë°ì´í„° êµ¬ì¡°ë¥¼ ì¤€ë¹„í•©ë‹ˆë‹¤.
    result_data = {
        "experiment_type": "mega_job",
        "timestamp": timestamp,
        "circuit_count": len(all_results),
        "results": all_results
    }
    
    if training_circuits:
        result_data["training_circuits"] = training_circuits
    
    # ëª¨ë“  ê²°ê³¼ ë°ì´í„°ë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.
    file_prefix = config.get('experiment_file_prefix', 'mega_job')
    json_filename = f"{results_dir}/{file_prefix}_results_{timestamp}.json"
    try:
        with open(json_filename, 'w') as f:
            json.dump(result_data, f, indent=2)
        print(f"   JSON íŒŒì¼ë¡œ ì €ì¥ ì™„ë£Œ: {json_filename}")
    except Exception as e:
        print(f"âš ï¸ JSON ì €ì¥ ì‹¤íŒ¨: {str(e)}")
    
    # ì£¼ìš” ê²°ê³¼ ì§€í‘œë¥¼ ìš”ì•½í•˜ì—¬ CSV íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.
    try:
        summary_list = []
        for result in all_results:
            execution_result = result.get("execution_result", {})
            circuit_properties = result.get("circuit_properties", {})
            
            # CSVì— ì €ì¥í•  ì£¼ìš” íšŒë¡œ ì •ë³´ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
            row = {
                "circuit_id": result.get("circuit_id", -1),
                "config_group": result.get("config_group", ""),
                "n_qubits": result.get("n_qubits", 0),
                "depth": result.get("depth", 0),
                "two_qubit_ratio_target": result.get("two_qubit_ratio_target", 0),
                "zero_state_prob": execution_result.get("zero_state_probability", 0),
                "robust_fidelity": execution_result.get("robust_fidelity", 0),
            }
            
            # í‘œí˜„ë ¥ ì§€í‘œ ì¶”ê°€
            expressibility = execution_result.get("expressibility", {})
            if isinstance(expressibility, dict):
                # ê¸°ë³¸ í‘œí˜„ë ¥ ì ìˆ˜ ë° ì—”íŠ¸ë¡œí”¼
                row["expressibility_score"] = expressibility.get("expressibility_score", None)
                row["expressibility_entropy"] = expressibility.get("entropy", None)
                
                # ì¶”ê°€ì ì¸ ê±°ë¦¬ ê¸°ë°˜ í‘œí˜„ë ¥ ì¸¡ì • ì§€í‘œë“¤
                distance_metrics = expressibility.get("distance_metrics", {})
                if isinstance(distance_metrics, dict):
                    for metric_name, value in distance_metrics.items():
                        row[f"expressibility_{metric_name}"] = value
            
            summary_list.append(row)
        
        # ì¶”ì¶œëœ ìš”ì•½ ì •ë³´ë¥¼ Pandas DataFrameìœ¼ë¡œ ë³€í™˜í•˜ì—¬ CSV íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.
        if summary_list:
            df = pd.DataFrame(summary_list)
            # file_prefix is defined above for the json filename
            csv_filename = f"{results_dir}/{file_prefix}_summary_{timestamp}.csv"
            df.to_csv(csv_filename, index=False)
            print(f"   CSV ìš”ì•½ ì €ì¥ ì™„ë£Œ: {csv_filename}")
        
    except Exception as e:
        print(f"âš ï¸ CSV ìš”ì•½ ì €ì¥ ì‹¤íŒ¨: {str(e)}")
    
    # ëª¨ë“  ê²°ê³¼ ë°ì´í„°ë¥¼ HDF5 í˜•ì‹ìœ¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤ (ëŒ€ìš©ëŸ‰ ë°ì´í„°ì— ì í•©).
    try:
        # file_prefix is defined above for the json filename
        hdf5_filename = f"{results_dir}/{file_prefix}_data_{timestamp}.h5"
        save_experiment_hdf5(all_results, hdf5_filename)
        print(f"   HDF5 ë°ì´í„° ì €ì¥ ì™„ë£Œ: {hdf5_filename}")
    except Exception as e:
        print(f"âš ï¸ HDF5 ì €ì¥ ì‹¤íŒ¨: {str(e)}")
    
    return {
        "timestamp": timestamp,
        "json_file": json_filename,
        "csv_file": f"{results_dir}/mega_job_summary_{timestamp}.csv",
        "hdf5_file": f"{results_dir}/mega_job_data_{timestamp}.h5"
    }


def analyze_two_qubit_ratio_results(all_results):
    """
    2íë¹— ê²Œì´íŠ¸ ë¹„ìœ¨ì— ë”°ë¥¸ ì‹¤í—˜ ê²°ê³¼ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.
    
    Args:
        all_results (List[Dict]): `process_mega_results` í•¨ìˆ˜ì—ì„œ ë°˜í™˜ëœ ì²˜ë¦¬ëœ ê²°ê³¼ ëª©ë¡ì…ë‹ˆë‹¤.
        
    Returns:
        pd.DataFrame: ë¶„ì„ ê²°ê³¼ë¥¼ ë‹´ì€ Pandas DataFrameì…ë‹ˆë‹¤.
    """
    print("\nğŸ“Š 2íë¹— ê²Œì´íŠ¸ ë¹„ìœ¨ë³„ ê²°ê³¼ ë¶„ì„ ì¤‘...")
    
    # DataFrame ìƒì„±ì„ ìœ„í•´ ë¶„ì„ì— í•„ìš”í•œ ë°ì´í„°ë¥¼ ê²°ê³¼ ëª©ë¡ì—ì„œ ì¶”ì¶œí•©ë‹ˆë‹¤.
    analysis_data = []
    
    for result in all_results:
        try:
            execution_result = result.get("execution_result", {})
            
            # í•µì‹¬ ë©”íŠ¸ë¦­(ì§€í‘œ)ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.
            row = {
                "circuit_id": result.get("circuit_id", -1),
                "config_group": result.get("config_group", ""),
                "n_qubits": result.get("n_qubits", 0),
                "depth": result.get("depth", 0),
                "two_qubit_ratio_target": result.get("two_qubit_ratio_target", 0),
                "zero_state_prob": execution_result.get("zero_state_probability", 0),
                "robust_fidelity": execution_result.get("robust_fidelity", 0),
            }
            
            # í‘œí˜„ë ¥ ì§€í‘œ ì¶”ê°€
            expressibility = execution_result.get("expressibility", {})
            if isinstance(expressibility, dict):
                # ê¸°ë³¸ í‘œí˜„ë ¥ ì ìˆ˜ ë° ì—”íŠ¸ë¡œí”¼
                row["expressibility_score"] = expressibility.get("expressibility_score", None)
                row["expressibility_entropy"] = expressibility.get("entropy", None)
                
                # ì¶”ê°€ì ì¸ ê±°ë¦¬ ê¸°ë°˜ í‘œí˜„ë ¥ ì¸¡ì • ì§€í‘œë“¤
                distance_metrics = expressibility.get("distance_metrics", {})
                if isinstance(distance_metrics, dict):
                    for metric_name, value in distance_metrics.items():
                        row[f"expressibility_{metric_name}"] = value
            
            analysis_data.append(row)
            
        except Exception as e:
            continue
    
    if not analysis_data:
        print("âš ï¸ ë¶„ì„í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return None
    
    # ì¶”ì¶œëœ ë¶„ì„ìš© ë°ì´í„°ë¡œ Pandas DataFrameì„ ìƒì„±í•©ë‹ˆë‹¤.
    df = pd.DataFrame(analysis_data)
    
    # íë¹— ìˆ˜, íšŒë¡œ ê¹Šì´, 2íë¹— ê²Œì´íŠ¸ ë¹„ìœ¨ë³„ë¡œ ê·¸ë£¹í™”í•˜ì—¬ í†µê³„ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
    print("\nğŸ“ˆ 2íë¹— ê²Œì´íŠ¸ ë¹„ìœ¨ë³„ í”¼ë¸ë¦¬í‹° ë° í‘œí˜„ë ¥ ë¶„ì„:")
    
    try:
        # ê·¸ë£¹ë³„ í†µê³„ (ì¶”ê°€ í‘œí˜„ë ¥ ë©”íŠ¸ë¦­ í¬í•¨)
        metric_columns = ['zero_state_prob', 'robust_fidelity', 'expressibility_score', 'expressibility_entropy']
        
        # DataFrameì— ë™ì ìœ¼ë¡œ ì¶”ê°€ëœ í‘œí˜„ë ¥ ë©”íŠ¸ë¦­ ì»¬ëŸ¼ë“¤ì„ ì°¾ìŠµë‹ˆë‹¤.
        distance_metrics_columns = [col for col in df.columns if col.startswith('expressibility_') 
                                   and col not in ['expressibility_score', 'expressibility_entropy']]
        if distance_metrics_columns:
            metric_columns.extend(distance_metrics_columns)
        
        # ê° ë©”íŠ¸ë¦­ë³„ë¡œ ì–´ë–¤ í†µê³„ í•¨ìˆ˜(í‰ê· , í‘œì¤€í¸ì°¨ ë“±)ë¥¼ ì ìš©í• ì§€ ì •ì˜í•©ë‹ˆë‹¤.
        agg_dict = {}
        for col in metric_columns:
            if col == 'zero_state_prob':
                agg_dict[col] = ['mean', 'std', 'count']
            else:
                agg_dict[col] = ['mean', 'std']
        
        grouped = df.groupby(['n_qubits', 'depth', 'two_qubit_ratio_target']).agg(agg_dict)
        
        # Pandas DataFrame ì¶œë ¥ í˜•ì‹ì„ ì„¤ì •í•©ë‹ˆë‹¤.
        pd.set_option('display.max_rows', None)
        pd.set_option('display.width', 120)
        pd.set_option('display.precision', 4)
        
        print("\nğŸ” ê·¸ë£¹ë³„ ì„±ëŠ¥ í†µê³„:")
        print(grouped)
        
        # ë³´ê³ ì„œ íŒŒì¼ëª…ì— ì‚¬ìš©ë  í˜„ì¬ ì‹œê° íƒ€ì„ìŠ¤íƒ¬í”„ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        
        # ë¶„ì„ ë³´ê³ ì„œë¥¼ ì €ì¥í•  ë””ë ‰í† ë¦¬ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.
        report_dir = "reports"
        os.makedirs(report_dir, exist_ok=True)
        
        # ë¶„ì„ ê²°ê³¼ë¥¼ CSV íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.
        csv_filename = f"{report_dir}/two_qubit_ratio_analysis_{timestamp}.csv"
        grouped.to_csv(csv_filename)
        print(f"\nâœ… ë¶„ì„ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {csv_filename}")
        
    except Exception as e:
        print(f"âš ï¸ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
    
    return df
